type,year,title,author,partof,resources,File,tags,abstract,alias
,2011,An Introduction to Memento and Open Annotation,Herbert van de Sompel,,,SWIB/SWIB2011/An Introduction to Memento and Open Annotation.md,"#swib/2011,#memento,#framework,#Annotea,#open/annotation,#eHumanities","This session will introduce two recent technologies that are relevant to making scholarly and cultural heritage collections accessible and usable:  
(1) Conceptually, the [Memento framework](http://mementoweb.org/) introduces the time dimension that has been missing from the Web. Technically, it achieves this by introducing content negotiation in the time dimension for resources that have HTTP URIs. This allows seamless, protocol-based access to prior representations of a resource, given its URI and a desired time. Memento also yields an HTTP-based resource versioning approach that offers attractive temporal navigation features for Web resources, and that is truly powerful for leveraging Linked Data that changes over time. Memento is already catching on in the Web Archiving community, and an RFC is in the making to support broad adoption.  
(2) [Open Annotation](http://openannotation.org/) specifies a Web-centric approach aimed at annotating resources and sharing annotations across the boundaries of content collections and annotation clients. When it comes to modeling and representing annotations, Open Annotation is inspired by the W3C Annotea project. But it differs in its approach to share annotations, relying on a publish/discover paradigm that is aligned with Linked Data practices rather than on a client-server protocol as was the case with Annotea. Open Annotation's requirements gathering has focused on - sometimes complex - eHumanities use cases, but broad applicability has remained a priority throughout the effort.",SWIB
,2011,Cataloguers as the Ultimate Reasoning Machines - Training Cataloguers to Create Intelligent Linked Library data,Rurik Greenall,,,SWIB/SWIB2011/Cataloguers as the Ultimate Reasoning Machines - Training Cataloguers to Create Intelligent Linked Library data.md,"#linked/library/data,#marc,#rdf,#cataloguing,#swib/2011,#manuscripts,#cataloging","The linked library data umbrella covers many projects aimed at converting data from MARC and other traditional library formats using mapping processes and automated linking, however, at NTNU University Library we do original cataloging directly in RDF and argue that there is a huge benefit to be had from intelligent, enrichment at source; this means that the cataloguers output information that far outstrips the kind of linking created using automated processes. In fact, this is one of the key reasons we commissioned the development of a system to help our cataloguers do this. This presentation gives details of the training given to our cataloguers, the system we commissioned and the results demonstrated in our discovery platform for historical manuscripts.",SWIB
,2011,Documentation of the research process in a library as Linked Data,"Benjamin Zapilko,Brigitte Mathiak",,,SWIB/SWIB2011/Documentation of the research process in a library as Linked Data.md,"#linked/data,#gesis,#ontologies,#research,#ontology,#swrc,#swib/2011","The presentation of the entire research process as Linked Data not only makes connections between individual entities (authors, publications, research projects, etc.) explicit, but also gives them semantic information about the connection itself. In libraries, the use of Linked Data technologies can facilitate research across the entire research process by creating links to other types of information that are not necessarily documented in the library itself. Historically, different types of information are often not only documented with different, unrelated metadata standards, but also stored physically separate from each other. By using ontologies, these hurdles of data integration can be overcome and originally unconnected data can be semantically linked with each other. At GESIS - Leibniz Institute for the Social Sciences, the institute's own research process is already fully recorded in the library. The prototypical addition of linked data technologies should not only overcome technical and conceptual problems of data integration, but also present the connections within the research process. For this purpose, the established ontology SWRC (Semantic Web for Research Communities), which maps extensive research processes, is used and supplemented with new links to other established ontologies and vocabularies in order to ensure interoperability in the sense of linked data thoughts with other available data.",SWIB
,2011,Einführung in Linked Open Data,"Felix Ostrowski, Pascal Christoph",,,SWIB/SWIB2011/Einführung in Linked Open Data.md,"#swib/2011,#legal,#licenses,#FOAF","The topic of "Linked Open Data" has also attracted a great deal of attention in the library world over the past two years. On the one hand, this workshop is intended to provide a basic introduction to the underlying technologies, and on the other hand to illuminate the resulting legal issues. After an introduction to the linked data concept, the RDF model, ontologies and SKOS as well as suitable open data licenses, the participants should apply the knowledge they have gained in practice. To do this, they will create descriptions of themselves using the widely used FOAF ontology. This description should also be linked to an open data license according to linked data principles in order to implement machine-readable licensing.",SWIB
,2011,"Enhanced publications, linked data and experiences from the eco4r project",Wolfram Horstmann,,,"SWIB/SWIB2011/Enhanced publications, linked data and experiences from the eco4r project.md","#oai-ore,#bibliographic/models,#ontology,#enhanced/publications,#eco4r,#project,#long-term-archiving,#scientific-communication,#swib/2011","Research results are now available online in a wide variety of data forms (texts, software, visualizations, microdata) with different degrees of complexity in terms of their structures and models. This offers significant added value in terms of transparency and reuse and improved metadata quality and findability in (semantic) search engines. Despite existing models and prototypes (e.g. frameworks such as OAI-ORE, ontologies for bibliographic models), "enhanced publications" do not arise per se. They require documentation that must be provided by the author or a service facility such as the library. In addition, reliable linked data terminology services are required for the representation of the publications and appropriate software support. In the eco4r project, (complex) publications from productive repositories of the project partners were aggregated and visualized in a concrete application scenario. This allows the distributed publications to be compiled under new criteria. In addition to the exchange of complex information units across system boundaries, aspects of long-term archiving are also considered in the project. The lecture highlights the practical results of the project and at the same time questions the feasibility of "Enhanced Publications" for productive use in scientific communication.",SWIB
,2011,How Linking Changes the Role of Library Data: Examples from the Wider World,Thomas Baker,,,SWIB/SWIB2011/How Linking Changes the Role of Library Data - Examples from the Wider World.md,"#library-linked-data,#agrovoc,#bibliographic/description,#linked/data,#vocabularies,#swib/2011","Discussion in the W3C Library Linked Data Incubator Group (2010-2011) tended to focus on the benefits of linked-data technology to libraries. This talk explores how library data - datasets, element sets, and value vocabularies - when linked, provide new forms of support to scholarly and cultural communities in the wider world. Well-maintained value vocabularies, their concepts identified by URI and backed by institutional persistence policies, can function as magnets, forming hubs of incoming links from thousands of providers. The global agricultural research community maintains a key thesaurus, AGROVOC, through an effort distributed across multiple language areas. In the library world, the standards underpinning bibliographic description, such as ISBD, FRBR, FRAD, FRSAD, and RDA, are being translated into the language of linked data. Triplified standards provide building blocks for descriptive practice based not on fixed records, but on statements that can be recombined differently and bundled for diverse, even unanticipated, uses - aggregated "just in time" instead of being maintained "just in case". As for other artifacts of long-term cultural importance, libraries could play a key role in preserving the underlying vocabularies, ensuring their long-term usefulness as the "footnotes" of library data.",SWIB
,2011,Linked Data Light - link aggregation with BEACON,Jakob Voss,,,SWIB/SWIB2011/Linked Data Light - link aggregation with BEACON.md,"#beacon,#wikipedia,#linked/data,#swib/2011","One barrier to entry for providing and using links in the context of the Semantic Web is that the associated RDF technologies require some familiarization. For smaller institutions in particular, it is often tedious to first deal with technical aspects such as the configuration of web servers and triple stores if only a manageable number of links are to be published. The BEACON format developed as part of Wikipedia offers a simple alternative here. It should be shown how and where BEACON is already being used, when the use of BEACON makes sense and how links provided with BEACON can be adapted to other linked data applications.",SWIB
,2011,Linked data-based web services for economics,Joachim Neubert,,,SWIB/SWIB2011/Linked data-based web services for economics.md,"#autosuggest,#authority/data,#suggestion/services,#thesauri,#mappings,#rest-api,#api,#swib/2011","Web services with relatively simple programming interfaces offer an opportunity to integrate databases "on-the-fly" into your own applications with little effort. Such web services can be integrated in a Web 2.0 manner more easily than with linked data publications that follow "pure teaching" (RDF, SPARQL). This offers the libraries as a whole the opportunity to make their data - and in particular their terminology and authority data - reusable with low thresholds. An example for this are autosuggest services for personal names (and underlying identities), another suggestion services for retrieval vocabulary from thesauri, possibly enriched from mappings to other vocabularies. The technical focus - in our case on economics - also increases the relevance of the proposals. The article will describe a REST-oriented API on the one hand and the LOD-based infrastructure behind it on the other.",SWIB
,2011,Notes on Bibliographica,William Waites,,,SWIB/SWIB2011/Notes on Bibliographica.md,"#Bibliographica,#annotation,#relationships,#scholarly/works,#bibliographic/metadata,#science-mapping,#linked/data,#rdf-database,#rdf,#pylons,#project,#united-kingdom,#uk,#swib/2011","Bibliographica was conceived as a project to annotate the relationships between scholarly works and their authors so as to create a semantic map of the history and evolution of discourse in particular domains. The first step towards this was to collect a large amount of ground data, that is bibliographic metadata about the works and authors in question. To this end we have assisted in the publication of linked data version of the British National Bibliography as well as scientific publications from the medline database, some 23 million individual works in all. We have also investigated several strategies for publishing and working with this data, particularly the suitability of using RDF databases to underpin web application frameworks such as Pylons. This presentation gives an overview of our experiences in this endeavor.",SWIB
,2011,Ontology-driven scientific research with RODIN,"René Schneider,Fabio Ricci,Javier Belmonte",,,SWIB/SWIB2011/Ontology-driven scientific research with RODIN.md,"#rodin,#project,#research/project,#ontology,#skos,#france,#open-source,#swib/2011,#scientific/research","The RODIN (= ROUe D'INformation) project, which by definition is an application-oriented research project, aims to implement an alternative portal idea within the framework of E-lib.ch that allows user-defined searches in heterogeneous information sources. Ultimately, two search strategies are combined in RODIN: a simple but user-defined meta-search via widgets, and an ontology-driven advanced search, which is based on bibliographic and encyclopedic ontologies in the SKOS data model and builds on the results of the meta-search. RODIN sees itself as a tool for information specialists and advanced users in an academic context who need a differentiated and differentiating system for exploratory research that can serve as a complement to conventional search engines. After the end of the first project phase (end of 2011), RODIN will initially be available "out-of-the-box" as a general web portal in the form developed during the project period; the source code will be made available for download on an open source platform . Based on this, the software can be tailored to individual information portals ("customized version") and integrate those widgets and ontologies that are of interest for the respective research area on the websites of other portals.",SWIB
,2011,Pragmatic Linked Data at the University of Southampton,Christopher Gutteridge,,,SWIB/SWIB2011/Pragmatic Linked Data at the University of Southampton.md,"#eprints,#OpenOrgGrinder,#rdf,#XSLT,#ARC2,#PHP,#Graphite,#SPARQL,#4store,#swib/2011","The University of Southampton is at the forefront of work in the semantic web and has produced various open and linked data sites and tools over the years ( Blog ). Now it has embarked on a project to make large amounts of the organization's own data available as Linked Open Data, in a sustainable and useful way. Many parts of the University are involved including research, teaching, catering, finance, estates and transport. This has then been used to build a number of useful applications for the University staff, students and visitors. A very pragmatic approach has been taken, and rather than just publish the RDF, a website has been published over the top of the data which creates immediate value from data which was previously buried in spreadsheets. The focus has been on creating an agile, manageable and sustainable system rather than something perfect but brittle. The data comes from a mix of sources; various databases, 4 different EPrints repositories and a large number of google-docs spreadsheets, Example ). All the tools used to build the service are free open source software. We use a viral machine running Ubuntu Linux, store our data in 4-store. The smaller datasets are edited using Google Spreadsheets. We prepare our data using OpenOrgGrinder (created by us but open source) which converts spreadsheets into RDF, XSLT and rapper. To provide useful views of our data we use ARC2 PHP library, Graphite PHP Library (created by us) and Google Maps. The public SPARQL endpoint sits in front of the real endpoint and adds extra features not available from 4store.",SWIB
,2011,Pragmatische Ansätze für den Umgang mit 'Enhanced Publications' in existierenden Repository-Umgebungen,"Anouar Boulal,Martin Iordanidis,Jochen Schirrwagen",,,SWIB/SWIB2011/Pragmatische Ansätze für den Umgang mit 'Enhanced Publications' in existierenden Repository-Umgebungen.md,"#eco4r,#swib/2011,#DFG,#compound-objects,#long-term,#OAI-ORE,#enrichment,#metadata,#best-practice,#overlay-journal","In the DFG project eco4r "Exposing Compound Objects for Repositories" a concrete application scenario was implemented as a prototype. Complex publications are aggregated and visualized from the productive repository environments of the project partners (hbz NRW and Bielefeld University Library) in such a way that the distributed publications are compiled under new (e.g. subject-specific) criteria. A so-called overlay journal is created. In addition to the exchange of complex information units across system boundaries, aspects of long-term archiving are also considered. After a short introductory phase on the subject of complex information objects in repository environments, the focus is on practical applications. The participants are accompanied from the installation and configuration to the use of the most important modules developed in the project (OAI-ORE repository plugins for OPUS and Fedora, export interfaces, triple store, metadata enrichment, etc.). The preliminary workshop program is as follows"&#58;" Lectures on eco4r and project results, projects with similar objectives and an LTA concept for complex information objects; Hands On Sessions"&#58;" Practical demonstration of the Overlay Journal"&#58;" from a user's point of view, and installation, configuration and use of modules and components of the Overlay Journal Discussion of 'Best Practices' and presentation and summary of the workshop results",SWIB
,2011,Publishing and using loan data from libraries as Linked Open Data,Magnus Pfeffer,,,SWIB/SWIB2011/Publishing and using loan data from libraries as Linked Open Data.md,"#project,#germany,#library-lending,#vocabulary,#user-behavior,#lending,#mannheim,#swib/2011","In an ongoing project, I am investigating possible use cases for lending data from library systems as linked data together with Kai Eckert from the UB Mannheim and students at the Hochschule der Medien. The first scenario is the statistical comparison of (partial) libraries. Here, the description of the libraries, their inventory and the lending conditions must be modeled as a vocabulary. This vocabulary and its semantics must be based on the existing standards and recommendations for the statistical comparison of libraries and should in any case also allow the mapping of the DBS. The second scenario is the aggregation of loan information at the title level to analyze user behavior. As an application, an alternative ranking for retrieval is in the foreground, which is based on the popularity of the title. Basically, with this type of data, an application for the optimization of one's own inventory and the structure of the inventory would also be conceivable, which would then be completely independent of the library software used and a specific data warehouse solution. The challenge in modeling the second scenario is the various conceivable granularities in which the data is processed. This makes it possible to model and describe each individual lending process. Almost all information recorded in the library system would be retained. However, for retrieval use cases, a coarser mapping that aggregates the data at title level would be desirable. The data models for the mentioned scenarios and an example depiction of real data from the library system of the UB Mannheim are currently being developed. We will make the modeling and the real data available on Mannheim University Library's Linked Data Service over the course of the next few months .",SWIB
,2011,RDF-Daten in eigenen Anwendungen nutzen,Jakob Voß,,,SWIB/SWIB2011/RDF-Daten in eigenen Anwendungen nutzen.md,"#swib/2011,#rdf,#workshop","In recent years, the provision of information as Linked Open Data in RDF has steadily increased. Nevertheless, the question of the benefit of the provision often cannot be answered convincingly. It is doubtful that this will happen with a "killer application" that impressively demonstrates the further development of the World Wide Web. Instead, you can already develop your own applications that use RDF and Linked Open Data with manageable effort, without focusing on these technologies as an end in themselves. The workshop aims to show the way from the idea to your own application based on existing RDF data. The focus is less on merging and evaluating large amounts of data ("Big Data") and more on small, specialized applications ("Long Tail"), such as are regularly required in libraries and other institutions. The workshop is primarily aimed at developers and other interested parties with rudimentary programming skills and/or knowledge of HTML/CSS. With the help of a framework developed at the GBV network center for the simple development of RDF-based web applications, the participants should be able at the end of the workshop to develop their own applications that combine RDF data from different sources and present them prepared for end users . Together we will discuss which hurdles have to be overcome and what opportunities there are for further development. The practical exercises will take place in small teams.",SWIB
,2011,The High and Lows of Library Linked Data,Adrian Stevenson,,,SWIB/SWIB2011/The High and Lows of Library Linked Data.md,"#uk,#united-kingdom,#jisc,#locah,#project,#linked-data,#archival-metadata,#repositories,#library-catalog,#uri-patterns,#enriching,#opne-licenses,#swib/2011","This session will explore the progress of the UK JISC-funded LOCAH Project: Linked Open Copac and Archives Hub . The project is making records from the Archives Hub service and Copac service available as Linked Data. The Archives Hub is an aggregation of archival metadata from repositories across the UK; Copac provides access to the merged library catalogs of libraries throughout the UK, including all national libraries. In each case the aim is to provide Linked Data, so that we make our data interconnected with other data sets. The presentation will cover aspects of data modelling, the selection of vocabularies and the design of URI patterns. It will examine options for enriching the data, to provide links to other datasets. A prototype visualization will be shown, demonstrating how Linked Data can enable researchers to interrogate data in different ways. The presentation will conclude with a look at some of the main opportunities and barriers to the creation and use of Linked Data. The presentation will address a number of the questions posed by SWIB, including: how to produce useful links to and between newly published datasets; where to find LOD applications which show the added value created by linking assets; the value of open licenses to LOD-based infrastructures.",SWIB
,2011,The LODUM Project: Transparent Research Based on Linked Library Data,"Carsten Kessler,Tomi Kauppinen,Umut Tas",,,SWIB/SWIB2011/The LODUM Project - Transparent Research Based on Linked Library Data.md,"#Münster,#germany,#project,#research-results,#research/results,#research/data,#reproducible-research,#bibliographic/data,#cloud-environments,#cloud,#swib/2011","The Linked Open Data University of Münster (LODUM) project aims to improve the visibility and transparency of the university using Semantic Web technologies. The main goal is to improve the accessibility of research results (publications, research data, models, methods and software) to ensure transparent and reproducible research. This linked science approach relies on an improved exchange of results both within and between the various disciplines. The publication, as the predominant way of documenting research results, still plays a central role. LODUM not only uses Linked Data as a new metadata standard for bibliographic data, but also strives to link the publication with all relevant data and models. By providing the data and models in dereferenceable, machine-readable form, it should be possible to trace research results in cloud environments in the future.",SWIB
,2011,The Open Citation Corpus and the SPAR Ontologies,David Shotton,,,SWIB/SWIB2011/The Open Citation Corpus and the SPAR Ontologies.md,"#Open-Citations-Corpus,#PubMed-Central,#biomedical,#open-access,#bibliographic/records,#citations,#spar,#ontology,#open-citation-blog,#open-citation-project,#swib/2011","The Open Citations Corpus is a database of approx. 6.3 million biomedical literature citations harvested from the reference lists of all open access articles in PubMed Central. These contain references to approx. 3.4 million papers, which represent ~20% of all PubMed-listed papers published between 1950 and 2010, including all the most highly cited papers in every biomedical field. The Open Citations Corpus web site allows you to browse these bibliographic records and citations, to select an individual article, and to visualize its citation network in a variety of displays. Details of each selected reference, and the data and diagrams for its citation network, may be downloaded in a variety of formats, while the entire Open Citations Corpus can be downloaded in several formats including RDF and BibJSON.CiTO , FaBiO and other SPAR (Semantic Publishing and Referencing) ontology. Ontologies have been used to encode this information in RDF, after parsing the National Library of Medicine DTD XML obtained from PubMed Central, and after undertaking considerable work to remove the errors that exist in approximately 1% of the literature references. Further information about the Open Citation Corpus, the data processing, and the JISC Open Citations Project that supported this work, is given on the Open Citations Blog.",SWIB
,2011,Tipping the Sacred Cow: Thinking Beyond the Journal System,Herbert van de Sompel,,,SWIB/SWIB2011/Tipping the Sacred Cow - Thinking Beyond the Journal System.md,"#scholarly/communication,#beyond-the-pdf,#electronic-journals,#swib/2011","More than a decade after the emergence of electronic journals, the web-based scholarly communication system still strongly resembles its paper-based predecessor. The growing frustration with this status quo is illustrated by three prominent events in 2011 alone aimed at bringing together thought leaders to reflect on an improved scholarly communication system that better leverages the technical and social capabilities offered by the networked environment: the Beyond the PDF meeting , the Dagstuhl Workshop on the Future of Research Communication , and the Microsoft Research Transforming Scholarly Communication Workshop. Meanwhile, glimpses of eminent changes can already be observed, including the emergence of a machine-actionable layer of scholarly communication in which semantic technologies play a significant role and the growing interest in "papers" that are more tightly integrated in the scholarly process and environment . Examples of these changes can mostly be characterized as experimental, and their eventual deployment may still take years. Meanwhile, there remain plenty of opportunities to introduce straightforward improvements aimed at better aligning scholarly communication with established web practices.",SWIB
,2011,What needs to happen in a scholarly publishing reform?,Bjorn Brembs,,,SWIB/SWIB2011/What needs to happen in a scholarly publishing reform?.md,"#scholarly/publishing,#open-access,#digital-library,#swib/2011","Scholarly publishing is fundamentally broken at essentially all levels starting with basic functionality and ranging to access, incentives, attribution, archiving, share/re-use and cost/benefit. What could be the feasible alternatives which would move scholarly publishing closer to a modern, IT-based system? A system which assists scientists in sorting, filtering and discovering relevant scientific findings? Which provides open access to tax-payer-funded research at a reasonable price? Which provides an incentive structure with an attribution system that benefits science and scientists rather than publishers and bureaucrats? I will argue that a natural candidate for developing such a system is the one institution on this planet which has centuries of experience in archiving and making accessible the literature and data of scientists. In addition to centuries of experience, many libraries in our digital age lack a sense of purpose or direction because of it. Creating a world-wide, peer-reviewed, open access, federated digital library of science is exactly the kind of task any modern university library should dream of taking part in. This digital utopia is exactly what scientists today are in desperate need of and libraries would be able to deliver.",SWIB
,2011,culturegraph.org - building a hub for Linked Library Data,"Markus Geipel,Adrian Pohl",,,SWIB/SWIB2011/culturegraph.org - building a hub for Linked Library Data.md,"#culturegraph,#linked/open/data,#DNB,#hbz,#bibliography,#heterogeneity,#identifiers,#swib/2011,#metadata,#metadata/comparison","Culturegraph.org is a linked open data service whose objective is the uniform, reliable and persistent referencing of cultural products. The service is currently being set up in cooperation with the German National Library (DNB - OAI interface) and the University Library Center of the State of North Rhine-Westphalia (hbz) with the support of the Association of Network Systems. The databases of publishers, libraries and library associations are increasingly opening up to the Linked Open Data concept. In addition to the advantages and perspectives that this development brings with it, the heterogeneity of the descriptions and identifiers used is also growing. Another challenge is recognizing records that describe the same resources, since there is a large overlap in the catalogs - especially for bibliographic resources. Finally, authority data is also gaining in importance, especially when it is linked to other data sources. Culturegraph.org addresses these challenges. As an open service platform, Culturegraph.org should offer the possibility of comparing metadata and calculating equivalences. The results are freely available according to the linked open data standards. In further expansion stages, authority data will be added and linked to other data sources relevant to cultural institutions.",SWIB