"id","PY","TI","AB","AU","CT","url","KW"
"00a5718a5fc64467a388ba5e7bd9bff2",2014,"Using Open Source Tools to Create a Mobile Optimized,Crowdsourced Translation Tool","In late 2012, OSU Libraries and Press partnered with Maria's Libraries, an NGO in Rural Kenya, to provide users the ability to crowdsource translations of folk tales and existing children's books into a variety of African languages, sub-languages, and dialects. Together, these two organizations have been creating a mobile optimized platform using open source libraries such as Wink Toolkit (a library which provides mobile-friendly interaction from a website) and Globalize3 to allow for multiple translations of database entries in a Ruby on Rails application. Research regarding successes of similar tools has been utilized in providing a consistent user interface. The OSU Libraries & Press team delivered a proof-of-concept tool that has the opportunity to promote technology exploration, improve early childhood literacy, change the way we approach foreign language learning, and to provide opportunities for cost-effective, multi-language publishing.","Weinraub Lajoie,Evviva;Terrell,Trey;McEvoy,Susan;Kaplan,Eva;Schwartz,Ariel;Ajambo,Esther","Code4Lib","http://journal.code4lib.org/articles/9496","kenya;Ryby;OSU;children literacy;proof-of-concept"
"0100dc2bcbc941f4aed31754b6f34003",2014,"The Road to Responsive: University of Toronto Libraries’ Journey to a New Library Catalogue Interface","With the recent surge in the mobile device market and an ever expanding patron base with increasingly divergent levels of technical ability, the University of Toronto Libraries embarked on the development of a new catalogue discovery layer to fit the needs of its diverse users. The result: a mobile-friendly, flexible and intuitive web application that brings the full power of a faceted library catalogue to users without compromising quality or performance, employing Responsive Web Design principles.","Gayhart,Lisa;Khalid,Bilal;Belray,Gordon","Code4Lib","http://journal.code4lib.org/articles/9195","faceted library catalogue;mobile devices;Toronto;responsive web design"
"029bc3f2e8684a1faf6be0c6e22d1850",2022,"Automated 3D Printing in Libraries","This article highlights the creation of an automated 3D printed system created at a health sciences library at a large research university. As COVID-19 limited in-person interaction with 3D printers, a group of library staff came together to code a form that took users’ 3D printed files and connected them to machines automatically. A ticketing system and payment form was also automated via this system. The only in-person interactions are dedicated staff members that unload the prints. This article will describe the journey in getting to an automated system and share code and strategies so others can try it for themselves.","Patterson,Brandon;Engel,Ben;Holle,Willis","Code4Lib","https://journal.code4lib.org/articles/16310","3D;COVID-19;prints"
"02fb0892eb0b434080bef8b520d4bc3a",2013,"Editorial Introduction: It is Volunteers All the Way Down...","The Code4Lib community is wonderful and a wonder, as numerous conference keynote speakers and journal editors have noted.It started first as a mailing list then quickly branched out to an IRC channel, a website and wiki, an annual meeting with regional and international flair, this Journal, and countless other opportunities to network, share ideas, and build on the work of each other.As an active participant in the community, what I find even more fascinating is the sense of dedication that other like-minded people have for the community.I can imagine that this is due in some part because their employer has an enlightened sense of the importance of community participation to give staff release time to engage in Code4Lib activities.In other cases, the participants themselves cherish something of value and squirrel away unofficial time (perhaps evening hours, perhaps daytime activity under the broad heading of “professional development”) to use in community activities.Some have donated server space, others funds towards a domain registration.A few years back we had a professional graphics designer volunteer time to create the Code4Lib logo and style guide.","Murray,Peter","Code4Lib","http://journal.code4lib.org/articles/8441","Code4Lib;Peter Murray;editorial"
"0361e7c944b243e89abf60dd31a01c57",2023,"Apples to Oranges: Using Python and the pymarc library to match bookstore ISBNs to locally held eBook ISBNs","To alleviate financial burdens faced by students and to provide additional avenues for the benefits shown to be present when no-cost materials are available to students (equity and access and an increase in student success metrics), more and more libraries are leveraging their collections and acquisition processes to provide no-cost eBook alternatives to students. It is common practice now for academic libraries to have a partnership with their campus bookstore and to receive a list of print and eBook materials required for an upcoming semester. Libraries take these lists and use various processes and workflows, some extremely labor intensive and others semi-labor intensive, to identify which of these titles they already own as unlimited access eBooks, and which titles could be purchased as unlimited access eBooks. The most common way to match bookstore titles to already licensed eBooks is by searching the bookstore provided ISBN or title in either the Library Management System (LMS), the Analytics and Reporting layer of the LMS, the Library Discovery Layer, or via another homegrown process.While some searching could potentially be automated, depending on the available functionality of the LMS or the Analytics component of the LMS, the difficulty lies in matching the bookstore ISBN, often the print ISBN, to the library eBook ISBN. This article will discuss the use of Python, the Pymarc library in Python, and Library eBook MARC records to create an automated identification process to accurately match bookstore lists to library eBook holdings.","Scott,Mitchell","Code4Lib","https://journal.code4lib.org/articles/17126","LMS;eBooks;LMS;Python;MARC;Pymarc"
"03984f4359064dda908311e2f9bed30a",2014,"Editorial Introduction: Conscious Resolutions","Hack your life with 10 New Year's resolutions from Code4Lib Journal.","Averkamp,Shawn","Code4Lib","http://journal.code4lib.org/articles/9389","editorial;10 years;Code4Lib"
"03fc7f10756f47c584b6747317b9c19d",2021,"Choose Your Own Educational Resource: Developing an Interactive OER Using the Ink Scripting Language","Learning games are games created with the purpose of educating, as well as entertaining, players. This article describes the potential of interactive fiction (IF), a type of text-based game, to serve as learning games. After summarizing the basic concepts of interactive fiction and learning games, the article describes common interactive fiction programming languages and tools, including Ink, a simple markup language that can be used to create choice based text games that play in a web browser. The final section of the article includes code putting the concepts of Ink, interactive fiction, and learning games into action using part of an interactive OER created by the author in December of 2020.","Baker,Stewart","Code4Lib","https://journal.code4lib.org/articles/15721","games;interactive fiction;OER"
"046cf75c118d46f5ab991b15fbd8cab1",2021,"Building and Maintaining Metadata Aggregation Workflows Using Apache Airflow","PA Digital is a Pennsylvania network that serves as the state’s service hub for the Digital Public Library of America (DPLA). The group developed a homegrown aggregation system in 2014, used to harvest digital collection records from contributing institutions, validate and transform their metadata, and deliver aggregated records to the DPLA. Since our initial launch, PA Digital has expanded significantly, harvesting from an increasing number of contributors with a variety of repository systems. With each new system, our highly customized aggregator software became more complex and difficult to maintain. By 2018, PA Digital staff had determined that a new solution was needed. From 2019 to 2021, a cross-functional team implemented a more flexible and scalable approach to metadata aggregation for PA Digital, using Apache Airflow for workflow management and Solr/Blacklight for internal metadata review. In this article, we will outline how we use this group of applications and the new workflows adopted, which afford our metadata specialists more autonomy to contribute directly to the ongoing development of the aggregator. We will discuss how this work fits into our broader sustainability planning as a network and how the team leveraged shared expertise to build a more stable approach to maintenance.","Finnigan,Leanne;Toner,Emily","Code4Lib","https://journal.code4lib.org/articles/16171","DPLA;aggregation systemApache Airflow;Solr;Blacklight;metadata review; metadata"
"04ddf651e59f46638c481164a7898cec",2018,"Using R and the Tidyverse to Generate Library Usage Reports","Gathering, analyzing, and communicating library usage data provides a foundation for thoughtful assessment. However, the amount of time and expertise required creates a barrier to actually using this data. By using the statistical programming language R and the tools and approach of the Tidyverse, the process of gathering, analyzing, and communicating data can be automated in ways that reduce the amount of time and energy required. At the same time, this approach increases staff capacity for other data science projects and creates a shareable model and framework for other libraries. This article focuses on electronic resource usage reports - especially Counter DB1 Reports - but this approach could be extended to other data sources and needs.","Meyer,Andy","Code4Lib","http://journal.code4lib.org/articles/13282","statistics;R;Tydyverse;data;usage reports;Counter DB1"
"05475b9b5f364b298554debe338190a1",2010,"Easing Gently into OpenSRF, Part 2","The Open Service Request Framework (or OpenSRF, pronounced ""open surf"") is an inter-application message passing architecture built on XMPP (aka ""jabber""). The Evergreen open source library system is built on an OpenSRF architecture to support loosely coupled individual components communicating over an OpenSRF messaging bus. This article introduces OpenSRF, demonstrates how to build OpenSRF services through simple code examples, explains the technical foundations on which OpenSRF is built, and evaluates OpenSRF's value in the context of Evergreen. Part 2 of a 2 part article in this issue.","Scott,Dan","Code4Lib","http://journal.code4lib.org/articles/3365","OpenSRF;XMPP;jabber;Evergreen"
"05ab495577904b9abef3ad1807cced90",2008,"OpenBook WordPress Plugin: Open Source Access to Bibliographic Data","OpenBook is a WordPress PHP plugin that implements the Open Library APIs to insert book covers, titles, authors and publishers into web pages. The motive behind the development was to provide an easy alternative to the common practice of linking to Amazon. Open Library was selected as a data source because it is both open source and open data.The plugin is useful for book reviewers, library webmasters, anyone who wants to put book covers and data on their WordPress blog or website. The plugin also allows users to add links to publisher websites, a feature that was considered significant to independent publishers.","Miedema,John","Code4Lib","http://journal.code4lib.org/articles/105","book review resources;WordPress;WordPress plugins;API"
"05cd8486982e405bb507988143efed1a",2014,"Archiving the Web: A Case Study from the University of Victoria","The University of Victoria Libraries started archiving websites in 2013, and it quickly became apparent that many scholarly websites being produced by faculty, especially in the digital humanities, were going to prove very challenging to effectively capture and play back. This article will provide an overview of web archiving and explore the considerable legal and technical challenges of implementing a web archiving initiative at a research library, using the University of Victoria's implementation of Archive-it, a web archiving service from the Internet Archive, as a case study, with a special focus on capturing complex, interactive websites that scholars are creating to disseminate their research in new ways.","Davis,Corey","Code4Lib","http://journal.code4lib.org/articles/10015","digital humanities;Archive-it;web archiving;Victoria"
"064d368e3a194eed9238e3231025e7c6",2018,"The Automagic of the LII’s eCFR","The Legal Information Institute (LII) began providing access to federal legal materials in 1992.This article discusses their work expanding and improving free public access to federal legal resources in the U.S., particularly developingtheir eCFR product for the Code of Federal Regulations, and plans to integrate DocketWrench.","Schneider,Charlotte;Kwakye,Sylvia","Code4Lib","http://journal.code4lib.org/articles/13241","legal;eCFR;DocketWrench"
"0674dd8a826745c4b9ad0c9e7039abee",2019,"MatchMarc: A Google Sheets Add-on that uses the WorldCat Search API","Lehigh University Libraries has developed a new tool for querying WorldCat using the WorldCat Search API.  The tool is a Google Sheet Add-on and is available now via the Google Sheets Add-ons menu under the name “MatchMarc.” The add-on is easily customizable, with no knowledge of coding needed. The tool will return a single “best” OCLC record number, and its bibliographic information for a given ISBN or LCCN, allowing the user to set up and define “best.” Because all of the information, the input, the criteria, and the results exist in the Google Sheets environment, efficient workflows can be developed from this flexible starting point. This article will discuss the development of the add-on, how it works, and future plans for development.","Suranofsky,Michelle;McColl,Lisa","Code4Lib","https://journal.code4lib.org/articles/14813","API;Lehigh;WorldCat;Google Sheets;MatchMarc;ISBN;LCCN;add-on"
"06aefb86d20f4a5ca4ba3f0c03d53b9d",2011,"Editorial Introduction: Prioritizing the Future, Collaborating in the Present, and Archiving the Past","This is an exciting time for libraries and technology, and libraries have the opportunity now to build strong collaborations that both preserves our rich history and prioritizes our future. This issue shines a light on a unique blending of priorities old and new, detailed analysis of our past, and creative solutions that enhance the mission of libraries. Libraries big and small have the chance to impact our communities for the better. Come along, it's going to be a great ride.","M. McGeary,Timothy","Code4Lib","http://journal.code4lib.org/articles/5732","editorial;priorities;libraries"
"089c052c6fab48ae8b5003f45af4c1be",2019,"Developing Weeding Protocols for Born Digital Collections","As collections continue to be digitized and even be born digital, the way we handle collection development needs to also shift towards a digital mindset. Digital collections development are not so much concerned about shelf or storage space, as expansion can be as simple as procuring a new hard drive. Digital collections, when not archival, need to focus on issues of access and accessibility. For a born digital library, quality and usefulness must be the primary factors in the collection development policy.This article will walk through the steps taken by one digital library (PBSLearningMedia.org) to assess their collections with an eye to quality and user experience as well as a multi-phase deaccessioning project that occurred and is ongoing. The process, including the multi-iteration drafting of subject specific rubrics, targeted to the needs of the site’s core audience. It also included the quantitative assessment of thousands of items in the collection and the distribution of qualitative and quantitative data to stakeholders across the country. Special attention to the setting of minimal required standards and the communication of those standards was paid. Finally, as this process is now an ongoing review schema for LearningMedia, the article will discuss the issues faced in this project, recommendations for other organizations attempting their own digital weeding/deaccessioning projects, and the plans for the future of the project.","Livanos-Propst,Athina","Code4Lib","https://journal.code4lib.org/articles/14162","PBSLearningMedia;assessment;LearningMedia;digitl weeding;deaccessioning"
"08f6693254f4404ab694a3508b92c728",2015,"Using Google Tag Manager and Google Analytics to track DSpace metadata fields as custom dimensions","DSpace can be problematic for those interested in tracking download and pageview statistics granularly. Some libraries have implemented code to track events on websites and some have experimented with using Google Tag Manager to automate event tagging in DSpace. While these approaches make it possible to track download statistics, granular details such as authors, content types, titles, advisors, and other fields for which metadata exist are generally not tracked in DSpace or Google Analytics without coding. Moreover, it can be time consuming to track and assess pageview data and relate that data back to particular metadata fields. This article will detail the learning process of incorporating custom dimensions for tracking these detailed fields including trial and error attempts to use the data import function manually in Google Analytics, to automate the data import using Google APIs, and finally to automate the collection of dimension data in Google Tag Manager by mimicking SEO practices for capturing meta tags. This specific case study refers to using Google Tag Manager and Google Analytics with DSpace; however, this method may also be applied to other types of websites or systems.","Conrad,Suzanna","Code4Lib","http://journal.code4lib.org/articles/10311","API;Dspace;event tagging;Google Tag Manager;Google Analytics;Google APIs"
"0905f30dacb84b2bb53bd8cc1e942aec",2021,"Managing an institutional repository workflow with GitLab and a folder-based deposit system","Institutional Repositories (IR) exist in a variety of configurations and in various states of development across the country. Each organization with an IR has a workflow that can range from explicitly documented and codified sets of software and human workflows, to ad hoc assortments of methods for working with faculty to acquire, process and load items into a repository. The University of North Texas (UNT) Libraries has managed an IR called UNT Scholarly Works for the past decade but has until recently relied on ad hoc workflows. Over the past six months, we have worked to improve our processes in a way that is extensible and flexible while also providing a clear workflow for our staff to process submitted and harvested content. Our approach makes use of GitLab and its associated tools to track and communicate priorities for a multi-user team processing resources. We paired this Web-based management with a folder-based system for moving the deposited resources through a sequential set of processes that are necessary to describe, upload, and preserve the resource. This strategy can be used in a number of different applications and can serve as a set of building blocks that can be configured in different ways. This article will discuss which components of GitLab are used together as tools for tracking deposits from faculty as they move through different steps in the workflow. Likewise, the folder-based workflow queue will be presented and described as implemented at UNT, and examples for how we have used it in different situations will be presented.","R. Johnson-Freeman,Whitney;E. Phillips,Mark;K. Phillips,Kristy","Code4Lib","https://journal.code4lib.org/articles/15650","institutional repositories;North Texas;UNT;GitLab;tracking deposits"
"09a71d6a4c484806b5a3b9ce44063a04",2012,"From the Catalog to the Book on the Shelf: Building a Mapping Application for Vufind","At Yale University Library (YUL), recorded reference transactions revealed that after finding a book in the catalog patrons had difficulty knowing how to use the call number to find the book on the shelf. The Library created a mobile service to help locate the call number in the library stacks. From any call number of a book in Sterling Memorial Library at YUL, a map will be displayed which highlights that call number’s general area on a floor in the stacks. YUL introduced the mapping application in Yufind, a catalog in place at Yale since 2008 which is based on Vufind.","Bauer,Kathleen;Friscia,Michael;Matheson,Scott","Code4Lib","http://journal.code4lib.org/articles/6924","Yale;call numbers;YUL;Yufind;Vufind"
"0a44a01231814af28ec956de0be47289",2020,"Trust, But Verify: Auditing Vendor-Supplied Accessibility Claims","Despite a long-overdue push to improve the accessibility of our libraries’ online presences, much of what we offer to our patrons comes from third party vendors: discovery layers, OPACs, subscription databases, and so on. We can’t directly affect the accessibility of the content on these platforms, but rely on vendors to design and test their systems and report on their accessibility through Voluntary Product Accessibility Templates (VPATS). But VPATs are self-reported. What if we want to verify our vendors’ claims? We can’t thoroughly test the accessibility of hundreds of vendor systems, can we? In this paper, we propose a simple methodology for spot-checking VPATs. Since most websites struggle with the same accessibility issues, spot checking particular success criteria in a library vendor VPAT can tip us off to whether the VPAT as a whole can be trusted. Our methodology combines automated and manual checking, and can be done without any expensive software or complex training. What’s more, we are creating a repository to share VPAT audit results with others, so that we needn’t all audit the VPATs of all our systems.","Reidsma,Matthew;Zavala,Melina","Code4Lib","https://journal.code4lib.org/articles/15122","OPAC;VPATs;accessibility;subscription databases"
"0ae9ce2a52164f47824619d94d2fc4b3",2013,"Out From Behind the Firewall: Towards Better Library IT Communications","Traditionally, IT departments lack a strong focus on communications and promotions. Numerous exciting projects and services are created by library IT departments and web development teams daily, but resources for promotion are typically unavailable or deemed low priority. This article examines IT-specific communications within the library context, offers a model of user-focused communications useful to libraries of any size, and discusses University of Toronto Libraries' Information Technology Services department’s efforts to increase library technology communications.","Gayhart,Lisa","Code4Lib","http://journal.code4lib.org/articles/8741","IT departments;communication;Toronto;"
"0b2b66814250468e981b08d8c6f90cbc",2012,"Editorial Introduction","The winter months bring us festivities like Mardi Gras. Here at the Code4Lib Journal, we present you with a veritable feast to indulge in as our mid-winter festival offering. Consume slowly, to fully appreciate the myriad flavors and enjoy the richness of the fare.","Bean,Carol","Code4Lib","http://journal.code4lib.org/articles/6616","Mardi Grass;editorial"
"0b367d774f174efa89c554b1f04826ef",2017,"The FachRef-Assistant: Personalised, subject specific, and transparent stock management","We present in this paper a personalized web application for the weeding of printed resources: the FachRef-Assistant. It offers an extensive range of tools for evidence based stock management, based on the thorough analysis of usage statistics. Special attention is paid to the criteria individualization, transparency of the parameters used, and generic functions. Currently, it is designed to work with the Aleph-System from ExLibris, but efforts were spent to keep the application as generic as possible. For example, all procedures specific to the local library system have been collected in one Java package. The inclusion of library specific properties such as collections and systematics has been designed to be highly generic as well by mapping the individual entries onto an in-memory database. Hence simple adaption of the package and the mappings would render the FachRef-Assistant compatible to other library systems. The personalization of the application allows for the inclusion of subject specific usage properties as well as of variations between different collections within one subject area. The parameter sets used to analyse the stock and to prepare weeding and purchase proposal lists are included in the output XML-files to facilitate a high degree of transparency, objectivity and reproducibility.","T. Spielberg,Eike;Lützenkirchen,Frank","Code4Lib","http://journal.code4lib.org/articles/12660","FachRef-Assistant;weeding;Aleph;ExLibris;Java;XML;usage properties;purchase proposal lists"
"0bc3d028b89e4eb2b3152d2b34d3682c",2010,"Metadata In, Library Out. A Simple, Robust Digital Library System","Tired of being held hostage to expensive systems that did not meet our needs, the University of Alabama Libraries developed an XML schema-agnostic, light-weight digital library delivery system based on the principles of ""Keep It Simple, Stupid!"" Metadata and derivatives reside in openly accessible web directories, which support the development of web agents and new usability software, as well as modification and complete retrieval at any time. The file name structure is echoed in the file system structure, enabling the delivery software to make inferences about relationships, sequencing, and complex object structure without having to encapsulate files in complex metadata schemas. The web delivery system, Acumen, is built of PHP, JSON, JavaScript and HTML5, using MySQL to support fielded searching. Recognizing that spreadsheets are more user-friendly than XML, an accompanying widget, Archivists Utility, transforms spreadsheets into MODS based on rules selected by the user. Acumen, Archivists Utility, and all supporting software scripts will be made available as open source.","Loewald,Tonio;DeRidder,Jody","Code4Lib","http://journal.code4lib.org/articles/3107","Alabama;XML;metadata;Acumen;system"
"0c56d0b114544a6ebcded51418f9c60e",2018,"Improving Enterprise Content Findability through Strategic Intervention","This paper highlights work that information specialists within the Jet Propulsion Laboratory have done to strategically intervene in the creation and maintenance of JPL’s intranet. Three key interventions are discussed which best highlight how work in enterprise ""knowledge curation” fits into emergent knowledge management roles for institutional librarians (Lustigman, 2015). These three interventions are: 1) guided document creation, which includes the development of wiki portals and standard editing processes for consistent knowledge capture, 2) search curation, which includes manual and organic enterprise search relevancy improvements, and 3) index as intervention, which describes how metadata mapping and information modeling are used to improve access to content for both local and enterprise-wide applications.","Townsend,Rebecca;Mathieu,Camille","Code4Lib","https://journal.code4lib.org/articles/13877","Jet Propulsion Laboratory;JPL;knowledge curation;document creation;seach curation;indexing;metadata mapping"
"0c668438777c4b259da98e3adc928e7a",2010,"CONFERENCE REPORT: Code4Lib 2010","Conference reports from the 5th Code4Lib Conference, held in Asheville, NC, from February 22 to 25, 2010. The Code4Lib conference is a collective volunteer effort of the Code4Lib community of library technologists. Included are three brief reports on the conference from the recipients of conference scholarships.","Ho,Birong;Lakshminarayanan,Banurekha;Meireles,Vanessa","Code4Lib","http://journal.code4lib.org/articles/2717","c4l10;code4lib;report"
"0ce5853f2f2c47f198f534db6fc9d160",2013,"For Video Streaming/Delivery: Is HTML5 the Real Fix?","The general movement towards streaming or playing videos on the web has grown exponentially in the last decade. The combination of new streaming technologies and faster Internet connections continue to provide enhanced and robust user experience for video content. For many organizations, adding videos on their websites has transitioned from a “cool” feature to a mission critical service. Some of the benefits in putting videos online include: to engage and convert visitors, to raise awareness or drive interest, to share inspirational stories or recent unique events, etc. Along with the growth in the use and need for video content on the web; delivering videos online also remains a messy activity for developers and web teams. Examples of existing challenges include creating more accessible videos with captions and delivering content (using adaptive streaming) for the diverse range of mobile and tablet devices. In this article, we report on the decision-making and early results in using the Kaltura video platform in two popular library platforms: CONTENTdm and DSpace.","Millard,John;Tzoc,Elías","Code4Lib","http://journal.code4lib.org/articles/9059","CONTENTdm;Dspace;streaming;video;Kaltura"
"0d09619f1e144d49bfbf6f9edc5f36eb",2015,"Exploring Information Security and Shared Encrypted Spaces in Libraries","Libraries are sensitive to the need to protect patron data, but may not take measures to protect the data of the library.However, in an increasingly collaborative online environment, the protection of data is a concern that merits attention.As a follow-up to a new patron privacy policy, the Oakland University William Beaumont Medical Library evaluated information security tools for use in day-to-day operations in an attempt to identify ways to protect private information in communication and shared storage, as well as a means to manage passwords in a collaborative team environment.This article provides an overview of encryption measures, outlines the Medical Library’s evaluation of encryption tools, and reflects on the benefits and challenges in their adoption and use.","Engwall,Keith","Code4Lib","http://journal.code4lib.org/articles/10685","patron data;oakland;medical;privacy;encryption"
"0f1d3d35784f4621958a4cd08b0dfa7d",2009,"Semi-automatic Citation Correction with Lemon8-XML","The Lemon8-XML software application, developed by the Public Knowledge Project (PKP), provides an open-source, computer-assisted interface for reliable citation structuring and validation. Lemon8-XML combines citation parsing algorithms with freely-available online indexes such as PubMed, WorldCat, and OAIster. Fully-automated markup of entire bibliographies may be a genuine possibility using this approach. Automated markup of citations would increase bibliographic accuracy while reducing copyediting demands.","Suhonos,MJ","Code4Lib","http://journal.code4lib.org/articles/1011","Lemon8-XML;PKP;indexes;automated markup;bibliographies;citations;accuracy"
"0f1fb3e89586495b86f1aed49614c827",2016,"An Open-Source Strategy for Documenting Events: The Case Study of the 42nd Canadian Federal Election on Twitter","This article examines the tools, approaches, collaboration, and findings of the Web Archives for Historical Research Group around the capture and analysis of about 4 million tweets during the 2015 Canadian Federal Election. We hope that national libraries and other heritage institutions will find our model useful as they consider how to capture, preserve, and analyze ongoing events using Twitter. While Twitter is not a representative sample of broader society - Pew research shows in their study of US users that it skews young, college-educated, and affluent (above $50,000 household income) – Twitter still represents an exponential increase in the amount of information generated, retained, and preserved from 'everyday' people. Therefore, when historians study the 2015 federal election, Twitter will be a prime source.On August 3, 2015, the team initiated both a Search API and Stream API collection with twarc, a tool developed by Ed Summers, using the hashtag #elxn42. The hashtag referred to the election being Canada's 42nd general federal election (hence 'election 42' or elxn42). Data collection ceased on November 5, 2015, the day after Justin Trudeau was sworn in as the 42nd Prime Minister of Canada. We collected for a total of 102 days, 13 hours and 50 minutes. To analyze the data set, we took advantage of a number of command line tools, utilities that are available within twarc, twarc-report, and jq. In accordance with the Twitter Developer Agreement & Policy, and after ethical deliberations discussed below, we made the tweet IDs and other derivative data available in a data repository. This allows other people to use our dataset, cite our dataset, and enhance their own research projects by drawing on #elxn42 tweets. Our analytics included: breaking tweet text down by day to track change over time; client analysis, allowing us to see how the scale of mobile devices affected medium interactions; URL analysis, comparing both to Archive-It collections and the Wayback Availability API to add to our understanding of crawl completeness; and image analysis, using an archive of extracted images. Our article introduces our collecting work, ethical considerations, the analysis we have done, and provides a framework for other collecting institutions to do similar work with our off-the-shelf open-source tools. We conclude by ruminating about connecting Twitter archiving with a broader web archiving strategy.","Ruest,Nick;Milligan,Ian","Code4Lib","http://journal.code4lib.org/articles/11358","API;Canada;Canadian Federal Election;Twitter;Search API;data;jq;URL analysis;Wayback Machine;web archiving"
"0f3cc265c0614b80a29a087e2e78a1ca",2008,"Editorial Introduction - Issue 3","Code4Lib Journal seeks to share ideas for solving issues and, hopefully, inspire new ideas.","Peterson,Ron","Code4Lib","http://journal.code4lib.org/articles/104","editorial"
"0f540a880f614cbaa654f7f1ed75450a",2013,"SPRUCE Mashup London","SPRUCE digital preservation mashups are a series of unique events that are being organized in the United Kingdom to bring together digital preservation practitioners and developers to work on real-world digital preservation challenges. During the 3-day event the digital preservation developers work to create practical solutions to real-world challenges the practitioners are having related to digital preservation. Meanwhile, the practitioners work to create compelling business cases for digital preservation at their institution. This article describes the SPRUCE Mashup London event held in September 2012.","M. Corrado,Edward","Code4Lib","http://journal.code4lib.org/articles/8004","SPRUCE;digital preservation;UK;mashup"
"1028ed45c50f4e9dbde5e6f563ff611b",2013,"Relevance and Phrase Searching in Summon: looking under the hood","This article briefly examines the mechanisms behind seemingly counter-intuitive phrase search results in Serials Solutions’ discovery platform Summon. The authors use the platform’s search API to explain why users sometimes encounter greater numbers of results when typically they would expect fewer. The article explores the reasons behind the search results and the implications for library instruction.","Hodge,Thomas;RW MacDonald,James","Code4Lib","http://journal.code4lib.org/articles/8352","API;phrase search;Summon;rearch results;library instruction"
"11781438ccf34f2488ef468f33b79848",2015,"Using SemanticScuttle for managing lists of recommended resources on a library website","Concordia University Libraries has adopted SemanticScuttle, an open source and locally-hosted PHP/MySQL application for social bookmarking, as an alternative to Delicious for managing lists of recommended resources on the library’s website. Two implementations for displaying feed content from SemanticScuttle were developed: (1) using the Google Feed API and (2) using direct SQL access to SemanticScuttle’s database.","Neugebauer,Tomasz;Carson,Pamela;Krujelskis,Stephen","Code4Lib","http://journal.code4lib.org/articles/10269","Concordia;SemanticScuttle;Delicious;Google Feed API;API"
"12fc310101524fb0b565f22729d5dd8b",2015,"Code as Code: Speculations on Diversity, Inequity, and Digital Women","All technologies are social. Taking this socio-technological position becomes less a political stance as a necessity when considering the lived experience of digital inequity, divides, and –isms as they are encountered in every-day library work spheres. Personal experience as women and women of color in our respective technological and leadership communities provides both fore- and background to explore the private-public lines delineating definitions of “diversity”, “inequity”, and digital literacies in library practice.We suggest that by not probing these definitions at the most personal level of lived experience, we in the LIS and technology professions will remain well-intentioned, but ineffective, in genuine inclusion.","L. Comstock,Sharon;Copeny,Jerica;Landrum,Cynthia","Code4Lib","http://journal.code4lib.org/articles/10470","technology professions;inclusion"
"13788cdc76624522a674cafccf84a77d",2014,"Mdmap: A Tool for Metadata Collection and Matching","This paper describes a front-end for the semi-automatic collection, matching, and generation of bibliographic metadata obtained from different sources for use within a digitization architecture. The Library of a Billion Words project is building an infrastructure for digitizing text that requires high-quality bibliographic metadata, but currently only sparse metadata from digitized editions is available. The project’s approach is to collect metadata for each digitized item from as many sources as possible. An expert user can then use an intuitive front-end tool to choose matching metadata. The collected metadata are centrally displayed in an interactive grid view. The user can choose which metadata they want to assign to a certain edition, and export these data as MARCXML. This paper presents a new approach to bibliographic work and metadata correction. We try to achieve a high quality of the metadata by generating a large amount of metadata to choose from, as well as by giving librarians an intuitive tool to manage their data.","Simke,Rico","Code4Lib","http://journal.code4lib.org/articles/10055","semi-automatic collection;bibliographic metadata;digitization:Library of a Billion Words;project;MARCXMLmetadata correction;metadata;quality"
"13aebab207824c21acb8335aa8bd09d2",2011,"Best Practices for a University Laptop Lending Program","The University of Arizona Libraries currently circulates over three hundred pieces of equipment including laptops, netbooks, projectors and iPads. This article describes the best practices and workflows we have developed since 2003 to create alaptop/equipment lending program that is efficient and mindful of financial resources and that our student body loves and continues to support.","Buzzard,Pamela;Teetor,Travis","Code4Lib","http://journal.code4lib.org/articles/5876","Arizona;best practices;equipment;iPads"
"1669f5c1822e4bd0af126a5861de28b3",2016,"How to Party Like it’s 1999: Emulation for Everyone","Emulated access of complex media has long been discussed, but there are very few instances in which complex, interactive, born-digital emulations are available to researchers. New York Public Library has made 1980-90's era video games from 5.25"" floppy disks in the Timothy Leary Papers accessible via a DosBox emulator. These games appear in various stages of development and display the work of at least four of Leary's collaborators on the games. 56 disk images from the Leary Papers are currently emulated in the reading room. New York University has made late 1990s-mid 2000's era Photoshop files from the Jeremy Blake Papers accessible to researchers. The Blake Papers include over 300 pieces of media. Cornell University Library was awarded a grant from the NEH to analyze approximately 100 born-digital artworks created for CD-ROM from the Rose Goldsen Archive of New Media Art to develop preservation workflows, access strategies, and metadata frameworks. Rhizome has undertaken a number of emulation projects as a major part of its preservation strategy for born-digital artworks. In cooperation with the University of Freiburg in Germany, Rhizome recently restored several digital artworks for public access using a cloud-based emulation framework. This framework (bwFLA) has been designed to facilitate the reenactments of software on a large scale, for internal use or public access. This paper will guide readers through how to implement emulation. Each of the institutions weigh in on oddities and idiosyncrasies they encountered throughout the process — from accession to access.","Dietrich,Dianne;Kim,Julia;McKeehan,Morgan;Rhonemus,Alison","Code4Lib","http://journal.code4lib.org/articles/11386","DosBox;emulation;preservation workflows;Rhizome;bwFLA"
"16e61151b67f4d439f2fc19a59f5538c",2020,"Editorial","An abundance of information sharing.","M. Gonzales,Brighid","Code4Lib","https://journal.code4lib.org/articles/15194","editorial"
"177c1f903ae441658e5e836eea0961f3",2009,"Visualizing Media Archives: A Case Study","The WGBH Media Library and Archives is piloting an online media archive for scholarly research. In conversation with users, we have discovered they want to quickly pinpoint items relevant to their work and get an overview of collections and their relationships to other materials. To demonstrate the size and complexity of our collection to users in a meaningful way, WGBH is employing data visualization techniques to provide an interactive, graphical representation of the various relationships between items. This article discusses the techniques employed in implementing our relationship map, emphasizes the cataloging techniques required for this effort, and offers code and examples to spark discussion about ways to improve or extend this effort.","Todorovic,Mayo;Michael,Courtney;Beer,Chris","Code4Lib","http://journal.code4lib.org/articles/1119","WGBH;data visualization"
"17a33d199306424f9686b7467abf21a5",2014,"Implementing a Collaborative Workflow for Metadata Analysis, Quality Improvement, and Mapping","The University of North Texas (UNT) and the Oklahoma Historical Society (OHS) are collaborating to digitize, process, and make publicly available more than one million photographs from the Oklahoma Publishing Company’s historic photo archive.The project, started in 2013, is expected to span a year and a half and will result in digitized photographs and metadata available through The Gateway to Oklahoma History.The project team developed the workflow described in this article to meet the specific criterion that all of the metadata work occurs in two locations simultaneously.","Phillips,Mark;Tarver,Hannah;Frakes,Stacy","Code4Lib","http://journal.code4lib.org/articles/9199","North Texas;UNT;Oklahoma Historical Society;digitization;photographs;project"
"17d65c519eba48a784f24c8aee2b9ee9",2018,"The Tools We Don’t Have: Future and Current Inventory Management in a Room Reservation System","Fondren Library at Rice University has numerous study rooms which are very popular with students. Study rooms, and equipment, have future inventory needs which require a visual calendar for reservation. Traditionally libraries’ manage reservations through a booking module in an Integrated Library System (ILS), but most, if not all, booking modules lack a visual calendar which allows patrons to pick out a place and time to create a reservation. The IT department at Fondren library was able to overcome this limitation by modifying the open source Booked Scheduling software so that it did all of the front end work for the ILS, while still allowing the ILS to manage the use of the rooms.","Galvin,Denis;Sun,Mang;Lee,Hanjun","Code4Lib","https://journal.code4lib.org/articles/13718","ILS;Fondren;Booked Scheduling"
"17e43e63644644ae9ee3e3f4d7cfdfb3",2016,"Are games a viable solution to crowdsourcing improvements to faulty OCR? – The Purposeful Gaming and BHL experience","The Missouri Botanical Garden and partners from Dartmouth, Harvard, the New York Botanical Garden, and Cornell recently wrapped up a project funded by IMLS called Purposeful Gaming and BHL:engaging the public in improving and enhancing access to digital texts (http://biodivlib.wikispaces.com/Purposeful+Gaming).The goals of the project were to significantly improve access to digital texts through the applicability of purposeful gaming for the completion of data enhancement tasks needed for content found within the Biodiversity Heritage Library (BHL).This article will share our approach in terms of game design choices and the use of algorithms for verifying the quality of inputs from players as well as challenges related to transcriptions and marketing.We will conclude by giving an answer to the question of whether games are a successful tool for analyzing and improving digital outputs from OCR and whether we recommend their uptake by libraries and other cultural heritage institutions.","J. Seidman,Max;Mary Flanagan,Dr.;Rose-Sandler,Trish;Lichtenberg,Mike","Code4Lib","http://journal.code4lib.org/articles/11781","Missouri;botany;IMLS;gaming;public engagements;BHL;game design;OCR"
"17f143e665ba4d3a907be534ca85b599",2008,"Editorial Introduction - Issue 5","Welcome to the 5th issue of the Code4Lib Journal. We've come a long way in just over a year! We hope you take a few minutes to celebrate those accomplishments with us as you explore issue 5 and read about the innovations, ideas, and experiences shared there. Let's learn from each other.","Lynema,Emily","Code4Lib","http://journal.code4lib.org/articles/670","editorial"
"180bbb9565244e50ade2d0b5e15c8362",2011,"Open Access Publishing with Drupal","In January 2009, the Colorado Association of Libraries (CAL) suspended publication of its print quarterly journal, Colorado Libraries, as a cost-saving measure in atime of fiscal uncertainty. Printing and mailing the journal to its 1300 members cost CAL morethan $26,000 per year. Publication of the journal was placed on an indefinite hiatus until the editorial staff proposed an online, open access format a year later. The benefits to migrating to open access included: significantly lower costs; a green platform; instant availability ofcontent; a greater level of access to users with disabilities; and a higher level of visibility of the journal and the association. The editorial staff chose Drupal, including the E-journal module, and while Drupal is notorious for its steep learning curve—which exacerbated delays to content that had been created before the publishing hiatus—the fourth electronic issue was published recently at coloradolibrariesjournal.org. This article will discuss both the benefits and challenges of transitioning to an open access model and the choice Drupal aș a platform over other more established journal software options.","McHale,Nina","Code4Lib","http://journal.code4lib.org/articles/5913","Colorado;Drupal;publishing"
"18ab185f659d4d5c8cac59bd607304d0",2017,"Linked Data is People: Building a Knowledge Graph to Reshape the Library Staff Directory","One of our greatest library resources is people. Most libraries have staff directory information published on the web, yet most of this data is trapped in local silos, PDFs, or unstructured HTML markup. With this in mind, the library informatics team at Montana State University (MSU) Library set a goal of remaking our people pages by connecting the local staff database to the Linked Open Data (LOD) cloud. In pursuing linked data integration for library staff profiles, we have realized two primary use cases: improving the search engine optimization (SEO) for people pages and creating network graph visualizations. In this article, we will focus on the code to build this library graph model as well as the linked data workflows and ontology expressions developed to support it. Existing linked data work has largely centered around machine-actionable data and improvements for bots or intelligent software agents. Our work demonstrates that connecting your staff directory to the LOD cloud can reveal relationships among people in dynamic ways, thereby raising staff visibility and bringing an increased level of understanding and collaboration potential for one of our primary assets: the people that make the library happen.","A. Clark,Jason;W. H. Young,Scott","Code4Lib","http://journal.code4lib.org/articles/12320","Montana;MSU;LOD;use cases;SEO;ontology"
"197b3729c43a40f0a3d6b8c7cad6f92b",2020,"CollectionBuilder-CONTENTdm: Developing a Static Web ‘Skin’ for CONTENTdm-based Digital Collections","Unsatisfied with customization options for CONTENTdm, librarians at University of Idaho Library have been using a modern static web approach to creating digital exhibit websites that sit in front of the digital repository. This ""skin"" is designed to provide users with new pathways to discover and explore collection content and context. This article describes the concepts behind the approach and how it has developed into an open source, data-driven tool called CollectionBuilder-CONTENTdm. The authors outline the design decisions and principles guiding the development of CollectionBuilder, and detail how a version is used at the University of Idaho Library to collaboratively build digital collections and digital scholarship projects.","Becker,Devin;Williamson,Evan;Wikle,Olivia","Code4Lib","https://journal.code4lib.org/articles/15326","CONTENTdm;Idaho;digital exhibits;CollectionBuilder;digital scholarhip"
"197ebc9ae772446c814231898385c06d",2010,"Creating Library Websites with Joomla: Not Too Big, Not Too Small, Just Right","Many organizations, including libraries, are turning to content management systems to simplify the management of their websites. Alfred University‘s Herrick Memorial Library recently implemented a new website using Joomla, an open-source content management system. While Drupal has received significant attention in the library community, Joomla may be a more practical choice for some libraries. The purpose of this paper is to share our experience with Joomla so that other libraries can more easily evaluate its suitability to their environment.","Bahr,Ellen;Speed,Matt","Code4Lib","http://journal.code4lib.org/articles/4226","Joomla;Drupal;Alfred University"
"1ae46f4175804e68aaca272fc633545e",2021,"Machine Learning Based Chat Analysis","The BYU library implemented a Machine Learning-based tool to perform various text analysis tasks on transcripts of chat-based interactions between patrons and librarians. These text analysis tasks included estimating patron satisfaction and classifying queries into various categories such as Research/Reference, Directional, Tech/Troubleshooting, Policy/Procedure, and others. An accuracy of 78% or better was achieved for each category. This paper details the implementation details and explores potential applications for the text analysis tool.","Brousseau,Christopher;Johnson,Justin;Thacker,Curtis","Code4Lib","https://journal.code4lib.org/articles/15660","machine learning;text analysis"
"1b5c614279934bf5a13ce63651f34cf1",2020,"IIIF by the Numbers","The UCLA Library began work on building a suite of services to support IIIF for their digital collections. The services perform image transformations and delivery as well as manifest generation and delivery. The team was unsure about whether they should use local or cloud-based infrastructure for these services, so they conducted some experiments on multiple infrastructure configurations and tested them in scenarios with varying dimensions.","Gomez,Joshua;S. Clarke,Kevin;Vuong,Anthony","Code4Lib","https://journal.code4lib.org/articles/15217","UCLA;IIIF;infrastructure configuration;scenarios"
"1c137e5f6562436db64c7a0268987d40",2008,"Free and Open Source Options for Creating Database-Driven Subject Guides","This article reviews available cost-effective options libraries have for updating and maintaining pathfinders such as subject guides and course pages. The paper discusses many of the available options, from the standpoint of a mid-sized academic library which is evaluating alternatives to static-HTML subject guides. Static HTML guides, while useful, have proven difficult and time-consuming to maintain. The article includes a discussion of open source database-driven solutions (such as SubjectsPlus, LibData, Research Guide, and Library Course Builder), Wikis, and social tagging sites like del.icio.us. This article discusses both the functionality and the relative strengths and weaknessess of each of these options.","M. Corrado,Edward;A. Frederick,Kathryn","Code4Lib","http://journal.code4lib.org/articles/47","static HTML;subject guides"
"1c8dcdee8c344d71ad3e3b1cc86fcb6c",2019,"Generating Geographic Terms for Streaming Videos Using Python: A Comparative Analysis","In libraries, the relationship between textual descriptions of audiovisual material and access to that material is a primary concern, as users expect to have access to all the library’s resources—which increasingly include audiovisual content—through a simple and effective web interface. At UW-Oshkosh, library staff developed a unique site for its streaming video collection that would allow users to search for videos and browse collections on particular topics across each of the three vendors. În order to create more meaningful and topical collections, various programming tools and techniques were employed to identify geographical locations in vendor-supplied MARC records. This article describes three different methods for generating
geographic terms for streaming videos using different Python libraries and evaluates them based on the number of terms generated, overlap in terms generated between the three methods, and the amount of cleanup needed to generate useful geographic terms.","Harrington,Patrick","Code4Lib","https://journal.code4lib.org/articles/14676","UW-Oshkosh;MARC;Python;geo;streaming videos"
"1cbe4c90c2e34b5eb8bd3cb6d49f3629",2010,"Managing Library IT Workflow with Bugzilla","Prior to September 2008, all technology issues at the University of Colorado Denver's Auraria Library were reported to a dedicated departmental phone line. A variety of staff changes necessitated a more formal means of tracking, delegating, and resolving reported issues, and the department turned to Bugzilla, an open source bug tracking application designed by Mozilla.org developers. While designed with software development bug tracking in mind, Bugzilla can be easily customized and modified to serve as an IT ticketing system. Twenty-three months and over 2300 trouble tickets later, Auraria's IT department workflow is much smoother and more efficient. This article includes two Perl Template Toolkit code samples for customized Bugzilla screens for its use in a library environment; readers will be able to easily replicate the project in their own environments.","McHale,Nina","Code4Lib","http://journal.code4lib.org/articles/3814","Bugzilla;ticketing system;Perl;Denver"
"1d44fbd99e0b42ffbc68ba7cb59e4253",2011,"Lessons in Public Touchscreen Development","In October 2010, the NCSU Libraries debuted its first public touch screen information kiosk, designed to provide on-demand access to useful and commonly consulted real-time displays of library information. This article presents a description ofthe hardware and software development process, as well as the rationale behind a variety ofdesign and implementation decisions. This article also provides an analysis of usage of thetouchscreen since its debut, including a numerical analysis of most popular content areas, anda heatmap-based analysis of user interaction patterns with the kiosk’s interface components.","K. Orphanides,Andreas","Code4Lib","http://journal.code4lib.org/articles/5832","NCSU;kiosk;touch screen;interface"
"1d45b75e044b467e8329f696967d3106",2012,"On Dentographs, A New Method of Visualizing Library Collections","A dentograph is a visualization of a library's collection built on the idea that a classification scheme is a mathematical function mapping one set of things (books or the universe of knowledge) onto another (a set of numbers and letters). Dentographs can visualize aspects of just one collection or can be used to compare two or more collections. This article describes how to build them, with examples and code using Ruby and R, and discusses some problems and future directions.","Denton,William","Code4Lib","http://journal.code4lib.org/articles/6300","dentograph;classification scheme;Ruby;R"
"1d94b584541e4f8d8cc9e86e5097fe4d",2011,"Controlled Terms or Free Terms? A JavaScript Library to Utilize SubjectHeadings and Thesauri on the Web","There are two types of keywords used as metadata: controlled terms and free terms. Free terms have the advantage that metadata creators can freely select keywords,but there also exists a disadvantage that the information retrieval recall ratio might be reduced. The recall ratio can be improved by using controlled terms. But creating and maintaining controlled vocabularies has an enormous cost. In addition, many existing controlled vocabularies are published in formats less suitable for programming. We introduce a JavaScript library called “covo.js” that enables us to make use of controlled vocabularies aș metadata for the organization of web pages.","Nagaya,Shun;Hayashi,Yutaka;Otani,Shuhei;Itabashi,Keizo","Code4Lib","http://journal.code4lib.org/articles/5994","metadata;keywords;controlled terms;information retrieval;controlled vocabularies;Javascript;covo.js"
"1df186c392c442a98a4d4c61cfca1cca",2008,"The ICAP (Interactive Course Assignment Pages) Publishing System","The ICAP publishing system is an open source custom content management system that enables librarians to easily and quickly create and manage library help pages for course assignments (ICAPs), without requiring knowledge of HTML or other web technologies. The system's unique features include an emphasis on collaboration and content reuse and an easy-to-use interface that includes in-line help, simple forms and drag and drop functionality. The system generates dynamic, attractive course assignment pages that blend Web 2.0 features with traditional library resources, and makes the pages easier to find by providing a central web page for the course assignment pages. As of December 2007, the code is available as free, open-source software under the GNU General Public License.","Griggs,Kim;Mellinger,Margaret","Code4Lib","http://journal.code4lib.org/articles/63","ICAP;publishing system;Web 2.0"
"1dff463ebd124ad7839786fe22271051",2009,"Infomaki: An Open Source, Lightweight Usability Testing Tool","Infomaki is an open source ""lightweight"" usability testing tool developed by the New York Public Library to evaluate new designs for the NYPL.org web site and uncover insights about our patrons. Designed from the ground up to be as respectful of the respondents' time as possible, it presents respondents with a single question at a time from a pool of active questions. In just over seven months of use, it has fielded over 100,000 responses from over 10,000 respondents.","Lascarides,Michael","Code4Lib","http://journal.code4lib.org/articles/2099","Infomaki;NYPL;patrons;redesign"
"1e01a175736848ad9606ec7683a2ddeb",2016,"Peripleo: a Tool for Exploring Heterogeneous Data through the Dimensions of Space and Time","This article introduces Peripleo, a prototype spatiotemporal search and visualization tool. Peripleo enables users to explore the geographic, temporal and thematic composition of distributed digital collections in their entirety, and then to progressively filter and drill down to explore individual records. We provide an overview of Peripleo's features, and present the underlying technical architecture. Furthermore, we discuss how datasets that differ vastly in terms of size, content type and theme can be made uniformly accessible through a set of lightweight metadata conventions we term ""connectivity through common references"". Our current demo installation links approximately half a million records from 25 datasets. These datasets originate from a spectrum of sources, ranging from the small personal photo collection with 35 records, to the large institutional database with 134.000 objects. The product of research in the Andrew W. Mellon-funded Pelagios 3 project, Peripleo is Open Source software.","Simon,Rainer;Isaksen,Leif;Barker,Elton;de Soto Cañamares,Pau","Code4Lib","http://journal.code4lib.org/articles/11144","Peripleo; spatiotemporal search;visualization;datasets;Pelagios"
"1e20c474a8d74807b133710e25961ced",2015,"Building a Better Book in the Browser (Using Semantic Web technologies and HTML5)","The library as place and service continues to be shaped by the legacy of the book. The book itself has evolved in recent years, with various technologies vying to become the next dominant book form. In this article, we discuss the design and development of our prototype software from Montana State University (MSU) Library for presenting books inside of web browsers. The article outlines the contextual background and technological potential for publishing traditional book content through the web using open standards. Our prototype demonstrates the application of HTML5, structured data with RDFa and Schema.org markup, linked data components using JSON-LD, and an API-driven data model. We examine how this open web model impacts discovery, reading analytics, eBook production, and machine-readability for libraries considering how to unite software development and publishing.","A. Clark,Jason;W. H. Young,Scott","Code4Lib","http://journal.code4lib.org/articles/10668","API;RDFa;Schema.org;Montana;JSON-LD;eBook"
"1e5fa9afa6d746789befbb1a0d8436cd",2014,"A Web Service for File-Level Access to Disk Images","Digital forensics tools have many potential applications in the curation of digital materials in libraries, archives and museums (LAMs). Open source digital forensics tools can help LAM professionals to extract digital contents from born-digital media and make more informed preservation decisions. Many of these tools have ways to display the metadata of the digital media, but few provide file-level access without having to mount the device or use complex command-line utilities. This paper describes a project to develop software that supports access to the contents of digital media without having to mount or download the entire image. The work examines two approaches in creating this tool: First, a graphical user interface running on a local machine. Second, a web-based application running in web browser.The project incorporates existing open source forensics tools and libraries including The Sleuth Kit and libewf along with the Flask web application framework and custom Python scripts to generate web pages supporting disk image browsing.","Misra,Sunitha;A. Lee,Christopher;Woods,Kam","Code4Lib","http://journal.code4lib.org/articles/9773","digital forensics;LAM;GUI;The Sluth Kit;Flask"
"1ee91a54aee74aa4ad6a17f77fa5d8a2",2020,"Data reuse in linked data projects: a comparison of Alma and Share-VDE BIBFRAME networks","This article presents an analysis of the enrichment, transformation, and clustering used by vendors Casalini Libri/@CULT and Ex Libris for their respective conversions of MARC data to BIBFRAME. The analysis considers the source MARC21 data used by Alma then the enrichment and transformation of MARC21 data from Share-VDE partner libraries. The clustering of linked data into a BIBFRAME network is a key outcome of data reuse in linked data projects and fundamental to the improvement of the discovery of library collections on the web and within search systems.","Hahn,Jim","Code4Lib","https://journal.code4lib.org/articles/15424","MARC;BIBFRAME;MARC21;Share-VDE;Ex Libris"
"1fa0e2dd047944b8ae2830e5321dfff6",2010,"Improving the Drupal User Experience","Drupal is a powerful, but complex, Web Content Management System, being adopted by many libraries. Installing Drupal typically involves adding additional modules for flexibility and increased functionality. Although installing additional modules does increase functionality, it inevitably complicates usability. At the University of Houston Libraries, the Web Services department researched what modules work well together to accomplish a simpler interface while simultaneously providing the flexibility and advanced tools needed to create a successful user experience within Drupal. This article explains why particular modules were chosen or developed, how the design enhanced the user experience, how the CMS architecture was created, and how other library systems were integrated into Drupal.","Vacek,Rachel;Watkins,Sean;M. Morris,Christina;Keller,Derek","Code4Lib","http://journal.code4lib.org/articles/4578","Drupal;Huston;CMS;module develoment"
"201ec2712c334f758499ee901fadafee",2008,"Identifying FRBR Work-Level Data in MARC Bibliographic Records for Manifestations of Moving Images","The library metadata community is dealing with the challenge of implementing the conceptual model, Functional Requirements for Bibliographic Records (FRBR). In response, the Online Audiovisual Catalogers (OLAC) created a task force to study the issues related to creating and using FRBR-based work-level records for moving images. This article presents one part of the task force's work: it looks at the feasibility of creating provisional FRBR work-level records for moving images by extracting data from existing manifestation-level bibliographic records. Using a sample of 941 MARC records, a subgroup of the task force conducted a pilot project to look at five characteristics of moving image works. Here they discuss their methodology; analysis; selected results for two elements, original date (year) and director name; and conclude with some suggested changes to MARC coding and current cataloging policy.","Bisko,Lynne;McGrath,Kelley","Code4Lib","http://journal.code4lib.org/articles/775","FRBR;OLAC;MARC;catloguing policy"
"20323f7a8729493d85a1b55484ee3f0c",2012,"Presenting results as dynamically generated co-authorship subgraphs in semantic digital library collections","Semantic web representations of data are by definition graphs, and these graphs can be explored using concepts from graph theory. This paper demonstrates how semantically mapped bibliographic metadata, combined with a lightweight software architecture and Web-based graph visualization tools, can be used to generate dynamic authorship graphs in response to typical user queries, as an alternative to more common text-based results presentations. It also shows how centrality measures and path analysis techniques from social network analysis can be used to enhance the visualization of query results. The resulting graphs require modestly more cognitive engagement from the user but offer insights not available from text.","Powell,James;M. McMahon,Tamara;Mane,Ketan;Miller,Laniece;Collins,Linn","Code4Lib","http://journal.code4lib.org/articles/6381","semantic web;bibliographic metadata;graph theory;centrality measurement;centrality"
"205407995a1c4105bc72b7100e0f174b",2009,"Automated Metadata Formatting for Cornell’s Print-on-Demand Books","Cornell University Library has made Print-On Demand (POD) books available for many of its digitized out-of-copyright books. The printer must be supplied with metadata from the MARC bibliographic record in order to produce book covers. Although the names of authors are present in MARC records, they are given in an inverted order suitable for alphabetical filing rather than the natural order that is desirable for book covers. This article discusses a process for parsing and manipulating the MARC author strings to identify their various component parts and to create natural order strings. In particular, the article focuses on processing non-name information in author strings, such as titles that were commonly used in older works, e.g., baron or earl, and suffixes appended to names, e.g., ""of Bolsena."" Relevant patterns are identified and a Python script is used to manipulate the author name strings.","Dietrich,Dianne","Code4Lib","http://journal.code4lib.org/articles/2138","POD;print on demand;MARC;Python"
"2182a35b5d69441c897b02c3acf949a8",2017,"Outside The Box: Building a Digital Asset Management Ecosystem for Preservation and Access","The University of Houston (UH) Libraries made an institutional commitment in late 2015 to migrate the data for its digitized cultural heritage collections to open source systems for preservation and access: Hydra-in-a-Box, Archivematica, and ArchivesSpace. This article describes the work that the UH Libraries implementation team has completed to date, including open source tools for streamlining digital curation workflows, minting and resolving identifiers, and managing SKOS vocabularies. These systems, workflows, and tools, collectively known as the Bayou City Digital Asset Management System (BCDAMS), represent a novel effort to solve common issues in the digital curation lifecycle and may serve as a model for other institutions seeking to implement flexible and comprehensive systems for digital preservation and access.","Weidner,Andrew;Watkins,Sean;Scott,Bethany;Krewer,Drew;Washington,Anne;Richardson,Matthew","Code4Lib","http://journal.code4lib.org/articles/12342","Huston;cultural heritage;migration;Hydra-in-aBox;Archivematica;ArchivesSpace;SKOS;digital curation;digital preservation"
"21e93007bd3140eab20fe6ce910a9f13",2017,"Annotation-based enrichment of Digital Objects using open-source frameworks","The W3C Web Annotation Data Model, Protocol, and Vocabulary unify approaches to annotations across the web, enabling their aggregation, discovery and persistence over time. In addition, new javascript libraries provide the ability for users to annotate multi-format content. In this paper, we describe how we have leveraged these developments to provide annotation features alongside Islandora’s existing preservation, access, and management capabilities. We also discuss our experience developing with the Web Annotation Model as an open web architecture standard, as well as our approach to integrating mature external annotation libraries. The resulting software (the Web Annotation Utility Module for Islandora) accommodates annotation across multiple formats.This solution can be used in various digital scholarship contexts.","Emmanuel Barnes,Marcus;Ledchumykanthan,Natkeeran;Pham,Kim;Stapelfeldt,Kirsta","Code4Lib","http://journal.code4lib.org/articles/12582","W3C;annotation;data model;Islandora;digital scolarship"
"2243c85bf4e34f3faa0cbf0659778dcd",2021,"GaNCH: Using Linked Open Data for Georgia’s Natural, Cultural and Historic Organizations’ Disaster Response","In June 2019, the Atlanta University Center Robert W. Woodruff Library received a LYRASIS Catalyst Fund grant to support the creation of a publicly editable directory of Georgia’s Natural, Cultural and Historical Organizations (NCHs), allowing for quick retrieval of location and contact information for disaster response. By the end of the project, over 1,900 entries for NCH organizations in Georgia were compiled, updated, and uploaded to Wikidata, the linked open data database from the Wikimedia Foundation. These entries included directory contact information and GIS coordinates that appear on a map presented on the GaNCH project website (https://ganch.auctr.edu/), allowing emergency responders to quickly search for NCHs by region and county in the event of a disaster. In this article we discuss the design principles, methods, and challenges encountered in building and implementing this tool, including the impact the tool has had on statewide disaster response after implementation.","Landis,Cliff;Wiseman,Christine;F. Smith,Allyson;Stephens,Matthew","Code4Lib","https://journal.code4lib.org/articles/15576","LYRASIS;Wikidata;Wikimedia;GaNCH;project"
"2312c265b9e147fdb1521a0212aa165c",2017,"Countering Stryker’s Punch: Algorithmically Filling the Black Hole","Two current digital image editing programs are examined in the context of filling in missing visual image data from hole-punched United States Farm Security Administration (FSA) negatives. Specifically, Photoshop's Content-Aware Fill feature and GIMP's Resynthesizer plugin are evaluated and contrasted against comparable images. A possible automated workflow geared towards large scale editing of similarly hole-punched negatives is also explored. Finally, potential future research based upon this study's results are proposed in the context of leveraging previously-enhanced, image-level metadata.","J. Bennett,Michael","Code4Lib","http://journal.code4lib.org/articles/12542","GIMP;digital editing;images;metadata"
"234bd5087e77433495f272bcad8cc2a0",2017,"Editorial: Introspection as Activism, or, Getting Our Houses in Order","Those of us in libraries like to trace our history to Alexandria or to the French governmental system of record-keeping, but the construction of the modern GLAM world is far more recent, almost as new as coding. It has evolved almost as rapidly. And its future is on us, whether we choose to passively accept a status quo others build or to act and grow and develop ourselves and our workplaces.","Kitchin Tillman,Ruth","Code4Lib","http://journal.code4lib.org/articles/12232","Alexandria;GLAM;editorial"
"23e219fd1cd946c5b1ce453fa426ba1e",2012,"Hacking 360 Link: A hybrid approach","When the University of Victoria Libraries switched from a locally-hosted link resolver (SFX) to a vendor-hosted link resolver (360Link), new strategies were required to effectively integrate the vendor-hosted link resolver with the Libraries' other systems and services. Custom javascript is used to add links to the 360Link page; these links then point at local PHP code running on UVic servers, which can then redirect to appropriate local service or display a form directly. An open source PHP OpenURL parser class is announced. Consideration is given to the importance of maintaining open protocols and standards in the transition to vendor-hosted services.","Durno,John","Code4Lib","http://journal.code4lib.org/articles/7308","Victoria;SFX;PHP;Uvic;OpenURL"
"250c25f0c38c411d9eb4ec6005206857",2008,"Help! A simple method for getting back-up help to the reference desk","Using the ""net send"" command, native to Windows XP, librarians at the University of California, Riverside created a ""help button"" for the reference desk. The simple script file sends a message to librarians' workstations in their offices and logs the date and time of use. This paper describes that program.","Furuta,Kenneth;Potter,Michele","Code4Lib","http://journal.code4lib.org/articles/45","reference service;scripting"
"258b381178a446faa82b091bf9883722",2021,"Introducing SAGE: An Open-Source Solution for Customizable Discovery Across Collections","Digital libraries at research universities make use of a wide range of unique tools to enable the sharing of eclectic sets of texts, images, audio, video, and other digital objects.Presenting these assorted local treasures to the world can be a challenge, since text is often siloed with text, images with images, and so on, such that per type, there may be separate user experiences in a variety of unique discovery interfaces.One common tool that has been developed in recent years to potentially unite them all is the Apache Solr index.Texas A&M University (TAMU) Libraries has harnessed Solr for internal indexing for repositories like DSpace, Fedora, and Avalon.Impressed by frameworks like Blacklight at peer institutions, TAMU Libraries wrote an analogous set of tools in Java, and thus was born SAGE, the Solr AGgregation Engine, with two primary functions:1) aggregating Solr indices or “cores,” from various local sources, and 2) presenting search facility to the user in a discovery interface.","B. Lowe,David;Creel,James;German,Elizabeth;Hahn,Douglas;Huff,Jeremy","Code4Lib","https://journal.code4lib.org/articles/15740","indexing;Apache Solr;TAMU;Solr;Blacklight"
"263fec01a4c54821826455eaeedfc170",2007,"BOOK REVIEW: The Success of Open Source by Steven Weber","The Success of Open Source by Steven Weber details the history, process, motivations, and possible long-term effects of open source software (OSS). Weber’s book can be used as a set of guidelines – a description of a framework – for building software solutions for the computing problems facing libraries.","Lease Morgan,Eric","Code4Lib","http://journal.code4lib.org/articles/30","review;book review;open source"
"26f3dace9d6f426f9ae30abfa32abcfc",2013,"Using XSLT and Google Scripts to Streamline Populating an Institutional Repository","The College of Wooster has created a process that allows library staff to quickly populate institutional repositories. An XSLT script is used to transform RefWorks citations into Dublin Core XML and batch load those records into the institutional repository. A second script in a Google Docs spreadsheet then looks up publisher permissions in Sherpa/RoMEO. The resulting workflow has dramatically reduced the amount of time necessary to populate an institutional repository with faculty scholarly articles.","X. Flynn,Stephen;Oyler,Catalina;Miles,Marsha","Code4Lib","http://journal.code4lib.org/articles/7825","Wooster;XLST;RefWorks;Dublin Core;XML;scripting;Sherpa/Romeo;institutional repository"
"27368ca370da44f4a6fa812aa5e4dfd8",2009,"CONFERENCE REPORT: Code4Lib 2009","Conference reports from the 4th Code4Lib conference, held in Providence, RI from February 23 to 26, 2009. The Code4Lib conference is a collective volunteer effort of the informal Code4Lib community of library technologists. Included are four brief reports on the conference from the recipients of conference scholarships.","Ko,Lauren;DiPasquale,Joanna;Chen,Jie;Orphanides,Andreas","Code4Lib","http://journal.code4lib.org/articles/998","report;conference"
"27efa97fdbb140cc82545ad999dfb756",2018,"WMS, APIs and LibGuides: Building a Better Database A-Z List","At the American University of Sharjah, our Databases by title and by subject pages are the 3rd and 4th most visited pages on our website. When we changed our ILS from Millennium to OCLC’s WorldShare Management Services (WMS), our previous automations which kept our Databases A-Z pages up-to-date were no longer usable and needed to be replaced. Using APIs, a Perl script, and LibGuides’ database management interface, we developed a workflow that pulls database metadata from WMS Collection Manager into a clean public-facing A-Z list. This article will discuss the details of how this process works, the advantages it provides, and the continuing issues we are facing.","Ramshaw,Veronica;Lecat,Véronique;Hodge,Thomas","Code4Lib","https://journal.code4lib.org/articles/13688","API;Sarjah;Perl;LibGuides"
"28023d6be3c6469582b29ecaeb9d71fd",2016,"OSS4EVA: Using Open-Source Tools to Fulfill Digital Preservation Requirements","This paper builds on the findings of a workshop held at the 2015 International Conference on Digital Preservation (iPRES), entitled, “Using Open-Source Tools to Fulfill Digital Preservation Requirements” (OSS4PRES hereafter). This day-long workshop brought together participants from across the library and archives community, including practitioners, proprietary vendors, and representatives from open-source projects. The resulting conversations were surprisingly revealing: while OSS’ significance within the preservation landscape was made clear, participants noted that there are a number of roadblocks that discourage or altogether prevent its use in many organizations. Overcoming these challenges will be necessary to further widespread, sustainable OSS adoption within the digital preservation community. This article will mine the rich discussions that took place at OSS4PRES to (1) summarize the workshop’s key themes and major points of debate, (2) provide a comprehensive analysis of the opportunities, gaps, and challenges that using OSS entails at a philosophical, institutional, and individual level, and (3) offer a tangible set of recommendations for future work designed to broaden community engagement and enhance the sustainability of open source initiatives, drawing on both participants’ experience as well as additional research.","Carleton,Janet;Dowding,Heidi;Gengenbach,Marty;Graham,Blake;Meister,Sam;Moran,Jessica;Peltzman,Shira;Seifert,Julie;Waugh,Dorothy","Code4Lib","https://journal.code4lib.org/articles/11940","OSS4PRES;OSS4EVA;workshop;recommendations"
"2844b8eadb774b508b56492e3e4df14d",2010,"Easing Gently into OpenSRF, Part 1","The Open Service Request Framework (or OpenSRF, pronounced ""open surf"") is an inter-application message passing architecture built on XMPP (aka ""jabber""). The Evergreen open source library system is built on an OpenSRF architecture to support loosely coupled individual components communicating over an OpenSRF messaging bus. This article introduces OpenSRF, demonstrates how to build OpenSRF services through simple code examples, explains the technical foundations on which OpenSRF is built, and evaluates OpenSRF's value in the context of Evergreen. Part 1 of a 2 part article in this issue.","Scott,Dan","Code4Lib","http://journal.code4lib.org/articles/3284","OpenSRF;XMPP;jabber;Evergreen"
"292b90f5c97146aba6a466635dccefde",2011,"How to Provide Live Library Information via SMS Using Twilio","Paul Smith’s College provides library hours and workstation availability using SMS Text Messages. The service was implemented using an easy and affordable web-based API for SMS sending and receiving, from twilio.com. A new class of ‘cloud-based‘ SMS vendors make simple SMS-based services efficient and cost-effective to implement, and have many possible applications in the library environment. A simple PHP example is provided which supplies workstation availability over SMS based on a database of computer availability from a previous Code4Lib Journal Article.","Beccaria,Mike","Code4Lib","http://journal.code4lib.org/articles/5542","API;Paul Smith;SMS;Twilio;PHP"
"297f9b7db7ce4d12946c595ecb34dd40",2017,"Python, Google Sheets, and the Thesaurus for Graphic Materials for Efficient Metadata Project Workflows","In 2017, the University of Virginia (U.Va.) will launch a two year initiative to celebrate the bicentennial anniversary of the University’s founding in 1819.The U.Va. Library is participating in this event by digitizing some 20,000 photographs and negatives that document student life on the U.Va. grounds in the 1960s and 1970s.Metadata librarians and archivists are well-versed in the challenges associated with generating digital content and accompanying description within the context of limited resources.This paper describes how technology and new approaches to metadata design have enabled the University of Virginia’s Metadata Analysis and Design Department to rapidly and successfully generate accurate description for these digital objects. Python’s pandas module improves efficiency by cleaning and repurposing data recorded at digitization, while the lxml module builds MODS XML programmatically from CSV tables. A simplified technique for subject heading selection and assignment in Google Sheets provides a collaborative environment for streamlined metadata creation and data quality control.","Bartczak,Jeremy;Glendon,Ivey","Code4Lib","http://journal.code4lib.org/articles/12182","Virginia;metadata design;MODS;XML;CSV;subject heading;metadata;data quality"
"299a0e38a15047129de6e653a66da03d",2009,"Using Book Data Providers to Improve Services to Patrons","At Paul Smith's College, I recently implemented a ""New Books"" display using open APIs and an image scroller. In this article I'll give a brief overview of Google Book Search, OpenLibrary and Worldcat, explain how I created this New Books Widget using book cover data, and provide readers with some practical and simple code to show how to collect this data. This article will be of interest to anyone who wants to read about a brief overview of current state of free book data service providers. Additionally, beginner programmers will likely find the examples at the end of the article helpful when getting started with projects of their own.","Beccaria,Mike","Code4Lib","http://journal.code4lib.org/articles/1009","API;Paul Smith;New Books;image scroller;book data service providers"
"2a1797171b2e4043930b157346d6aad9",2017,"Editorial: The Economics of Not Being an Organization","Our successes have caught up with us. Now we get to choose the next step in our evolution.","Bean,Carol","Code4Lib","http://journal.code4lib.org/articles/13074","editorial"
"2aa5c8867c5547ab8e595931b5878db9",2013,"Editorial Introduction: A Peer Network","Code4Lib, and the Code4Lib Journal, considered as a peer network.","Darby,Andrew","Code4Lib","http://journal.code4lib.org/articles/8087","editorial"
"2afca622351849e5814d913e5942b4c4",2015,"Topic Space: Rapid Prototyping a Mobile Augmented Reality Recommendation App","With funding from an Institute of Museum and Library Services (IMLS) Sparks! Ignition Grant, researchers from the University of Illinois Library designed and tested a mobile recommender app with augmented reality features. By embedding open source optical character recognition software into a “Topic Space” module, the augmented reality app can recognize call numbers on a book in the library and suggest relevant items that are not shelved nearby. Topic Space can also show users items that are normally shelved in the starting location but that are currently checked out. Using formative UX methods, grant staff shaped app interface and functionality through early user testing. This paper reports results of UX testing; a redesigned mobile interface, and provides considerations on the future development of personalized recommendation functionality.","Hahn,Jim;Ryckman,Ben;Lux,Maria","Code4Lib","http://journal.code4lib.org/articles/10881","IMLS;recommender;mobile app;topic space;UX;interface"
"2be4483f9eb54f8cbf51ac3833c2542b",2019,"Creating a Low-cost, DIY Multimedia Studio in the Library","This case study will explain steps in creating a multimedia studio inside a health sciences library with existing software and a minimal budget. From ideation to creation to assessment, the process will be outlined in development phases and include examples of documentation, user feedback, lessons learned, and future considerations. We’ll explore multimedia software like One Button Studio, GameCapture, Kaltura, Adobe Creative Cloud, Garage Band, and others and compare their effectiveness when working on audio and visual projects in the library.","Elias Hull and Brandon Patterson,Bryan","Code4Lib","https://journal.code4lib.org/articles/14435","case study;health;multimedia;comparison"
"2c89b495f78f478f924e76093b219b1c",2019,"Reporting from the Archives: Better Archival Migration Outcomes with Python and the Google Sheets API","Columbia University Libraries recently embarked on a multi-phase project to migrate nearly 4,000 records describing over 70,000 linear feet of archival material from disparate sources and formats into ArchivesSpace. This paper discusses tools and methods brought to bear in Phase 2 of this project, which required us to look closely at how to integrate a large number of legacy finding aids into the new system and merge descriptive data that had diverged in myriad ways. Using Python, XSLT, and a widely available if underappreciated resource—the Google Sheets API—archival and technical library staff devised ways to efficiently report data from different sources, and present it in an accessible, user-friendly way,. Responses were then fed back into automated data remediation processes to keep the migration project on track and minimize manual intervention. The scripts and processes developed proved very effective, and moreover, show promise well beyond the ArchivesSpace migration. This paper describes the Python/XSLT/Sheets API processes developed and how they opened a path to move beyond CSV-based reporting with flexible, ad-hoc data interfaces easily adaptable to meet a variety of purposes.","W. Hodges,David;Schlottmann,Kevin","Code4Lib","https://journal.code4lib.org/articles/14871","API;Columbia;ArchiveSpace;Python;XSLT;Google Sheets;CSV;migration"
"2caa6f76c330483088bfafd14193204b",2015,"Making User Rights Clear: Adding e-resource License Information in Library Systems","Libraries sign a wide variety of licensing agreements that specify terms of both access and use of a publisher’s electronic collections. Adding easily accessible licensing information to collections helps ensure that library users comply with these agreements. This article will describe the addition of licensing permissions to resource displays using Mondo by Queen’s University and Scholars Portal (a service of the Ontario Council of University Libraries). We will give a brief introduction to Mondo and explain how we improved Mondo to add the license permissions to different library systems. The systems we used are an ILS (Voyager), an OpenURL Link Resolver (360 Link), and a Discovery System (Summon). However, libraries can use Mondo to add the license permissions to other library systems which allow user configurations.","Jing,Jenny;Lin,Qinqin;Sharifi,Ahmedullah;Swartz,Mark","Code4Lib","http://journal.code4lib.org/articles/10724","Queen;Ontario;Mondo;ILS;Voyager;OpenURL;Summon"
"2ceaf66ced2b491fad91bbd223b71e3f",2018,"FAIR Principles for Library, Archive and Museum Collections: A proposal for standards for reusable collections","Many heritage institutions would like their collections to be open and reusable but fail to achieve that situation because of organizational, legal and technological barriers. A set of guidelines and best practices is proposed to facilitate the process of making heritage collections reusable. These guidelines are based on the FAIR Principles for scholarly output (FAIR data principles [2014]), taking into account a number of other recent initiatives for making data findable, accessible, interoperable and reusable. The resulting FAIR Principles for Heritage Library, Archive and Museum Collections focus on three levels: objects, metadata and metadata records. Clarifications and examples of these proposed principles are presented, as well as recommendations for the assessment of current situations and implementations of the principles.","Koster,Lukas;Woutersen-Windhouwer,Saskia","Code4Lib","http://journal.code4lib.org/articles/13427","FAIR;data;guidelines;good practices"
"2d08a0a920764edf82ee3f40786b66cc",2008,"BOOK REVIEW: Two Books about FRBR, Compared","This article reviews 2 books on FRBR published in the past year. Although both books aim to be introductions to FRBR, their approaches are very different. One is sort of a FRBR study guide with commentary, the other a collection of essays. Robert Maxwell's book, FRBR: A Guide for the Perplexed, takes the study guide approach. Arlene Taylor edited Understanding FRBR: What It Is and How It Will Affect Our Retrieval Tools, a book of essays about FRBR and FRAD, written by cataloging experts, aimed at a broader audience, not just the cataloging specialist.The first seven chapters lay out the basics: introductions to FRBR and FRAD, FRBR research, FRBR and the history of cataloging, FRBR and RDA. These chapters provide an excellent introduction for those new to FRBR. The last seven chapters each look at different types of resources in relation to FRBR.","Schwartz,Christine","Code4Lib","http://journal.code4lib.org/articles/138","book review;FRBR"
"2d0a81d7c22843abbcfef38237f3d03f",2019,"Editorial","If you build it, I'll probably come.","Amato,Sara","Code4Lib","https://journal.code4lib.org/articles/14876","editorial"
"2e85a45737de4cf38b4b2ec56fdcfe12",2013,"Determining Usability of VuFind for Users in the United Arab Emirates","In late 2011, the Higher Colleges of Technology, a higher education institution in the United Arab Emirates, implemented Vufind as the search interface for the libraries’ resources. Before launching Vufind in the 2012 academic year, usability testing occurred across three campuses to test the functionality of the search interface features. Twenty-one participants, including Emirati students and expatriate faculty, were tested using a performance based assessment along with think-aloud protocol, which was recorded using Camtasia screen capture software. As a result of the testing several features of Vufind were customized including language, layout and prioritization of results. The current study builds on the limited existing body of literature on Vufind, which has previously indicated a number of design elements and practices which should optimize user experience. Several key findings are consistent with and confirm results from prior studies with findings from this study adding to the literature by observing how or why linguistic orientation affects user behavior in search systems.","Johnston,Nicole;Salaz,Alicia;O'Connell,Rob","Code4Lib","http://journal.code4lib.org/articles/7880","Vufind;Emirates;Camtasia;search"
"2e969b74a8504f1da8c8196d46914821",2018,"Analyzing EZproxy SPU Logs Using Python Data Analysis Tools","Even with the assortment of free and ready-made tools for analyzing EZproxy log files, it can be difficult to get useful, meaningful data from them. Using the Python programming language with its collection of modules created specifically for data analysis can help with this task, and ultimately result in better and more useful data customized to the needs of the library using it. This article describes how Our Lady of the Lake University used Python to analyze its EZproxy log files to get more meaningful data, including a walk-through of the code needed to accomplish this task.","M. Gonzales,Brighid","Code4Lib","https://journal.code4lib.org/articles/13918","Ezproxy;log files;Python;data analysis"
"2f286c1c8d3f4bc18296f2a6721d96c2",2011,"Editorial Introduction: Ride On, Mighty Warriors","I joined the fellowship of the Journal only one year past. In the time since I have helped to caress into sonnets the grunts and mutterings of paladins near and far. But forgive my crude tongue, for I do not wish to offend. You who share your drunken yarns are the font, the wellspring, of all that you see here.","Farrell,Gabriel","Code4Lib","http://journal.code4lib.org/articles/4892","editorial"
"2f2962abcc95474d91e61e51c77ecab6",2015,"Collecting and Describing University-Generated Patents in an Institutional Repository: A Case Study from Rice University","Providing an easy method of browsing a university's patent output can free up valuable research time for faculty, students, and external researchers. This is especially true for Rice University's Fondren Library, a USPTO-designated Patent and Trademark Resource Center that serves an academic community widely recognized for cutting edge science and engineering research. In order to make Rice-generated patents easier to find in the university's community, a team of technical and public services librarians from Fondren Library devised a method to identify, download, and upload patents to the university’s institutional repository, starting with a backlog of over 300. This article discusses the rationale behind the project, its potential benefits, and challenges as new Rice-generated patents are added to the repository on a monthly basis.","Spiro,Linda;Carlson,Scott","Code4Lib","http://journal.code4lib.org/articles/10981","Rice;Patents;trademarks;repository"
"2fa180628a9f49838b27cad6009bc7ae",2021,"Customizing Alma and Primo for Home & Locker Delivery","Like many Ex Libris libraries in Fall 2020, our library at California State University, Northridge (CSUN) was not physically open to the public during the 2020-2021 academic year, but we wanted to continue to support the research and study needs of our over 38,000 university students and 4,000 faculty and staff. This article will explain our Alma and Primo implementation to allow for home mail delivery of physical items, including policy decisions, workflow changes, customization of request forms through labels and delivery skins, customization of Alma letters, a Python solution to add the “home” address type to patron addresses to make it all work, and will include relevant code samples in Python, XSL, CSS, XML, and JSON. In Spring 2021, we will add the on-site locker delivery option in addition to home delivery, and this article will include new system changes made for that option.","L. Hennessey,Christina","Code4Lib","https://journal.code4lib.org/articles/15521","Ex Libris; California;CSUN;Alma;Primo;Python;system;mail delivery"
"2fda1851a6e74808841dda477677aa44",2018,"Getting More out of MARC with Primo: Strategies for Display, Search and Faceting","Going beyond author, title, subject and notes, there are many new (or newly-revitalized) fields and subfields in the MARC 21 format that support more structured data and could be beneficial to users if exposed in a discovery interface. In this article, we describe how the Orbis Cascade Alliance has implemented display, search and faceting for several of these fields and subfields in our Primo discovery interface. We discuss problems and challenges we encountered, both Primo-specific and those that would apply in any search interface.","McGrath,Kelley;Lowery,Lesley","Code4Lib","https://journal.code4lib.org/articles/13600","MARC21;Primo;interface;search"
"30d3842164554a768c14b95b7558ad8a",2020,"Leveraging Google Drive for Digital Library Object Storage","This article will describe a process at the University of Kentucky Libraries for utilizing an unlimited Google Drive for Education account for digital library object storage. For a number of recent digital library projects, we have used Google Drive for both archival file storage and web derivative file storage. As a part of the process, a Google Drive API script is deployed in order to automate the gathering of of Google Drive object identifiers. Also, a custom Omeka plugin was developed to allow for referencing web deliverable files within a web publishing platform via object linking and embedding. For a number of new digital library projects, we have moved toward a small VM approach to digital library management where the VM serves as a web front end but not a storage node. This has necessitated alternative approaches to storing web addressable digital library objects. One option is the use of Google Drive for storing digital objects. An overview of our approach is included in this article as well as links to open source code we adopted and more open source code we produced.","C. Weig,Eric","Code4Lib","https://journal.code4lib.org/articles/15073","API;Google Drive;Omeka;Kentucky"
"3111a8738f9a47f1beea5b2b9402fc27",2014,"HathiTrust Ingest of Locally Managed Content: A Case Study from the University of Illinois at Urbana-Champaign","In March 2013, the University of Illinois at Urbana-Champaign Library adopted a policy to more closely integrate the HathiTrust Digital Library into its own infrastructure for digital collections. Specifically, the Library decided that the HathiTrust Digital Library would serve as a trusted repository for many of the library’s digitized book collections, a strategy that favors relying on HathiTrust over locally managed access solutions whenever this is feasible. This article details the thinking behind this policy, as well as the challenges of its implementation, focusing primarily on technical solutions for “remediating” hundreds of thousands of image files to bring them in line with HathiTrust’s strict specifications for deposit. This involved implementing HTFeed, a Perl 5 application developed at the University of Michigan for packaging content for ingest into Hathi Trust, and its many helper applications (JHOVE to detect metadata problems, Exiftool to detect metadata issues and repair missing image metadata, and Kakadu to create JP2000 files), as well as a file format conversion process using ImageMagick. Today, Illinois has over 1600 locally managed volumes queued for ingest, and has submitted over 2300 publicly available titles to the HathiTrust Digital Library.","R. Rimkus,Kyle;M. Hess,Kirk","Code4Lib","http://journal.code4lib.org/articles/9703","HathiTrust;Perl;JHOVE;metadata;Exiftool;Kakadu;ImageMagick;images"
"3159ca66ccaf48fab18725f7ea6838a9",2008,"Conference Report: Code4LibCon 2008","This article contains three reports relating to Code4LibCon 2008 -- the third annual Code4Lib conference in Portland, Oregon (February 25-28, 2008). The first describes the birth of the conference and introduces the 2008 OSU / Code4Lib scholarship recipients. The latter two parts, written by the scholarship recipients, outline the things they saw and learned at the conference.","Mouw,Deborah;Junus,Ranti;Bean,Carol","Code4Lib","http://journal.code4lib.org/articles/72","reports"
"317331193a1249988c0bd2bd74f0ec96",2009,"Editorial Introduction — Openness","On openness and the Code4Lib Journal.","Darby,Andrew","Code4Lib","http://journal.code4lib.org/articles/2282","editorial"
"31d23bb9036244a58fb0d008bc1b6494",2023,"The viability of using an open source locally hosted AI for creating metadata in digital image collections","Artificial intelligence (AI) can support metadata creation for images by generating descriptions, titles, and keywords for digital collections in libraries. Many AI options are available, ranging from cloud-based corporate software solutions, including Microsoft Azure Custom Vision and Google Cloud Vision, to open-source locally hosted software packages. This case study examines the feasibility of deploying the open-source, locally hosted AI software, Sheeko, and the accuracy of the descriptions generated for images using two of the pre-trained models. The study aims to ascertain if Sheeko’s AI would be a viable solution for producing metadata in the form of descriptions, or titles for digital collections in Libraries and Cultural Resources at the University of Calgary.","Reiche,Ingrid","Code4Lib","https://journal.code4lib.org/articles/17186","artificial intelligence;ai;Microsoft Azure;Custom Vision;Cloud Vision;Sheeko;metadata;descriptions"
"32a9da45e54b47079a3e4b07070a7726",2021,"Adaptive Digital Library Services: Emergency Access Digitization at the University of Illinois at Urbana-Champaign During the COVID-19 Pandemic","This paper describes how the University of Illinois at Urbana-Champaign Library provided access to circulating library materials during the 2020 COVID-19 pandemic. Specifically, it details how the library adapted existing staff roles and digital library infrastructure to offer on-demand digitization of and limited online access to library collection items requested by patrons working in a remote teaching and learning environment. The paper also provides an overview of the technology used, details how dedicated staff with strong local control of technology were able to scale up a university-wide solution, reflects on lessons learned, and analyzes nine months of usage data to shed light on library patrons’ changing needs during the pandemic.","R. Rimkus,Kyle;Dolski,Alex;Emery,Brynlee;Johns,Rachael;Lampron,Patricia;Schlaack,William;Waarala,Angela","Code4Lib","https://journal.code4lib.org/articles/15915","COVID-19;digitization;usage data;pandemic;Urbana-Champaign"
"32f7de31304445acb62bcd8e4f8f2e2e",2018,"Archidora: Integrating Archivematica and Islandora","“Archidora” is shorthand for the publicly available integration between the open source software packages Archivematica and Islandora. Sponsored by the University of Saskatchewan Library, this integration enables the automated ingest into Archivematica of objects created in Islandora. This will allow institutions that use Islandora as a digital asset management system, particularly for digitized material, to take advantage of Archivematica’s standards-based digital preservation functionality, without requiring staff doing digitization to interact with Archivematica. This paper outlines the basic functionality and workflow of archidora; provides an overview of the development process including challenges and lessons learned; and discusses related initiatives and possible future directions for development.","Hutchinson,Tim","Code4Lib","http://journal.code4lib.org/articles/13150","Archidora;Archivematica;Saskatchewan;Islandora"
"3395bb3795734690a19e8e365f8a9639",2022,"Strategies for Preserving Digital Scholarship / Humanities Projects","The Digital Scholarship Unit (DSU) at the University of Toronto Scarborough library frequently partners with faculty for the creation of digital scholarship (DS) projects. However, managing completed projects can be challenging when it is no longer under active development by the original project team, and resources allocated to its ongoing maintenance are scarce. Maintaining inactive projects on the live web bloats staff workloads or is not possible due to limited staff capacity. As technical obsolescence meets a lack of staff capacity, the gradual disappearance of digital scholarship projects forms a gap in the scholarly record. This article discusses the Library DSU’s experimentations with using web archiving technologies to capture and describe digital scholarship projects, with the goal of accessioning the resulting web archives into the Library’s digital collections. In addition to comparing some common technologies used for crawling and replay of archives, this article describes aspects of the technical infrastructure the DSU is building with the goal of making web archives discoverable and playable through the library’s digital collections interface.","Stapelfeldt,Kirsta;Khera,Sukhvir;Ledchumykanthan,Natkeeran;Gomez,Lara;Liu,Erin;Dhaliwal,Sonia","Code4Lib","https://journal.code4lib.org/articles/16370","Scarborough;digital scholarship;interface;discoverability"
"33af746b508746deb8f9560328a1002a",2011,"Using ImageMagick to Automatically Increase Legibility of Scanned Text Documents","The Law Library Digitization Project of the Rutgers University School of Law in Camden, New Jersey, developed a Perl script to use the open-source module PerlMagick to automatically adjust the brightness levels of digitized images from scanned microfiche. This script can be adapted by novice Perl programmers to manipulate large numbers of text and image files using commands available in PerlMagick and ImageMagick.","Belfiore,Doreva","Code4Lib","http://journal.code4lib.org/articles/5385","law;digitization;Rutgers;Perl;PerlMagick;images;microfiche;scripting"
"33d6111611fe40ad84d0d2707805bef2",2016,"Building Bridges with Logs: Collaborative Conversations about Discovery across Library Departments","This article describes the use of discovery system search logs as a vehicle for encouraging constructive conversations across departments in an academic library. The project focused on bringing together systems and teaching librarians to evaluate the results of anonymized patron searches in order to improve communication across departments, as well as to identify opportunities for improvement to the discovery system itself.","Ghaphery,Jimmy;Owens,Emily;Coghill,Donna;Gariepy,Laura;Hodge,Megan;McNulty,Thomas;White,Erin","Code4Lib","http://journal.code4lib.org/articles/11355","search logs;discovery system"
"342ff74b53f042b48b0077cdebd3696e",2008,"The Planets Testbed: Science for Digital Preservation","The preservation of digital objects requires specific software tools or services. These can be characterisation tools that abstract the essential characteristics of a digital object from a file, migration tools that convert digital objects to different formats, or emulation tools that render digital objects in their original context on a new infrastructure.Until recently digital preservation has been characterised by practices and processes that could best be described as more art and craft than science. The Planets Testbed provides a controlled environment where preservation tools can be tested and evaluated, and where experiment results can be empirically compared.This paper presents an overview of the Testbed application, an analysis of the experiment methodology and a description of the Testbed's web service approach.","Ross,Seamus;Nicchiarelli,Eleonora;Lindley,Andrew;Jackson,Andrew;Helwig,Petra;Aitken,Brian","Code4Lib","http://journal.code4lib.org/articles/83","digital preservation;Planets;Testbed"
"350a88e255844eb8bcf7c94d40954ff4",2021,"Enhancing Print Journal Analysis for Shared Print Collections","The Western Regional Storage Trust (WEST), is a distributed shared print journal repository program serving research libraries, college and university libraries, and library consortia in the Western Region of the United States. WEST solicits serial bibliographic records and related holdings biennially, which are evaluated and identified as candidates for shared print archiving using a complex collection analysis process. California Digital Library’s Discovery & Delivery WEST operations team (WEST-Ops) supports the functionality behind this collection analysis process used by WEST program staff (WEST-Staff) and members. For WEST, proposals for shared print archiving have been historically predicated on what is known as an Ulrich’s journal family, which pulls together related serial titles, for example, succeeding and preceding serial titles, their supplements, and foreign language parallel titles. Ulrich’s, while it has been invaluable, proves problematic in several ways, resulting in the approximate omission of half of the journal titles submitted for collection analysis. Part of WEST’s effectiveness in archiving hinges upon its ability to analyze local serials data across its membership as holistically as possible. The process that enables this analysis, and subsequent archiving proposals, is dependent on Ulrich’s journal family, for which ISSN has been traditionally used to match and cluster all related titles within a particular family. As such, the process is limited in that many journals have never been assigned ISSNs, especially older publications, or member bibliographic records may lack an ISSN(s), though the ISSN may exist in an OCLC primary record. Building a mechanism for matching on ISSNs that goes beyond the base set of primary, former, and succeeding titles, expands the number of eligible ISSNs that facilitate Ulrich’s journal family matching. Furthermore, when no matches in Ulrich’s can be made based on ISSN, other types of control numbers within a bibliographic record may be used to match with records that have been previously matched with an Ulrich’s journal family via ISSN, resulting in a significant increase in the number of titles eligible for collection analysis. This paper will discuss problems in Ulrich’s journal family matching, improved functional methodologies developed to address those problems, and potential strategies to improve in serial title clustering in the future.","Jemison,Dana;Liu,Lucy;Striker,Anna;Wohlers,Alison;Jiang,Jing;Dobry,Judy","Code4Lib","https://journal.code4lib.org/articles/15649","repository;WEST;ISSN;Ulrich;clustering"
"3516079513ea42b5a95230ce0bd0503a",2019,"Editorial: New Editors, Diversity, and Representation","Welcoming new editors, new surveys, and thinking about diversity at code4Lib Journal.","Tidal,Junior","Code4Lib","https://journal.code4lib.org/articles/14551","editorial"
"365431ac7db742549055cb97d45510c3",2010,"Using Cloud Services for Library IT Infrastructure","Cloud computing comes in several different forms and this article documents how service, platform, and infrastructure forms of cloud computing have been used to serve library needs. Following an overview of these uses the article discusses the experience of one library in migrating IT infrastructure to a cloud environment and concludes with a model for assessing cloud computing.","Mitchell,Erik","Code4Lib","http://journal.code4lib.org/articles/2510","cloud computing;cloud;ifrastructure"
"36652074c82b4729947e9bcf7e0f321b",2015,"A Novel Open Source Approach to Monitor EZproxy Users’ Activities","This article describes using Elasticsearch/Logstash/Kibana (ELK) to monitor and visualize Ezproxy logs in real time.","Zou,Qing","Code4Lib","http://journal.code4lib.org/articles/10589","Elasticsearch;ELK;Ezproxy;logs;visualization;real time"
"367b7f27328c480d9afa55b41e52f1fc",2008,"Toward element-level interoperability in bibliographic metadata","This paper discusses an approach and set of tools for translating bibliographic metadata from one format to another.A computational model is proposed to formalize the notion of a 'crosswalk'. The translation process separates semantics from syntax, and specifies a crosswalk as machine executable translation files which are focused on assertions of element equivalence and are closely associated with the underlying intellectual analysis of metadata translation.A data model developed by the authors called Morfrom serves as an internal generic metadata format. Translation logic is written in an XML scripting language designed by the authors called the Semantic Equivalence Expression Language (Seel). These techniques have been built into an OCLC software toolkit to manage large and diverse collections of metadata records, called the Crosswalk Web Service.","Childress,Eric;Smith,Devon;Jean Godby,Carol","Code4Lib","http://journal.code4lib.org/articles/54","bibliographic metadata;computational model;crosswalk;XML;Seel;OCLC"
"36c7e5d4fed1479ca06bc4801efa14f4",2022,"Simplifying ARK ID management for persistent access to digital objects","This article will provide a brief overview of considerations made by the UTSC Library in selecting a persistent identifier scheme for digital collections in a mid-sized Canadian library.  ARKs were selected for their early support of digital object management, the low-cost, decentralized capabilities of the ARK system, and the usefulness of ARK URLs during system migration projects.  In the absence of a subscription to a centralized resolver service for ARKs, the UTSC Library Digital Scholarship Unit built an open source PHP-based application for minting, binding, managing, and tracking ARK IDs. This article will introduce the application's architecture and affordances, which may be useful to others in the library community with similar use cases, as well as the approach to using ARKs planned for an Islandora 2.x system.","Huynh, Natkeeran Ledchumykanthan, Kirsta Stapelfeldt, Irfan Rahman,Kyle","Code4Lib","https://journal.code4lib.org/articles/16774","ARK;PHP;architecture;Islandora"
"36cae3d71be94d5a86b9e78595990353",2022,"Citation Needed: Adding Citations to CONTENTdm Records","The Tennessee State Library and Archives and the Illinois State Library identified a need to add citation information to individual image records in OCLC’s CONTENTdm (https://www.oclc.org/en/contentdm.html).Experience with digital archives at both institutions showed that citation information was one of the most requested features. Unfortunately, CONTENTdm does not natively display citation information about image records; to add this functionality, custom JavaScript had to be written that would interact with the underlying React environment and parse out or retrieve the appropriate metadata to dynamically build record citations. Detailed code and a description of methods for building two different models of citation generators are presented.","Randles,Jenn;Bullen,Andrew","Code4Lib","https://journal.code4lib.org/articles/16289","Tennessee;OCLC;CONTENTdm;JavaScript;React;metadata"
"36d73958b34b46c68ca76751ea92458a",2008,"User-Centred Design and Agile Development: Rebuilding the Swedish National Union Catalogue","With a new generation of OPACs emerging that attempt to address longstanding shortcomings, how do we make sure that we do not lose ground again in the future? This article suggests a combination of iterative development and user-centred design as a way to develop systems that will meet the constantly changing expectations of users by providing both functionality and usability. It gives a short introduction to iterative software development and user-centred design. A case study of the development of the new version of LIBRIS (http://libris.kb.se), the Swedish National Union Catalogue, is used as an example of how these methodologies can benefit from each other in practice.","Lindström,Henrik;Malmsten,Martin","Code4Lib","http://journal.code4lib.org/articles/561","agile software development;iterative development;usability;user-centred design"
"36dc79352d314f80bf2e8400836d286d",2010,"A Method for Visualizing Transaction Logs of a Faceted OPAC","The authors introduce a method for visualizing user transaction logs from a library catalog application. Simple visualization supporting intuitive or qualitative analysis to quickly make sense of complicated patterns can be a useful supplement or alternative to more common quantitative analysis. To this end, a visual flowchart is created illustrating an individual user session. This visualization can be used to qualitatively grasp user behavior within the application, possibly as an aid to identifying patterns or clusters of use. These flowcharts are created by automatically pre-processing apache transaction logs into an XML representation of meaningful user actions, which are then converted via JavaScript in a web browser to HTML table based flowcharts. The particular toolkit introduced is named Visualization for Understanding Transaction Logs (VUTL), and is available with an open source license. The toolkit has been prototyped with logs from the catalog applications of several academic and one public library.","Niu,Xi;M. Hemminger,Bradley","Code4Lib","http://journal.code4lib.org/articles/4325","XML;VUTL;JavaScript;visualization;flowchart;logs"
"3724143b1b0f48339c47791728d50131",2019,"Developing Sinopia’s Linked-Data Editor with React and Redux","An important software product for the Linked-Data for Production phase 2 grant from the Mellon foundation was the creation of a linked-data editor that professional cataloging staff would use to create original RDF descriptions of their collections. Using the Bibframe Editor from the Library of Congress as inspiration, the Stanford University Library-based software development team are actively building a React/Redux linked-data editor for use by a cohort of national, academic, and special libraries. A very popular combination for front-end Javascript applications, this article will explain how React and Redux are used with great success in the editor's implementation of a domain-specific-language (DSL) called Profiles containing one or more resource templates that specify an HTML form-based user interface for cataloging using RDF.","Nelson,Jeremy","Code4Lib","https://journal.code4lib.org/articles/14598","RDF;Sinopia;linked data;LOC;JavaScript;DSL"
"3763569572b4486686330a3f5cab429b",2010,"Wrangling Electronic Resources: A Few Good Tools","There are several freely available tools today that fill the needs of librarians tasked with maintaining electronic resources, that assist with tasks such as editing MARC records and maintaining web sites that contain links to electronic resources. This article gives a tour of a few tools the author has found invaluable as an Electronic Resources Librarian.","Klug,Brandy","Code4Lib","http://journal.code4lib.org/articles/2634","MARC;electronic resources"
"3914a94d535b4f1a870866bd5f5f8930",2012,"The Martha Berry Digital Archive Project: A Case Study in Experimental pEDagogy","Using the Martha Berry Digital Archive Project as an exploratory case study, this article discusses experimental methods in digital archive development, describing how and why a small project team is leveraging undergraduate student support, a participatory (crowdsourced) editing model, and free and open source software to digitize and disseminate a large documentary collection.","A. Schlitz,Stephanie;S. Bodine,Garrick","Code4Lib","http://journal.code4lib.org/articles/6823","Martha Berry Digital Archive;project;digital archive"
"396ed606919f4b5a9269e0b7689abf70",2015,"Implementing a Bento-Style Search in LibGuides v2","The National University of Singapore Libraries converted their LibGuides v2 instance into a research portal and incorporated a “bento box” search interface—that is, an interface where results from multiple systems or categories are compartmentalized by system or category, like a Japanese “bento”-style lunch box—on a trial basis. Our experience shows that building and maintaining a bento box search in LibGuides requires fewer resources than a fully homegrown solution would require. This makes it an attractive platform for building a bento-style search both for libraries who have limited technical resources and libraries who might want to experiment with this kind of search before fully committing. This paper shares the design, implementation and some early usage patterns of our bento search.","Tay,Aaron;Yikang,Feng","Code4Lib","http://journal.code4lib.org/articles/10709","Singapore;LibGuides;interface;bento;design;search"
"39b246ce7e784a419e0a472d59ea160e",2016,"From Users to Developers: NCSU’s Involvement with an Open Source ERM","CORAL, an open source electronic resource management tool, has been adopted by libraries around the world. The community manages the software development contributed to the open source codebase by independent organizations. NCSU Libraries’ Acquisition & Discovery Department started using CORAL to manage monograph orders at the end of 2013. Since then, they have completed a series of developments to enhance CORAL functions for workflow management, streamlining the complex electronic resource acquisition process. This paper presents NCSU’s adoption and development of CORAL. It explains what prompted the development, shares the experience, from identifying internal resources to outsourcing development work, and identifies challenges and opportunities of the current mechanism of CORAL development.","Song,Xiaoyan","Code4Lib","https://journal.code4lib.org/articles/11954","CORAL;NCSU;aquisitions"
"3aa1671d85fa4170a4a45858283a5514",2009,"library/mobile: Tips on Designing and Developing Mobile Web Sites","Mobile applications can support learning by making library resources more ubiquitous, by bringing new users to the library through increased accessibility to the resources libraries offer, and by creating a new way to enhance connections between patrons and libraries. This increased use of mobile phones provides an untapped resource for delivering library resources to patrons. The mobile Web is the next step for libraries in providing universal access to resources and information. This article will share Oregon State University (OSU) Libraries’ experience creating a mobile Web presence and will provide key design and development strategies for building mobile Web sites.","Gascho Rempel,Hannah;M. Bridges,Laurie;Griggs,Kim","Code4Lib","http://journal.code4lib.org/articles/2055","mobile phones;Oregon;web sites"
"3b05110217944701bc245b38e384189c",2010,"A Principled Approach to Online Publication Listings and Scientific Resource Sharing","The Max Planck Institute (MPI) for Psycholinguistics has developed a service to manage and present the scholarly output of their researchers. The PubMan database manages publication metadata and full-texts of publications published by their scholars. All relevant information regarding a researcher's work is brought together in this database, including supplementary materials and links to the MPI database for primary research data. The PubMan metadata is harvested into the MPI website CMS (Plone). The system developed for the creation of the publication lists, allows the researcher to create a selection of the harvested data in a variety of formats.","Ringersma,Jacquelijn;Kastens,Karin;Tschida,Ulla;van Berkum,Jos","Code4Lib","http://journal.code4lib.org/articles/2520","Max Plank;psycholinguistics;PubMan;Plone"
"3be6d3c97d27402d857b3fa6ecfd1749",2013,"The Moab Design for Digital Object Versioning","The Stanford Digital Repository has adopted the ""Moab"" design for versioned archiving of digital objects--a locally developed approach that optimizes data transfer, storage, and replication while providing efficient single file retrieval or full object reconstruction for any version of an object. This paper includes a review of various versioning strategies including forward-delta, reverse-delta and content-addressable mechanisms, the pro's and cons of each, and highlights the relative advantages of the Moab design. In our approach, the fixity information of a file manifestation is used as its primary identifier and the filename is treated as metadata. Storage and retrieval of an object's files is faciliated by mapping between a virtual version inventory and the physical location via a file signature catalog.","Anderson,Richard","Code4Lib","http://journal.code4lib.org/articles/8482","Stanford;Moab;design;digital objects;versioning"
"3d594185568c479585556c1643a8405f",2011,"mapFAST: A FAST Geographic Authorities Mashup with Google Maps","When looking for information about a particular place, it is often useful to check surrounding locations as well. FAST geographic subjects provide clean access points to this material, and a Google Maps mashup allows users to see surrounding locations that are also FAST subjects. Moreover, the Web Service to the underlying data is also open and available for use. The map interface allows for simple selection of a location, with links to enter it directly as a search into either WorldCat.org or Google Books.","Bennett,Rick;T. O’Neill,Edward;Kammerer,Kerre;Shipengrover,JD","Code4Lib","http://journal.code4lib.org/articles/5645","FAST;geographic subjects;mapFAST;geographic authorities;Google Maps"
"3f25a5d102df4923b1e65c12bced6678",2015,"Integration of Library Services with Internet of Things Technologies","The SELIDA framework is an integration layer of standardized services that takes an Internet-of-Things approach for item traceability in the library setting. The aim of the framework is to provide tracing of RFID tagged physical items among or within various libraries. Using SELIDA we are able to integrate typical library services—such as checking in or out items at different libraries with different Integrated Library Systems—without requiring substantial changes, code-wise, in their structural parts. To do so, we employ the Object Naming Service mechanism that allows us to retrieve and process information from the Electronic Product Code of an item and its associated services through the use of distributed mapping servers. We present two use case scenarios involving the Koha open source ILS and we briefly discuss the potential of this framework in supporting bibliographic Linked Data.","Stefanidis,Kyriakos;Tsakonas,Giannis","Code4Lib","http://journal.code4lib.org/articles/10897","SELIDA;framework;RFID;ILS;Linked Data;Koha"
"3fa7d0041b574a27a535a5087954bb19",2023,"PREMIS Events Through an Event-sourced Lens","The PREMIS metadata standard is widely adopted in the digital preservation community. Repository software often include fully compliant implementations or assert some level of conformance. Within PREMIS we have four semantic units, but “Events”, the topic of this paper, are particularly interesting as they describe “actions performed within or outside the repository that affects its capability to preserve Objects over the long term.” Events can help us to observe interactions with digital objects and understand where and when something may have gone wrong with them. Events in PREMIS, however, are slightly different to events in software development paradigms, specifically event driven software development – though similar, the design of PREMIS event logs does not promote their “being complete” nor their consumption and reuse; and so, learning from logs in event driven software development, may help us to simplify the PREMIS data model; plug identified gaps in implementations; and improve the ability to migrate digital content in future repositories.","Spencer,Ross","Code4Lib","https://journal.code4lib.org/articles/17264","PREMIS;metadata standard;digital preservation;data model;repositories"
"3ff30e84dc114792b3e73d63faf19466",2017,"Adopting a Distributed Model for Data Services","This article describes how the Saint Edward’s University Library implemented a distributed model for the Institutional Repository. Based on Cloud Based platforms and APIs, the Library has created an Institutional Repository that is scaleable and modular, considerably lowering its implementation and maintenance costs, while lowering its technical complexity.","Gibbs,Casey;Hernandez,Marcos;Sennyey,Pongracz","Code4Lib","http://journal.code4lib.org/articles/12191","API;institutional repository;cloud"
"40678241d75c45e186bfa4585d9bebb1",2009,"Course Views: A Scalable Approach to Providing Course-Based Access to Library Resources","The NCSU Libraries’ Course Views project, along with a locally developed widget web service, improves course-based access to library collections and services by dynamically generating library course pages for all 6000+ courses at NCSU. By automatically generating custom content when possible and showcasing authored content when available, Course Views is able to achieve full course coverage without significantly increasing staff time to create and manage content. This paper will describe the system and the use of web services to achieve scalable and sustainable delivery of course-related library content.","Ryan,Joseph;Duckett,Kim;Duckett,Kim;Casden,Jason","Code4Lib","http://journal.code4lib.org/articles/1218","NCSU;courses;system;Course Views"
"40a2eed74ef6409d8ef2ea845d0c8002",2007,"Connecting the Real to the Representational: Historical Demographic Data in the Town of Pullman, 1880-1940","The Pullman House History Project is a part of the Pullman State Historic Site’s virtual museum and web site (http://www.pullman-museum.org/) which links together census, city directory, and telephone directory information to describe the people who lived in the town of Pullman, Illinois between 1881 and 1940. This demographic data is linked through a database/XML record system to online maps and Perl programs that allow the data to be represented in various useful combinations. This article describes the structure of the database and XML records, as well as the methods and code used to link the parts together and display the data.","H. Bullen,Andrew","Code4Lib","http://journal.code4lib.org/articles/29","Pullman House History Project;demographic data;XML;Perl;database structure"
"4111a1971dad456abf8b219385901b23",2008,"Auto-Populating an ILL form with the Serial Solutions Link Resolver API","In this article we'll take a tour of the OpenURL protocol; discover how to use it to get an XML API response from the Serial Solutions link resolver; and see how to receive and process that XML data using PHP to create an Interlibrary Loan webform. Finally, we'll see a few examples of how to handle form processing. This article will be of interest to beginner programmers interested in examples of programming with OpenURL and XML in PHP, and to more experienced programmers interested in taking a look at the Serial Solutions 360 Link API.","Talsky,Daniel","Code4Lib","http://journal.code4lib.org/articles/108","OpenURL;XML;API;link resolver;PHP;Serial Solutions 360 Link"
"4139ab082bb541d887e454566e172b44",2008,"Making Patron Data Work Harder: User Search Terms as Access Points?","Montana State University (MSU) Libraries are experimenting with re-using patron-generated data to create browseable access points for the Electronic Theses and Dissertations (ETD) collection. A beta QueryCatcher module logs recent search terms and the number of associated hits. These terms are used to create browseable lists and tagclouds which enhance access to the ETD collection. Gathering and reusing information about user behavior is an emerging trend in web application development. This article outlines MSU Libraries' reasoning for moving towards a user-generated model and provides a complete walkthrough of the steps in building the application and example code.","A. Clark,Jason","Code4Lib","http://journal.code4lib.org/articles/78","Montana;ETD;QueryCatcher;tagclud"
"41f236a67eac47249a92e2210770ace4",2014,"Developing Applications in the Era of Cloud-based SaaS Library Systems","As the move to cloud-based SaaS library systems accelerates, we must consider what it means to develop applications when the core of the system isn't under the library's control. The entire application lifecycle is changing, from development to testing to production. Developing applications for cloud solutions raises new concerns, such as security, multi-tenancy, latency, and analytics. In this article, we review the landscape and suggest a view of how to be successful for the benefit of library staff and end-users in this new reality. We discuss what kinds of APIs and protocols vendors should be supporting, and suggest how best to take advantage of the innovations being introduced.","Weisman,Josh","Code4Lib","http://journal.code4lib.org/articles/10029","SaaS;API;cloud;discussion;protocols;overview"
"42074482cf064acd9a9cf42d150d666c",2012,"Code4Lib 2012 Conference Report","Amy Unger is one of the recipients of the Gender Diversity Scholarships to attend the Code4Lib 2012 conference. The Journal is pleased to present her conference report here.","Unger,Amy","Code4Lib","http://journal.code4lib.org/articles/6848","report"
"430e1dba6a494f23964e5ba2ce7a9b3f",2018,"Editorial: Musing on learning to be a selfish librarian","One of the perks of being the coordinating editor is you get to write the opening editorial for the issue.  It’s an opportunity to think broadly about the community, the journal…current events.  And if you look back over the past year or so, those that have taken on this role have been more than up […]","Reese,Terry","Code4Lib","http://journal.code4lib.org/articles/13351","editorial"
"4393ac40dfa8431a92e92b57fe1ea0eb",2012,"Using PHP to Parse eBook Resources from Drupal 6 to Populate a Mobile Web Page","The Ursula C. Schwerin library needed to create a page for its mobile website devoted to subscribed eBooks. These resources, however, were only available through the main desktop website. These resources were organized using the Drupal 6 content management system with contributed and core modules. It was necessary to create a solution to retrieve the eBook databases from the Drupal installation to a separate mobile site.","Tidal,Junior","Code4Lib","http://journal.code4lib.org/articles/7294","Ursula C. Schwerin;eBook;Drupal;mobile site"
"43a97c5c09ae49fa9b4b7dd5788016ee",2013,"Thresholds for Discovery: EAD Tag Analysis in ArchiveGrid, and Implications for Discovery Systems","The ArchiveGrid discovery system is made up in part of an aggregation of EAD (Encoded Archival Description) encoded finding aids from hundreds of contributing institutions. In creating the ArchiveGrid discovery interface, the OCLC Research project team has long wrestled with what we can reasonably do with the large (120,000+) corpus of EAD documents. This paper presents an analysis of the EAD documents (the largest analysis of EAD documents to date). The analysis is paired with an evaluation of how well the documents support various aspects of online discovery. The paper also establishes a framework for thresholds of completeness and consistency to evaluate the results. We find that, while the EAD standard and encoding practices have not offered support for all aspects of online discovery, especially in a large and heterogeneous aggregation of EAD documents, current trends suggest that the evolution of the EAD standard and the shift from retrospective conversion to new shared tools for improved encoding hold real promise for the future.","Proffitt,M.;Washburn,B.;Bron,M.","Code4Lib","http://journal.code4lib.org/articles/8956","ArchiveGrid;EAD;OCLC;tag analysis"
"44058d84e9c047979ca621e020f14385",2019,"Building an institutional author search tool","Frequently academic departments want to know how many publications their faculty and researchers have published over a particular period of time. At the Oregon Health Science University (OHSU) these questions were traditionally handled by having a librarian manually search various publication databases. These searches were complicated, and the outputs of these searches were often cumbersome and unwieldy. This meant that the answers to questions were often limited by how much effort could be put forth by the librarian whom may spend many hours managing these searches and the resulting data.","Forero,David;Peterson,Nick;Hamilton,Andrew","Code4Lib","https://journal.code4lib.org/articles/14753","Oregon;health;publication databases;data"
"45892abe4daf41108998af94751d9dd2",2008,"The Library Search Engine: A Smart Solution for Integrating Resources Beyond Library Holdings","The Cooperative Library Network Berlin-Brandenburg (KOBV), Germany addresses the problem of how to integrate resources found outside the library and library holdings into a single discovery tool. It presents a solution that uses open source technology to develop a next-generation catalog interface called the Library Search Engine. This pilot project was launched in 2007 with the library of Albert Einstein Science Park, Potsdam. The idea was to design and develop a fast and convenient search tool, integrating local holdings (books, journals, journal articles) as well as relevant scientific subject information such as open access publications and bibliographies.","Herm,Karin;Volz,Sibylle","Code4Lib","http://journal.code4lib.org/articles/142","KOBV;project;interface;search"
"462357cf749a45049bc8df969960b230",2015,"Transforming Knowledge Creation: An Action Framework for Library Technology Diversity","This paper will articulate an action framework for library technology diversity consisting of five dimensions and based on the vision for knowledge creation, the academic library’s fundamental vision. The framework focuses on increasing diversity for library technology efforts based on the desire for transformation and inclusiveness within and across the dimensions. The dimensions are people, content and pedagogy, embeddedness and the global perspective, leadership, and the 5th dimension – bringing it all together.","I. Dewey,Barbara","Code4Lib","http://journal.code4lib.org/articles/10442","knowledge creation"
"46c63c0b327042a8bd9a95a6d6bc592f",2019,"Managing Discovery Problems with User Experience in Mind","Williams Libraries recently developed a system for users to report problems they included while using the library catalog/discovery layer (Primo). Building on a method created by the Orbis Cascade Alliance, we built a Google form that allows users to report problems connecting to full text (or any other issue) and automatically includes the permalink in their response. We soon realized that we could improve the user experience by automatically forwarding these reports into our Ask a Librarian email service (LibAnswers) so we could offer alternative solutions while we worked on fixing the initial issue. The article will include an explanation of the process, reactions from public service staff, methods for managing the problems once submitted, and code shared on GitHub for those interested in implementing the tool at their own library.","Shriver,Emery","Code4Lib","https://journal.code4lib.org/articles/14481","LibAnswers;GitHub;Primo;"
"46c69c5f58c04df5b2b43720a2110147",2010,"WattJournals: Towards an Economic and Lightweight Search Tool Alternative for Libraries To Help Their Students and Researchers Keep Up-To-Date","Learn how Heriot-Watt University Library's WattJournals could be just the search tool your patrons need to efficiently find the content that your library subscribes to. Built on top of a RESTful search API created by the JISC-sponsored JournalTOCs Project, WattJournals is a toolkit for connecting fulltext articles to the people who need them. This article provides a technical overview of the system, showing how it uses citation data pulled from the JournalTOCs table of contents awareness service to provide access to just your library's subscriptions.","Chumbe,Santiago;Macleod,Roddy","Code4Lib","http://journal.code4lib.org/articles/4134","API;RESTful;JISC;JournalTOC;project;WattJournal"
"475179faf9b94db881c4646a1c8d80cb",2010,"Interpreting MARC: Where's the Bibliographic Data?","The MARC data format was created early in the history of digital computers. In this article, the author entertains the notion that viewing MARC from a modern technological perspective leads to interpretive problems such as a confusion of ""bibliographic data"" with ""catalog records."" He explores this idea through examining a specific MARC interpretation task that he undertook early in his career and then revisited nearly four years later. Revising the code that performed the task confronted him with his own misconceptions about MARC that were rooted in his worldview about what he thought ""structured data"" should be and helped him to place MARC in a more appropriate context.","Thomale,Jason","Code4Lib","http://journal.code4lib.org/articles/3832","MARC;bibliographic data;structured data"
"48779029dd114dab9c48537c4d6b70c6",2010,"Editorial Introduction: The Code4Lib Journal Experiment, Rejection Rates, and Peer Review","Code4Lib Journal has been a successful experiment. With success, questions have arisen about the scholarly nature and status of the Journal. In this editorial introduction we take a look at the question of Code4Lib Journal's rejections rates and peer review status.","M. Corrado,Edward","Code4Lib","http://journal.code4lib.org/articles/3277","editorial"
"492e00feec9b42cda59438e3a1c56535",2015,"Editorial Introduction: Changes on the Editorial Board","The publication of the 29th issue of the journal brings with it several changes to the editorial board.","Amato,Sara","Code4Lib","http://journal.code4lib.org/articles/10796","editorial"
"49fa1a10470740e5b9d965fca84f36af",2018,"Using XML Schema with Embedded Schematron Rules for MODS Quality Control in a Digital Repository","The Michigan State University Libraries Digital Repository relies primarily on MODS descriptive metadata to convey meaning to users and to improve discoverability and access to the libraries’ unique information resources. Because the repository relies on this metadata for so much of its functionality, it’s important that records are of consistently high quality. While creating a metadata guidelines document was an important step in assuring higher-quality metadata, the volume of MODS records made it impossible to evaluate metadata quality without some form of automated quality assessment. After considering several possible tools, an XML Schema with embedded Schematron rules was ultimately chosen for its customizability and capabilities. The two tools complement each other well: XML Schemas provide a concise method of dictating the structure of XML documents and Schematron adds more robust capabilities for writing detailed rules and checking the content of XML elements and attributes. By adding the use of this Schema to our metadata creation workflow, we’re able to catch and correct errors before metadata is entered into the repository.","Lorenzo,Lisa","Code4Lib","https://journal.code4lib.org/articles/13546","XML;MODS;Michigan;metadata creation;workflow;quality"
"4a5aa0b3fd744546aab6426b537d96f1",2021,"Pythagoras: Discovering and Visualizing Musical Relationships Using Computer Analysis","This paper presents an introduction to Pythagoras, an in-progress digital humanities project using Python to parse and analyze XML-encoded music scores. The goal of the project is to use recurring patterns of notes to explore existing relationships among musical works and composers. An intended outcome of this project is to give music performers, scholars, librarians, and anyone else interested in digital humanities new insights into musical relationships as well as new methods of data analysis in the arts.","Bellanti,Brandon","Code4Lib","https://journal.code4lib.org/articles/15949","Pythagoras;XML;music;data analysis"
"4a6b2ff4b051453b885c2597bfe51123",2017,"A Practical Starter Guide on Developing Accessible Websites","There is growing concern about the accessibility of the online content and services provided by libraries and public institutions. While many articles cover legislation, general benefits, and common opportunities to improve web accessibility on the surface (e.g., alt tags), few articles discuss web accessibility in more depth, and when they do, they are typically not specific to library web services. This article is meant to fill in this vacuum and will provide practical best practices and code.","Ng,Cynthia;Schofield,Michael","Code4Lib","http://journal.code4lib.org/articles/12697","legislation"
"4abf42a8173043628d12b0e91f788667",2016,"Introduction to Text Mining with R for Information Professionals","The 'tm:Text MiningPackage' in the open source statistical software R has made text analysis techniques easily accessible to both novice and expert practitioners, providing useful ways of analyzing and understanding large, unstructured datasets.Such an approach can yield many benefits to information professionals, particularly those involved in text-heavy research projects. This article will discuss the functionality and possibilities of text mining, as well as the basic setup necessary for novice R users to employ the RStudio integrated development environment (IDE). Common use cases, such as analyzing a corpus of text documents or spreadsheet text data, will be covered, as well as the text mining tools for calculating term frequency, term correlations, clustering, creating wordclouds, and plotting.","Maceli,Monica","Code4Lib","http://journal.code4lib.org/articles/11626","text mining;R;Rstudio;IDE;term frequency;tern correlations;clustering;wordclouds;plotting"
"4ad5109e77ef41fda031b67a2772193e",2015,"Streamlining Book Requests with Chrome","This article starts by examining why a Chrome Extension was desired and how we saw it making the workflow for requesting new items both easier and more accurate. We then go on to outline how we constructed our extension, looking at the folder structure, third party scripts and services that combine to make this achievable. Finally, the article looks at how the extension is regulated and plans for future development.","Rachel Schulkins,Dr.;Schulkins,Joseph","Code4Lib","http://journal.code4lib.org/articles/10996","chrome extensions;book requests;scripting"
"4ad60963916a481ab7beda8c4989bfdf",2010,"Building up a collaborative article database out of Open Source components","Members of a Swiss, Austrian and German network of health care libraries planned to build a collaborative article reference database. Since different libraries were cataloging articles on their own, and many national health care journals can not be found in other repositories (free or commercial) the goal was to merge existing collections and to enable participants to catalog articles on their own. As of November, 2010, the database http://bibnet.org contains 45,000 article references from 17 libraries. In this paper we will discuss how the software concept evolved and the problems we encountered during this process.","Kandera,Stefan;Fischer,Markus","Code4Lib","http://journal.code4lib.org/articles/4438","reference database;germanic space"
"4b6c84ce0c5c4e389cdae47041fbe2b5",2009,"Bibliographic Metadata Extraction from Theses","This article presents the application of part-of-speech (POS) based statistical text analysis to the task of bibliographic metadata extraction from electronic dissertations. By using the approach described here it is possible to detect the title of a Ph.D. paper with an accuracy of about 80%. The accuracy measurements are done using a conceptually simple approach and implementation.","Hatop,Götz","Code4Lib","http://journal.code4lib.org/articles/1686","part-of-speech;POS;electronic dissertations"
"4bb237a46dde4c17854717bc65e70db0",2014,"Ebooks without Vendors: Using Open Source Software to Create and Share Meaningful Ebook Collections","The Community Cookbook project began with wondering how to take local cookbooks in the library’s collection and create a recipe database. The final website is both a recipe website and collection of ebook versions of local cookbooks. This article will discuss the use of open source software at every stage in the project, which proves that an open source publishing model is possible for any library.","Weaver,Matt","Code4Lib","http://journal.code4lib.org/articles/9911","coockbook"
"4cb86aa92c0f420886658dfd68802d9b",2008,"Respect My Authority","Some simple modifications to VuFind, an open source library resource portal, improve the retrieval of both lists of works and information about authors from Wikipedia. These modifications begin to address ways that current ""next-generation"" catalogs fail to fully harness all of the bibliographic tools available for indexing and presenting author information. Simple methods such as those described in this article, which make use of full headings for authors, can offer marked improvements to these systems.","Gorman,Jonathan","Code4Lib","http://journal.code4lib.org/articles/57","VUFind;Wikipedia;bibliographic tools"
"4dfaed1ac3bd45dab9c373d161ef2ba5",2017,"Medici 2: A Scalable Content Management System for Cultural Heritage Datasets","Digitizing large collections of Cultural Heritage (CH) resources and providing tools for their management, analysis and visualization is critical to CH research. A key element in achieving the above goal is to provide user-friendly software offering
an abstract interface for interaction with a variety of digital content types. To address these needs, the Medici content management system is being developed in a collaborative effort between the National Center for Supercomputing Applications (NCSA) at the University of Illinois at Urbana-Champaign, Bibliotheca Alexandrina (BA) in Egypt, and the Cyprus Institute (CyI). The project is pursued in the framework of European Project “Linking Scientific Computing in Europe and Eastern Mediterranean 2” (LinkSCEEM2) and supported by work funded through the U.S. National Science Foundation (NSF), the U.S. National Archives and Records Administration (NARA), the U.S. National Institutes of Health (NIH), the U.S. National Endowment for the Humanities (NEH), the U.S. Office of Naval Research (ONR), the U.S. Environmental Protection Agency (EPA) as well as other private sector efforts. Medici is a Web 2.0 environment integrating analysis tools for the auto-curation of un-curated digital data, allowing automatic processing of input (CH) datasets, and visualization of both data and collections. It offers a simple user interface for dataset preprocessing, previewing, automatic metadata extraction, user input of metadata and provenance support, storage, archiving and management, representation and reproduction. Building on previous experience (Medici 1), NCSA, and CyI are working towards the improvement of the technical, performance and functionality aspects of the system. The current version of Medici (Medici 2) is the result of these efforts. It is a scalable, flexible, robust distributed framework with wide data format support (including 3D models and Reflectance Transformation Imaging-RTI) and metadata functionality. We provide an overview of Medici 2’s current features supported by representative use cases as well as a discussion of future development directions","Sophocleous,Constantinos;Marini,Luigi;Georgiou,Ropertos;Elfarargy,Mohammed;McHenry,Kenton","Code4Lib","http://journal.code4lib.org/articles/12317","digitization;cultural heritage;NCSA;Cyl;metadata;Medici;datasets"
"4e0b684d10a348aa966017e4c2b8877c",2020,"Experimenting with a Machine Generated Annotations Pipeline","The UCLA Library reorganized its software developers into focused subteams with one, the Labs Team, dedicated to conducting experiments. In this article we describe our first attempt at conducting a software development experiment, in which we attempted to improve our digital library’s search results with metadata from cloud-based image tagging services. We explore the findings and discuss the lessons learned from our first attempt at running an experiment.","Gomez,Joshua;Allen,Kristian;Matney,Mark;Awopetu,Tinuola;Shafer,Sharon","Code4Lib","https://journal.code4lib.org/articles/15209","UCLA;Labs team;software development"
"4ea525adfc864e90826f5b50c78828ce",2017,"Direct Database Access to OCLC Connexion’s Local Save File","A feature of OCLC's Connexion cataloging client unknown to most librarians is the ability to directly work with the Microsoft Access database underlying the local save file. This article provides an overview of the metadata made available through this method, including fields that cannot be accessed through the regular Connexion interface, and discusses factors to be considered when deciding whether to migrate the data to another database system instead of continuing to work with Access. Descriptions of three projects illustrate how this functionality has been applied to efficiently catalog a gift collection, find OCLC numbers for e-books, and create bibliographic records for Early English Books Online/Text Creation Partnership titles using data from multiple sources. With the option to rely only on common, off-the-shelf software, this method of directly accessing the local save file database offers a way to expand Connexion’s functionality for those unable or unwilling to work with OCLC APIs. Other benefits include the ability to import external data and to use SQL for more advanced querying. A number of limitations are also discussed, and their implications for metadata access and use are explored.","B. French,Rebecca","Code4Lib","http://journal.code4lib.org/articles/12821","API;OCLC's Connexion;SQL;"
"4f274e7be3b84d099414c8272f229a97",2014,"Use of Cue Sheets in Audio Digitization","Audio digitization is becoming essential to many libraries. As more and more audio files are being digitally preserved, the workflows for handling those digital objects need to be examined to ensure efficiency. In some instances, files are being manually manipulated when it would be more efficient to manipulate them programmatically. This article describes a time-saving solution to the problem of how to split master audio files into sub-item tracks.","Dixon,Austin","Code4Lib","http://journal.code4lib.org/articles/9314","audio;digitization;sub-item tracks"
"4fe3146693ea4a60823cc5f33cd1acec",2016,"Partnering for Discoverability: Knitting Archival Finding Aids to Digitized Material Using a Low Tech Digital Content Linking Process","As libraries continue to ramp up digitization efforts for unique archival and special collections material, the segregation of archival finding aids from their digitized counterparts presents an accumulating discoverability problem for both patrons and library staff. For Utah State University (USU) Libraries, it became evident that a system was necessary to connect both new and legacy finding aids with their digitized content to improve use and discoverability. Following a cross-departmental workflow analysis involving the Special Collections, Cataloging and Metadata, and Digital Initiatives departments, a process was created for semi-automating the batch linking of item and folder level entries in EAD finding aids to the corresponding digitized material in CONTENTdm. In addition to the obvious benefit of linking content, this cross-departmental process also allowed for the implementation of persistent identifiers and the enhancement of finding aids using the more robust metadata that accompanies digitized material. This article will provide a detailed overview of the process, as well as describe how the three departments at USU have worked together to identify key stakeholders, develop the procedures, and address future developments.","Woolcott,Liz;Payant,Andrea;Skindelien,Sara","Code4Lib","https://journal.code4lib.org/articles/11997","CONTENTdm;USU;Utah;EAD;metadata"
"502b2394063f469f93e7390703c0cbd1",2012,"Using Semantic Web Technologies to Collaboratively Collect and Share User-Generated Content in Order to Enrich the Presentation of Bibliographic Records–Development of a Prototype Based on RDF, D2RQ, Jena, SPARQL and WorldCat’s FRBRization Web Service","In this article we present a prototype of a semantic web-based framework for collecting and sharing user-generated content (reviews, ratings, tags, etc.) across different libraries in order to enrich the presentation of bibliographic records. The user-generated data is remodeled into RDF, utilizing established linked data ontologies. This is done in a semi-automatic manner utilizing the Jena and the D2RQ-toolkits. For the remodeling, a SPARQL-construct statement is tailored for each data source. In the data source used in our prototype, user-generated content is linked to the relevant books via their ISBN. By remodeling the data according to the FRBR model, and expanding the RDF graph with data returned by WorldCat's FRBRization web service, we are able to greatly increase the number of entry points to each book. We make the social content available through a RESTful web service with ISBN as a parameter. The web service returns a graph of all user-generated data registered to any edition of the book in question in the RDF/XML format. Libraries using our framework would thus be able to present relevant social content in association with bibliographic records, even if they hold a different version of a book than the one that was originally accessed by users. Finally, we connect our RDF graph to the linked open data cloud through the use of Talis’ openlibrary.org SPARQL endpoint.","Holgersen,Ragnhild;Preminger,Michael;Massey,David","Code4Lib","http://journal.code4lib.org/articles/6695","semantic web;SPARQL;RDF;Jena;D2RQ;FRBR;RESTful;API;ISBN;XML;open data cloud;Talis"
"50329df819bb44948afff05644bedfd9",2013,"Harnessing Apache Mahout to Link Content","The National Library Board of Singapore has successfully used Apache Mahout to link contents in several collections such as its Infopedia collection of articles (http://infopedia.nl.sg). This article introduces Apache Mahout (http://mahout.apache.org) and focuses on its ability to link content through text analytic techniques. The article will run through the what, why, and the how. If there is a big collection of content that needs to be linked, Apache Mahout may just be the answer.","CHINNASAMY,Balakumar;Chee Kiam,LIM","Code4Lib","http://journal.code4lib.org/articles/8912","Singapore;Apache Mahout;Infopedia;text analytics"
"5037e43c0ebb463487e03514c9dff0f4",2016,"Overly Honest Data Repository Development","After a year of development, the library at the University of Illinois at Urbana-Champaign has launched a repository, called the Illinois Data Bank (https://databank.illinois.edu/), to provide Illinois researchers with a free, self-serve publishing platform that centralizes, preserves, and provides persistent and reliable access to Illinois research data. This article presents a holistic view of development by discussing our overarching technical, policy, and interface strategies. By openly presenting our design decisions, the rationales behind those decisions, and associated challenges this paper aims to contribute to the library community's work to develop repository services that meet growing data preservation and sharing needs.","Fallaw,Colleen;Dunham,Elise;Wickes,Elizabeth;Strong,Dena;Stein,Ayla;Zhang,Qian;Rimkus,Kyle;Ingram,Bill;J. Imker,Heidi","Code4Lib","https://journal.code4lib.org/articles/11980","Urbana-Champaign;repository;Data bank;data preservation"
"5059e5af3b174048af7816ad279f15d8",2019,"Programming Poetry: Using a Poem Printer and Web Programming to Build Vandal Poem of the Day","Vandal Poem of the Day (VPOD) is a public poetry initiative led by the Center for Digital Inquiry and Learning (CDIL) at the University of Idaho Library. For four academic years VPOD has published contemporary poems daily in collaboration with
award-winning poetry presses and journals. This article details the project's genesis and history, focusing on two aspects of the project: 1) the customized WordPress site, CSS, and plugins that enable the layout, publication, and social media
promotion of the poetry and 2) the innovative means we have developed for promoting the site using receipt printers. The latter portion includes details and code related to two different physical computing projects that use receipt printers--one
using a Raspberry Pi and the other using a recycled library circulation printer-- to print individual VPOD poems on demand.","Williamson,Evan;Becker,Devin","Code4Lib","https://journal.code4lib.org/articles/14575","Vandal Poem of the Day;poetry;Idaho;VPOD;WordPress;CSS;Raspberry Pi"
"506236e226ab438585b15cdc7c07c2b6",2017,"Participatory Design Methods for Collaboration and Communication","Website redesigns can be contentious and fraught in any type of organization, and libraries are no exception. Coming to consensus on priorities and design decisions is nearly impossible, as different groups compete to ensure their subject or specialty area is represented. To keep projects on track and on time, libraries may give a few staff members the authority to make all of the decisions, while keeping user research limited to a small number of usability tests. While these tactics are sometimes necessary, at best they can leave many feeling left out of the process, and at worst, can result in major oversights in the final design.  Participatory design methods can bring users and stakeholders into the design process and ultimately lead to a better design and less friction in the project. The authors share their experience and lessons learned using participatory design techniques in a website redesign project at a large, multi-location academic library, and how these techniques facilitated communication, shaped design decisions, and kept a complex, difficult project on track.","Wood,Tara;Kompare,Cate","Code4Lib","http://journal.code4lib.org/articles/12127","design methods;participatory design techniques;project"
"507dae06f462447f99361dfd794faf04",2022,"Archiving an Early Web-Based Journal: Addressing Issues of Workflow, Authenticity, and Bibliodiversity","SWITCH is a journal of new media art that has been published in an online-only format since 1995 by the CADRE Laboratory for New Media at San José State University (SJSU). The journal is distinctive in its commitment to presenting scholarship and criticism on new media art in a visual format that reflects and enhances its engagement with the subject. This approach, which includes the practice of redesigning the journal’s platform and visual presentation for each issue, raises significant challenges for the long-term preservation of the journal, as well as immediate issues related to indexing and discovery. This article describes the initial stages of a collaboration between the Martin Luther King, Jr. Library and the CADRE Laboratory at SJSU to archive and index SWITCH and to host a copy of the journal on SJSU’s institutional repository, SJSU ScholarWorks. It will describe the process of harvesting the journal, share scripts used to extract metadata and modify files to address accessibility and encoding issues, and discuss an ongoing curricular project that engages CADRE students in the process of augmenting metadata for SWITCH articles. The process reflects the challenges of creating an authentic version of this journal that is also discoverable and citable within the broader scholarly communication environment. This effort is part of a growing multi-institutional project to archive the new media art community in the Bay Area in a 3D web exhibition format.","Szydlowski, Rhonda Holberton, Erika Johnson,Nick","Code4Lib","https://journal.code4lib.org/articles/16696","SWITCH;SJSU;journal;bibliodiversity;journal archiving"
"50d48e53b16345baafae26d97048190a",2017,"The Drawings of the Florentine Painters: From Print Catalog to Linked Open Data","The Drawings of The Florentine Painters project created the first online database of Florentine Renaissance drawings by applying Linked Open Data (LOD) techniques to a foundational text of the same name, first published by Bernard Berenson in 1903 (revised and expanded editions, 1938 and 1961). The goal was to make Berenson’s catalog information—still an essential information resource today—available in a machine-readable format, allowing researchers to access the source content through open data services. This paper provides a technical overview of the methods and processes applied in the conversion of Berenson’s catalog to LOD using the CIDOC-CRM ontology; it also discusses the different phases of the project, focusing on the challenges and issues of data transformation and publishing. The project was funded by the Samuel H. Kress Foundation and organized by Villa I Tatti, The Harvard University Center for Italian Renaissance Studies. Catalog: http://florentinedrawings.itatti.harvard.edu Data Endpoint: http://data.itatti.harvard.edu","Klic,,Lukas;Miller,Matt;K. Nelson,Jonathan;Pattuelli,Cristina;Provo,Aexandra","Code4Lib","http://journal.code4lib.org/articles/12902","LOD;CIDOC-CRM;project;Rennaissance;catalog"
"5122264e9dbb41e8ab4a77f4cc43927a",2011,"Book Review: 3 Titles from A Book Apart","Three recently published books by A Book Apart, the book-publishing arm of the website A List Apart, offer concise, high-impact introductions to three tools that can be employed in facing this challenge: HTML5, CSS3, and content strategy. This article reviews the books ""HTML5 For Web Designers"" by Jeremy Keith; ""CSS3 for Web Designers"" by Dan Cederholm; and ""The Elements of Content Strategy"" by Erin Kissane.","Mealey,Nathan","Code4Lib","http://journal.code4lib.org/articles/5552","HTML5;book review"
"5153137214484ca1973a0bd395cedced",2016,"Beyond Open Source: Evaluating the Community Availability of Software","The Code4Lib community has produced an increasingly impressive collection of open source software over the last decade, but much of this creative work remains out of reach for large portions of the library community. Do the relatively privileged institutions represented by a majority of Code4Lib participants have a professional responsibility to support the adoption of their innovations? Drawing from old and new software packaging and distribution approaches (from freeware to Docker), we propose extending the open source software values of collaboration and transparency to include the wide and affordable distribution of software. We believe this will not only simplify the process of sharing our applications within the library community, but also make it possible for less well-resourced institutions to actually use our software. We identify areas of need, present our experiences with the users of our own open source projects, discuss our attempts to go beyond open source, propose a preliminary set of technology availability performance indicators for evaluating software availability, and make an argument for the internal value of supporting and encouraging a vibrant library software ecosystem.","Davidson,Bret;Casden,Jason","Code4Lib","http://journal.code4lib.org/articles/11148","Docker;software ecosystem"
"51f52eed74934f638ae9952809af713f",2023,"Strategies for Digital Library Migration","A migration of the datastore and data model for Stanford Digital Repository’s digital object metadata was recently completed. This paper describes the motivations for this work and some of the strategies used to accomplish the migration. Strategies include: adopting a validatable data model, abstracting the datastore behind an API, separating concerns, testing metadata mappings against real digital objects, using reports to understand the data, templating unit tests, performing a rolling migration, and incorporating the migration into ongoing project work. These strategies may be useful to other repository or digital library application migrations.","Littman, Mike Giarlo, Peter Mangiafico, Laura Wrubel, Naomi Dushay, Aaron Collier, Arcadia Falcone,Justin","Code4Lib","https://journal.code4lib.org/articles/17290","API;Stanford;metadata mapping;unit testing;migration"
"5248654a5bd040649d01e50cba4aeaa6",2013,"Integrating Linked Data into Discovery","Although the Linked Data paradigm has evolved from a research idea to a practical approach for publishing structured data on the web, the performance gap between currently available RDF data stores and the somewhat older search technologies could not be closed. The combination of Linked Data with a search engine can help to improve ad-hoc retrieval. This article presents and documents the process of building a search index for the Solr search engine from bibliographic records published as linked open data.","Hatop,Götz","Code4Lib","http://journal.code4lib.org/articles/8526","RDF;Linked Data;Solr;bibliographic records"
"527e18483cef4faf81f2c36232e0d361",2008,"COLUMN:We Love Open Source Software. No, You Can't Have Our Code","Librarians are among the strongest proponents of open source software.Paradoxically, libraries are also among the least likely to actively contribute their code to open source projects.This article identifies and discusses six main reasons this dichotomy exists and offers ways to get around them.","Askey,Dale","Code4Lib","http://journal.code4lib.org/articles/527","column;open source"
"52a28bc571ad49e9bf4008024fdf3f8c",2014,"Hacking Summon 2.0 The Elegant Way","Libraries have long been adding content and customizations to vendor-provided web-based search interfaces, including discovery systems such as ProQuest’s Summon(™). Unlike solutions based on using an API, these approaches augment the vendor-designed user interface using library-provided JavaScript code. Recently, vendors have been implementing such user interfaces using client-centric model-view-controller (MVC) frameworks such as AngularJS, which are characterized by the use of modern software engineering techniques such as domain-specific markup, data binding, encapsulation, and dependency injection. Consequently, traditional approaches such as reverse-engineering the document model (DOM) have become more difficult or even impossible to use because the DOM is highly dynamic, the templates used are difficult to discern, the vendor-provided JavaScript code is both encapsulated and partially obfuscated, and the data binding mechanisms impose a strict separation of model and view that discourages direct DOM manipulation. In fact, practitioners have started to complain that AngularJS-based websites such as Summon 2.0 are very difficult to enhance with custom content in a robust and efficient manner. In this article, we show how to reverse-engineer the AngularJS-based Summon 2.0 interface to discover the modules, directives, controllers, and services it uses, and we explain how we can use AngularJS’s built-in mechanisms to create new directives and controllers that integrate with and augment the vendor-provided ones to add desired customization and interactions. We have implemented several features that demonstrate our approach, such as a click-recording script, COinS and facet customization, and the integration of eBook public notes. Our explanation and code should be of direct use for adoption or as examples for other Summon 2.0 customers, but they may also be useful to anyone faced with the need to add enhancements to other vendor-controlled MVC-based sites.","Bailey,Annette;Back,Godmar","Code4Lib","http://journal.code4lib.org/articles/10018","API;JavaScript;AngularJS;DOM;Summon;CoinS;eBook;MVC"
"533bcff47882475eabf73f8f12311636",2015,"Feminism and the Future of Library Discovery","This paper discusses the various ways in which the practices of libraries and librarians influence the diversity (or lack thereof) of scholarship and information access. We examine some of the cultural biases inherent in both library classification systems and newer forms of information access like Google search algorithms, and propose ways of recognizing bias and applying feminist principles in the design of information services for scholars, particularly as libraries re-invent themselves to grapple with digital collections.","Sadler,Bess;Bourg,Chris","Code4Lib","http://journal.code4lib.org/articles/10425","feminist principles;infrmation services"
"53cd9cec241247b2872c6bed2c173d6f",2008,"Quick Lookup Laptops in the Library: Leveraging Linux with a SLAX LiveCD","This article discusses the experiences over the past year at Laurentian University in deploying a Linux live CD solution to create customized kiosk browsers on 'quick lookup' laptops. This provides security, reliability, ease of use, and improved response time compared to other options. We explain why we chose this solution, reveal techniques we used to achieve some of our goals, and reflect on possible future iterations of this project.","Beswick,Kevin;Scott,Dan","Code4Lib","http://journal.code4lib.org/articles/49","kiosk;Linux:SLAX"
"53d88e1c88e6485993a49b2c2141e4b8",2012,"LibALERTS: An author-level subscription system","Patron requests for the ability to subscribe to their favorite authors so they could receive notifications when new titles are released, presented an opportunity for Westlake Porter Public Library to learn, to build, and to engage with patrons on the development of a new service. The library’s libALERTS service, which launched in June 2012, was the culmination of a process that involved the development of a Drupal-based website augmented with a hand-coded preprocess interface that addressed critical concerns for the effectiveness of the service.","Weaver,Matt","Code4Lib","http://journal.code4lib.org/articles/7363","libALERTS;Drupal"
"549c5be3f4c7465ab6f3ffbc0a350ab3",2017,"Editorial: Reflecting on the success and risks to the Code4Lib Journal",,"E. Murray,Peter","Code4Lib","http://journal.code4lib.org/articles/12471","editorial"
"54a638e160584141a2ff09ac7b83c4b7",2012,"Jarrow, Electronic Thesis, and Dissertation Software","Collecting and disseminating theses and dissertations electronically is not a new concept. Tools and platforms have emerged to handle various components of the submission and distribution process. However, there is not a tool that handles the entirety of the process from the moment the student begins work on their thesis to the dissemination of the final thesis. The authors have created such a tool which they have called Jarrow. After reviewing available open-source software for theses submission and open-source institutional repository software this paper discusses why and how Jarrow was created and how it works. Jarrow can be downloaded and the project followed at http://code.library.unbc.ca.","MacDonald,James;Yule,Daniel","Code4Lib","http://journal.code4lib.org/articles/7486","Jarrow;ETD;thesis"
"5577478fb1ca4bd3bfc8c75fd960d188",2008,"Googlizing a Digital Library","This article describes how we dramatically increased access to our content through the use of sitemap files and sets of browsable links. Digital libraries, when characterized by search and retrieval capabilities, are normally part of the Deep Web, inaccessible to general web crawlers and hence to generalized search engines such as Google. Yet the primary goals of digital libraries include enhancing accessibility, expanding one's audience to the general public, and promoting the library. Leveraging the capabilities of popular search engines is a potentially powerful and low-cost method of meeting these goals. An overview is provided of the problem, the solutions being developed, as well as an exploration of the current methods of remediation and their applicability to two other search engines, Yahoo! and Ask. A selection of methods is implemented for a dynamically-delivered database of 1081 finding aids (in the form of Encoded Archival Description). Access statistics (ruling out crawlers) already indicate a remarkable increase in user and hit counts as a result.","DeRidder,Jody","Code4Lib","http://journal.code4lib.org/articles/43","EAD;sitemap files;Google;search engines"
"55dd1303be374518a28b212d8abd952e",2011,"GroupFinder: A Hyper-Local Group Study Coordination System","GroupFinder is a system designed to help users working in groups let each other know where they are, what they are working on, and when they started. Students can use the GroupFinder system to arrange meetings within the library. GroupFinder also works with the phpScheduleIt room reservation system used to reserve group study rooms at the D.H. Hill Library at NCSU. Information from GroupFinder is presented on the GroupFinder web site, the mobile web site and on electronic bulletin boards within the library. How GroupFinder was developed from the initial concept through the implementation is covered in the article.","Ryan,Joe;Boyer,Josh","Code4Lib","http://journal.code4lib.org/articles/5001","GroupFinder;system:Hill;NCSU"
"5694649f753d4bfc812b63898b9cdace",2019,"Talking Portraits in the Library: Building Interactive Exhibits with an Augmented Reality App","With funding from multiple sources, an augmented-reality application was developed and tested by researchers to increase interactivity for an online exhibit. The study found that augmented reality integration into a library exhibit resulted in increased engagement and improved levels of self-reported enjoyment. The study details the process of the project including describing the methodology used, creating the application, user experience methods, and future considerations for development. The paper highlights software used to develop 3D objects, how to overlay them onto existing exhibit images and added interactivity through movement and audio/video syncing.","Patterson,Brandon","Code4Lib","https://journal.code4lib.org/articles/14838","augmented reality;study;3D"
"578b8a8485d540ba8158acf22c45398b",2021,"Better Together: Improving the Lives of Metadata Creators with Natural Language Processing","DC Public Library has long held digital copies of the full run of local alternative weekly, Washington City Paper, but had no official status as a rights grantor to enable use. That recently changed due to a full agreement being reached with the publisher. One condition of that agreement, however, was that issues become available with usable descriptive metadata and subject access in time to celebrate the upcoming 40th anniversary of the publication, which at that time was in six months. One of the most time intensive tasks our metadata specialists work on is assigning description to digital objects. This paper details how we applied Python’s Natural Language Toolkit and OpenRefine’s reconciliation functions to the collection’s OCR text to simplify subject selection for staff with no background in programming.","Kelley,Paul","Code4Lib","https://journal.code4lib.org/articles/15946","Python;DC;digital objects;OpenRefine;OCR;subject selection"
"57d1431edf014fb3b7df60b63d205c3b",2012,"Improving the presentation of library data using FRBR and Linked data","When a library end-user searches the online catalogue for works by a particular author, he will typically get a long list that contains different translations and editions of all the books by that author, sorted by title or date of issue. As an attempt to make some order in this chaos, the Pode project has applied a method of automated FRBRizing based on the information contained in MARC records. The project has also experimented with RDF representation to demonstrate how an author's complete production can be presented as a short and lucid list of unique works, which can easily be browsed by their different expressions and manifestations. Furthermore, by linking instances in the dataset to matching or corresponding instances in external sets, the presentation has been enriched with additional information about authors and works.","Westrum,Anne-Lena;Rekkavik,Asgeir;Tallerås,Kim","Code4Lib","http://journal.code4lib.org/articles/6424","MARC;Pode;project;FRBR;RDF"
"57db280d622e461291105d185c1eaef0",2013,"Breaking Up With CONTENTdm: Why and How One Institution Took the Leap toOpen Source","In 2011, College of Charleston found itself at a digital assetmanagement crossroads. The Lowcountry Digital Library (LCDL), a multi-institution cooperativefounded less than three years prior, was rapidly approaching its CONTENTdm license limit of50,000 items. Understaffed and without a programmer, the College assessed their options andultimately began construction on a Fedora Commons repository with a Blacklight discoverylayer, an installation of Rutgers’ OpenWMS for Fedora ingestion and a Drupal front end as areplacement for their existing digital library. The system has been built and over 20,000items have been migrated. The project was a success but a lot of hard lessons were learned.","Gilbert and Tyler Mobley,Heather","Code4Lib","http://journal.code4lib.org/articles/8327","Charleston;CONTENTdm;OpenVMS;Fedora;Drupal;migration;Blacklight"
"581cdfad4aa14c919593bc546018e141",2020,"Open Source Tools for Scaling Data Curation at QDR","This paper describes the development of services and tools for scaling data curation services at the Qualitative Data Repository (QDR). Through a set of open-source tools, semi-automated workflows, and extensions to the Dataverse platform, our team has built services for curators to efficiently and effectively publish collections of qualitatively derived data. The contributions we seek to make in this paper are as follows:  1. We describe ‘human-in-the-loop’ curation and the tools that facilitate this model at QDR; 2. We provide an in-depth discussion of the design and implementation of these tools, including applications specific to the Dataverse software repository, as well as standalone archiving tools written in R; and 3. We highlight the role of providing a service layer for data discovery and accessibility of qualitative data. Keywords: Data curation; open-source; qualitative data","Weber,Nicholas;Karcher,Sebastian;Myers,James","Code4Lib","https://journal.code4lib.org/articles/15436","Qualitative Data Repository;repository;QDR;scaling data"
"585e6d7eb9ad4c02a36d7c9dd98666c3",2019,"Never Best Practices: Born-Digital Audiovisual Preservation","Archivists specializing in time-based born-digital workflows walk through the technical realities of developing workflows for born-digital video. Through a series of use cases, they will highlight situations wherein video quality, subject matter, file size and stakeholder expectations decisively impact preservation decisions and considerations of ""best practice"" often need to be reframed as ""good enough.""","Kim,Julia;Fraimow,Rebecca;Titkemeyer,Erica","Code4Lib","https://journal.code4lib.org/articles/14244","archivists;use cases"
"594fb9ee35e64189900db986330db681",2020,"Building a Library Search Infrastructure with Elasticsearch","This article discusses our implementation of an Elastic cluster to address our search, search administration and indexing needs, how it integrates in our technology infrastructure, and finally takes a close look at the way that we built a reusable, dynamic search engine that powers our digital repository search. We cover the lessons learned with our early implementations and how to address them to lay the groundwork for a scalable, networked search environment that can also be applied to alternative search engines such as Solr.","Pham,Kim;Reyes,Fernando;Rynhart,Jeff","Code4Lib","https://journal.code4lib.org/articles/15203","Elastic cluster;ELK;search;Solr;search engine"
"5a6bd6fa0bfc4668b1e06a5a07d833a0",2007,"COLUMN: 700 Dollars and a Dream : Take a Chance on Koha, There’s Very Little to Lose","I truly believe that the meekest amongst us has a special duty and a special circumstance that fosters innovation. Ours is not the culture of red tape entrenched tradition, but rather the atmosphere of the pioneer. No one will notice a failed experiment in the middle of nowhere, but they’ll certainly notice a cataloguer someplace in Edema making a dent in backwards standards.","Johnson,BWS","Code4Lib","http://journal.code4lib.org/articles/28","Edema;Koha"
"5a707f1bc7b54e0e87bcebe7772d55da",2017,"Editorial: Welcome New Editors, What We Know About Who We Are, and Submission Pro Tip!","Want to see your work in C4LJ?Here's a pro tip!","Amato,Sara","Code4Lib","http://journal.code4lib.org/articles/12651","editorial"
"5abb31ae049c47af952a0aa393bd1177",2013,"Visualizing Library Statistics using Open Flash Chart 2 and Drupal","Libraries continue to need to demonstrate their value to stakeholders, and while statistics alone do not represent value, they are an important element. We found ourselves, and our stakeholders, uninspired by our infrequently updated bulleted list of statistics on our website and so set out to create a more dynamic and visually appealing look at our statistics. This article outlines how we used our content management system, Drupal, Open Flash Chart and custom programming to convert library statistics into Flash charts, including how to populate the graphs with dynamic data from external sources. The end result is our Library Statistics Dashboard (http://library.uncw.edu/facts_planning/dashboard) that visually demonstrates the use, activity and resources in the library via interactive and visually interesting graphs.","K. Wiegand,Laura;Humphrey,Bob","Code4Lib","http://journal.code4lib.org/articles/7812","Open Flash Chart;Drupal;visualization;graphs"
"5c10b30a421e4d85ac8975cb0e39c7f3",2013,"Comparing the LibraryThing, OCLC, and Open Library ISBN APIs","LibraryThing, OCLC, and the Open Library project all provide ISBN services that take an ISBN and return information about related works for that ISBN. This article compares the license terms, quality of the data returned, documentation available, and details of the APIs for the three products. The article focuses on ease of use for developers, restrictions on types of use (and assumptions about types of use built into the license or terms of use), and cost of the services.","Fiander,David","Code4Lib","http://journal.code4lib.org/articles/8715","API;license terms;data quality;LibraryThing;OCLC;Open Library;"
"5ca77e1f8e0642bcab72e545b55e96e2",2010,"Why Purchase When You Can Repurpose? Using Crosswalks to Enhance User Access","The Mansfield Library subscribes to the Readex database U.S. Congressional Serial Set, 1817-1994 (full-text historic reports of Congress and federal agencies). Given the option of purchasing MARC records for all 262,000 publications in the Serial Set or making use of free access to simple Dublin Core records provided by Readex, the library opted to repurpose the free metadata. The process that the Mansfield Library used to obtain the Dublin Core records is described, including the procedures for crosswalking the metadata to MARC and batch loading the bibliographic records complete with holdings information to the local catalog. This report shows that we successfully achieved our goals of dramatically increasing access to Serial Set material by exposing metadata in the local catalog and discusses the challenges we faced along the way. We hope that others tasked with the manipulation of metadata will be able to use what we learned from this project.","M. Keenan,Teressa","Code4Lib","http://journal.code4lib.org/articles/3604","Mansfield;Dublin Core;MARC;Readex;metadata"
"5cb9e0e3a3e4476b8b6ca14d15efdb72",2022,"Annif Analyzer Shootout:Comparing text lemmatization methods for automated subject indexing","Automated text classification is an important function for many AI systems relevant to libraries, including automated subject indexing and classification. When implemented using the traditional natural language processing (NLP) paradigm, one key part of the process is the normalization of words using stemming or lemmatization, which reduces the amount of linguistic variation and often improves the quality of classification. In this paper, we compare the output of seven different text lemmatization algorithms as well as two baseline methods. We measure how the choice of method affects the quality of text classification using example corpora in three languages. The experiments have been performed using the open source Annif toolkit for automated subject indexing and classification, but should generalize also to other NLP toolkits and similar text classification tasks. The results show that lemmatization methods in most cases outperform baseline methods in text classification particularly for Finnish and Swedish text, but not English, where baseline methods are most effective. The differences between lemmatization methods are quite small. The systematic comparison will help optimize text classification pipelines and inform the further development of the Annif toolkit to incorporate a wider choice of normalization methods.","Suominen, Ilkka Koskenniemi,Osma","Code4Lib","https://journal.code4lib.org/articles/16719","automated text classification;AI;NLP;classification;Annif;tookits;normalization methods;Annif Analyzer;automated subject indexing"
"5d31c7cb769c425fb7445990564b6d5c",2022,"Lantern: A Pandoc Template for OER Publishing","Lantern is a template and workflow for using Pandoc and GitHub to create and host multi-format open educational resources (OER) online. It applies minimal computing methods to OER publishing practices. The purpose is to minimize the technical footprint for digital publishing while maximizing control over the form, content, and distribution of OER texts. Lantern uses Markdown and YAML to capture an OER’s source content and metadata and Pandoc to transform it into HTML, PDF, EPUB, and DOCX formats. Pandoc’s options and arguments are pre-configured in a Bash script to simplify the process for users. Lantern is available as a template repository on GitHub. The template repository is set up to run Pandoc with GitHub Actions and serve output files on GitHub Pages for convenience; however, GitHub is not a required dependency. Lantern can be used on any modern computer to produce OER files that can be uploaded to any modern web server.","Diaz,Chris","Code4Lib","https://journal.code4lib.org/articles/16329","OER;YAML;EPUB;Pandoc;Lantern;template"
"5e8f3a9aea09438b9ca5181cdbcc5079",2018,"Editorial: Looking to the Past to Find the Future","I reflect on my 10+ year tenure with the Code4Lib Journal. Ponder the work of our editors and authors. And come out the other side ready for 10 more years.","Peterson,Ron","Code4Lib","https://journal.code4lib.org/articles/13778","editorial"
"5ee90a199d3f4ab692016644a9a11e31",2018,"Wayfinding Serendipity: The BKFNDr Mobile App","Librarians and staff at St. John’s University Libraries created BKFNDr, a beacon-enabled mobile wayfinding app designed to help students locate print materials on the shelves at two campus libraries. Concept development, technical development, evaluation and UX implications, and financial considerations are presented.","Dent,Valeda;Takeuchi,Kiichi;Turner,Ben;Ball,Heather;Fuchs,Caroline;Jusino,Ann;Karnik,Shilpa","Code4Lib","https://journal.code4lib.org/articles/13811","St. John;BKFNDr;mobile app;UX;costs"
"5f7e585a872d4c629e05f0ffb1262b30",2023,"Building a Large-Scale Digital Library Search Interface Using The Libraries Online Catalog","The Kentucky Digital Newspaper Program (KDNP) was born out of the University of Kentucky Libraries' (UKL) work in the National Digital Newspaper Program (NDNP) that began in 2005. In early 2021, a team of specialists at UKL from library systems, digital archives, and metadata management was formed to explore a new approach to searching this content by leveraging the power of the library services platform (Alma) and discovery system (Primo VE) licensed from Ex Libris. The result was the creation of a dedicated Primo VE search interface that would include KDNP content as well as all Kentucky newspapers held on microfilm in the UKL system. This article will describe the journey from the question of whether we could harness the power of Alma and Primo VE to display KDNP content, to the methodology used in creating a new dedicated search interface that can be replicated to create custom search interfaces of your own.","Griffith and Eric Weig,Jason","Code4Lib","https://journal.code4lib.org/articles/17257","Kentucky;newspapers;KDNP;NDNP;Primo"
"5f8ab1b910cc47ee92bd73eace2a5443",2019,"Making the Move to Open Journal Systems 3: Recommendations for a (mostly) painless upgrade","From June 2017 to August 2018, Scholars Portal, a consortial service of the Ontario Council of University Libraries, upgraded 10 different multi-journal instances of the Open Journal Systems (OJS) 3 software, building expertise on the upgrade process along the way. The final and the largest instance to be upgraded was the University of Toronto Libraries, which hosts over 50 journals. In this article, we will discuss the upgrade planning and process, problems encountered along the way, and some best practices in supporting journal teams through the upgrade on a multi-journal instance. We will also include checklists and technical troubleshooting tips to help institutions make their upgrade as smooth and worry-free as possible. Finally, we will go over post-upgrade support strategies and next steps in making the most out of your transition to OJS 3. This article will primarily be useful for institutions hosting instances of OJS 2, but those that have already upgraded, or are considering hosting the software, may find the outlined approach to support and testing helpful.","Maistrovskaya,Mariya;Newson,Kaitlin","Code4Lib","https://journal.code4lib.org/articles/14260","PKP;OJS;Ontario;best practices;multi-journal instance"
"5fa5d3aecc4542f5b9d3a3ae1b5f0a42",2014,"Technical Challenges in Developing Software to Collect Twitter Data","Over the past two years, George Washington University Libraries developed Social Feed Manager (SFM), a Python and Django-based application for collecting social media data from Twitter.Expanding the project from a research prototype to a more widely useful application has presented a number of technical challenges, including changes in the Twitter API, supervision of simultaneous streaming processes, management, storage, and organization of collected data, meeting researcher needs for groups or sets of data, and improving documentation to facilitate other institutions’ installation and use of SFM. This article will describe how the Social Feed Manager project addressed these issues, use of supervisord to manage processes, and other technical decisions made in the course of this project through late summer 2014.This article is targeted towards librarians and archivists who are interested in building collections around web archives and social media data, and have a particular interest in the technical work involved in applying software to the problem of building a sustainable collection management program around these sources.","Chudnov,Daniel;Kerchner,Daniel;Sharma,Ankushi;Wrubel,Laura","Code4Lib","http://journal.code4lib.org/articles/10097","API;George Washington University;Social Feed Manager;SFM;Python;Django;Twitter;archives"
"5fb72a8315f44b139b8c2b86a2b371eb",2013,"Editorial Introduction: How Things Change","Introducing Issue 21","Reese,Terry","Code4Lib","http://journal.code4lib.org/articles/8811","editorial"
"60f541eedd114576991857734a4ca26f",2010,"Creating a Library Database Search using Drupal","When Florida Gulf Coast University Library was faced with having to replace its database locator, they needed to find a low-cost, non-staff intensive replacement for their 350 plus databases search tool. This article details the development of a library database locator, based on the methods described in Leo Klein’s “Creating a Library Database Page using Drupal” online presentation. The article describes how the library used Drupal along with several modules, such as CCK, Views, and FCKeditor. It also discusses various Drupal search modules that were evaluated during the process.","M. Rosenthal,Danielle;Bernardo,Mario","Code4Lib","http://journal.code4lib.org/articles/2920","Drupal;database;Florida Gulf Coast;FCKeditor"
"61c7680d46364805a1488917d73455cd",2013,"The Format Registry Problem","File format identification is an important issue in digital preservation. Several noteworthy attempts, including PRONOM, GDFR, and UDFR, have been made at creating a comprehensive repository of format information. The sheer amount of information to cover and the constant introduction of new formats and format versions has limited their success. Alternative approaches, such as Linked Data and offering limited per-format information with identifiers that can be used elsewhere, may lead to greater success.","McGath,Gary","Code4Lib","http://journal.code4lib.org/articles/8029","PRONOM;GDFR;UDFR;Linked Data;format identification"
"6236fc100b9c45d88f4c46d3cf2081d1",2017,"Tools and Workflows for Collaborating on Static Website Projects","Static website generators have seen a significant increase in popularity in recent years, offering many advantages over their dynamic counterparts. While these generators were typically used for blogs, they have grown in usage for other web-based projects, including documentation, conference websites, and image collections. However, because of their technical complexity, these tools can be inaccessible to content creators depending on their level of technical skill and comfort with web development technologies. Drawing from experience with a collaborative static website project, this article will provide an overview of static website generators, review different tools available for managing content, and explore workflows and best practices for collaborating with teams on static website projects.","Newson,Kaitlin","Code4Lib","http://journal.code4lib.org/articles/12779","static web pages;generators;tools"
"623ac1207b6e4217940961e7dcc22f34",2019,"Design reusable SHACL shapes and implement a linked data validation pipeline","In July 2017, W3C published SHACL as the standard to validate RDF. Since then, data modellers have the possibility to provide validation services based on SHACL shapes together with their models, however there are considerations to be taken in account when creating them. This paper aims to list such considerations and shows an example of a validation pipeline to address them.","Stani,Emidio","Code4Lib","https://journal.code4lib.org/articles/14711","SHACL;RDF;SHACL shapes:validation pipeline"
"62f5c636e52f44608e0ab6c03265a556",2018,"Spinning Communication to Get People Excited About Technological Change","Many organizations struggle with technological change. Often, the challenges faced are due to fear of change from stakeholders within the institution. Users grow accustomed to certain user interfaces, to processes associated with a specific system, and they can be frustrated when they have to revisit how they interact with a system, especially one that they use on a daily basis. This article will discuss how to acknowledge the fears associated with technological change and will suggest communication tactics and strategies to ease transitions. Specific scenarios and examples from the author’s experiences will be included.","Conrad,Suzanna","Code4Lib","https://journal.code4lib.org/articles/13641","technological change;user interfaces;habits"
"637115af857048c0bd44ebd688a21904",2013,"Providing Information about Reading Lists via a Dashboard Interface","As developers of the open source LORLS Resource/Reading List Management System we have developed a dashboard to better support academic staffs’ understanding of how their students use reading lists. This dashboard provides both graphical and tabulated information drawn from LORLS and the Aleph Integrated Library System. Development of the dashboard required changes to back-end functionality of LORLS such as logging views of reading lists and caching of loan data. Changes to the front end included the use of HTML5 canvas elements to generate pie charts and line graphs. Recently launched to academic staff at Loughborough University, the dashboard has already garnered much praise. It is hoped that further development of the dashboard will provide even more support for academics in the compilation of their reading lists.","Jason Cooper,Dr;Brewerton,DGary;Jon Knight,Dr","Code4Lib","http://journal.code4lib.org/articles/7745","LORLS;HTML5;canvas;Loughborough;dashboard;visualization"
"64695f4790b94011a6a12af1fedf6ea4",2016,"From Digital Commons to OCLC: A Tailored Approach for Harvesting and Transforming ETD Metadata into High-Quality Records","The library literature contains many examples of automated and semi-automated approaches to harvest electronic theses and dissertations (ETD) metadata from institutional repositories (IR) to the Online Computer Library Center (OCLC). However, most of these approaches could not be implemented with the institutional repository software Digital Commons because of various reasons includingproprietary schema incompatibilities and high level programming expertise requirements our institution did not want to pursue. Only one semi-automated approach was found in the library literature which met our requirements for implementation, and even though it catered to the particular needs of the DSpace IR, it could be implemented to other IR software if further customizations were applied. The following paper presents an extension of this semi-automated approach originally created by Deng and Reese, but customized and adapted to address the particular needs of the Digital Commons community and updated to integrate the latest Resource Description & Access (RDA) content standards for ETDs. Advantages and disadvantages of this workflow are discussed and presented as well.","Veve,Marielle","Code4Lib","http://journal.code4lib.org/articles/11676","ETD;institutional repositories;ETD;OCLC;RDA;workflow;quality"
"660d738c757c462b9581cbdaf7b630a0",2017,"The Semantics of Metadata: Avalon Media System and the Move to RDF","The Avalon Media System (Avalon) provides access and management for digital audio and video collections in libraries and archives. The open source project is led by the libraries of Indiana University Bloomington and Northwestern University and is funded in part by grants from The Andrew W. Mellon Foundation and Institute of Museum and Library Services. Avalon is based on the Samvera Community (formerly Hydra Project) software stack and uses Fedora as the digital repository back end. The Avalon project team is in the process of migrating digital repositories from Fedora 3 to Fedora 4 and incorporating metadata statements using the Resource Description Framework (RDF) instead of XML files accompanying the digital objects in the repository. The Avalon team has worked on the migration path for technical metadata and is now working on the migration paths for structural metadata (PCDM) and descriptive metadata (from MODS XML to RDF). This paper covers the decisions made to begin using RDF for software development and offers a window into how Semantic Web technology functions in the real world.","L. Hardesty,Juliet;B. Young,Jennifer","Code4Lib","http://journal.code4lib.org/articles/12668","Avalon;fedora:RDF;XML;MODS;Hydra Project;metadata semantics"
"666d30121f83484cbe0cf7a104dbe034",2013,"Keeping up with Ebooks: Automated Normalization and Access Checking withNormac","Cataloging ebooks is difficult to do well, as they are often purchasedin large collections, sometimes with only low-quality cataloging copy available. MARC records may be provided upfront in a large batch, or trickle in one at a time as they become available. Records may contain links that point nowhere, to the wrong book, or to an offer tosell you the book you already own. Loading records sight unseen may introduce inconsistency or overlay good print records with poor electronic ones, making the catalog much more difficult to search. This article describes in more detail the major challenges in ebook cataloging, record normalization and access checking, and introduces Normac: an open source web-based tool for processing MARC records.","Lybarger,Kathryn","Code4Lib","http://journal.code4lib.org/articles/8375","Ebooks;cataloguing;MARC;Normac;tool"
"66bb472d520c4b41a43f591acd012bad",2013,"Workflow Tools for Digital Curation","Maintaining usable and sustainable digital collections requires a complex set of actions that address the many challenges at various stages of the digital object lifecycle. Digital curation activities enhance access and retrieval, maintain quality,add value, and facilitate use and re-use over time. Digital resource lifecycle management is becoming an increasingly important topic as digital curators actively explore software tools that perform metadata curation and file management tasks. Accordingly, the University of NorthTexas (UNT) Libraries develop tools and workflows that streamline production and quality assurance activities. This article demonstrates two open source software tools, AutoHotkey and Selenium IDE, which the UNT Digital Libraries Division has adopted for use during the pre-ingest and post-ingest stages of the digital resource lifecycle.","James Weidner,Andrew;Gelaw Alemneh,Daniel","Code4Lib","http://journal.code4lib.org/articles/8419","UNT;North Texas;digital objects;lifecycle;quality assurance;digital curation;Selenium"
"66bcde511f864fbc98738ccbabd13dc5",2018,"Accio e-Libri: Magically Delivering Digital Resources to Patrons Using NFC Technology","To coincide with the 20th anniversary of the publication of Harry Potter and the Philosopher’s/Sorcerer’s Stone, our library created a Happee Birthdae Harry display incorporating Near Field Communication (NFC) technology alongside print materials in order to magically place electronic resources in our users’ hands. The display was a spellbinding success, increasing usage of both print and electronic items, and helping our students become familiar with this innovative technology in an engaging manner. This article will provide step-by-step instructions on the materials and procedures librarians need to implement NFC technology in their own libraries, and will discuss the challenges and opportunities associated with this rapidly spreading technology.","M. Jimenez,Christopher;M. Sorondo,Barbara","Code4Lib","http://journal.code4lib.org/articles/13308","NFC;Accio e-Libri"
"6705fa9ae9774b8c8c03c3a4a3014c33",2011,"Joining an Open Source Community: Creating a Symphony Connector for the XC NCIP Toolkit","When the Pennsylvania Academic Library Consortium, Inc. (PALCI) decided to upgrade its resource sharing software (EZ-Borrow) all of the participating libraries – among them Lehigh University – were responsible to have in place an implementation of the NCIP protocol to provide communication between the new EZ-Borrow software developed by Relias International and their respective ILS. This article presents the process of Lehigh choosing to adopt the eXtensible Catalog NCIP Toolkit, and the technical details about building a connector with the SirsiDynix Symphony ILS.","Suranofsky,Michelle","Code4Lib","http://journal.code4lib.org/articles/5608","Pennsylvania;EX-Borrow;NCIP protocol;ILS"
"6728a80e74dd4ecf970853a7ee6ee502",2015,"Improving Access to Archival Collections with Automated Entity Extraction","The complexity and diversity of archival resources make constructing rich metadata records time consuming and expensive, which in turn limits access to these valuable materials. However, significant automation of the metadata creation process would dramatically reduce the cost of providing access points, improve access to individual resources, and establish connections between resources that would otherwise remain unknown. Using a case study at Oregon Health & Science University as a lens to examine the conceptual and technical challenges associated with automated extraction of access points, we discuss using publically accessible API’s to extract entities (i.e. people, places, concepts, etc.) from digital and digitized objects. We describe why Linked Open Data is not well suited for a use case such as ours. We conclude with recommendations about how this method can be used in archives as well as for other library applications.","Banerjee,Kyle;Johnson,Max","Code4Lib","http://journal.code4lib.org/articles/10726","API;Oregon;health;archival collectons;entities extraction;lod;linked open data"
"67758cb79bb341dd873750222f7dc23f",2009,"Using a Web Services Architecture with Me, Myself and I","The UW-Madison Libraries Library Course Page system is used to deliver electronic reserves materials and course-focused library instruction webpages to students. As part of a rewrite of our system we broke the application into three component pieces: a file repository, a course timetable data service, and an interface application for building and viewing individual course pages. The new three-piece system was written with an inward facing service-oriented architecture that allowed us to choose the best technologies to solve each of the tasks the entire system needs to accomplish.","Meyer,Stephen","Code4Lib","http://journal.code4lib.org/articles/1771","web service; architecture;UW-Madison"
"67855817d985403d92425e47d2cc9c8d",2013,"Editorial Introduction: Join Us at the Table","Introducing Issue 22","Amato,Sara","Code4Lib","http://journal.code4lib.org/articles/9052","editorial"
"68501952176a4e1aa45a9968b707d144",2018,"Extending and Adapting Metadata Audit Tools for Mountain West Digital Library Members","As a DPLA regional service hub, Mountain West Digital Library harvests metadata from 16 member repositories representing over 70 partners throughout the Western US and hosts over 950,000 records in its portal. The collections harvested range in size from a handful of records to many thousands, presenting both quality control and efficiency issues. To assist members in auditing records for metadata required by the MWDL Metadata Application Profile before harvesting, MWDL hosts a metadata auditing tool adapted from North Carolina Digital Heritage Center’s original DPLA OAI Aggregation Tools project, available on GitHub. The tool uses XSL tests of the OAI-PMH stream from a repository to check conformance of incoming data with the MWDL Metadata Application Profile. Use of the tool enables student workers and non-professionals to perform large-scale metadata auditing even if they have no prior knowledge of application profiles or metadata auditing workflows. In the spring of 2018, we further adapted and extended this tool to audit collections coming from a new member, Oregon Digital. The OAI-PMH provision from Oregon Digital’s Samvera repository is configured differently than that of the CONTENTdm repositories used by existing MWDL members, requiring adaptation of the tool. We also extended the tool by adding the Dublin Core Facet Viewer, which gives the ability to view and analyze values used in both required and recommended fields by frequency. Use of this tool enhances metadata completeness, correctness, and consistency. This article will discuss the technical challenges of project, offer code samples, and offer ideas for further updates.","K. Hebron,Teresa","Code4Lib","https://journal.code4lib.org/articles/13632","metadata audit;DPLA;Mountain West;quality;quality control;MWDL;OAI;OAI-PMH;Oregon;CONTENTdm;Dublin Core;technical challenges"
"6862502978ce4504b59f0370a3cd9135",2013,"Using a Raspberry Pi as a Versatile and Inexpensive Display Device","This article covers the process by which a library took some unused equipment and added a cheap computing device to produce very inexpensive but effective electronic signage. Hardware and software issues as well as a step-by-step guide through the process are included.","Iglesias,Edward;Schlegel,Arianna","Code4Lib","http://journal.code4lib.org/articles/8644","computing device;hardware;raspberry pi"
"6886ba3e70104950af870d05f121aa36",2022,"The DSA Toolkit Shines Light Into Dark and Stormy Archives","Themed web archive collections exist to make sense of archived web pages (mementos). Some collections contain hundreds of thousands of mementos. There are many collections about the same topic. Few collections on platforms like Archive-It include standardized metadata. Reviewing the documents in a single collection thus becomes an expensive proposition. Search engines help find individual documents but do not provide an overall understanding of each collection as a whole. Visitors need to be able to understand what individual collections contain so they can make decisions about individual collections and compare them to each other. The Dark and Stormy Archives (DSA) Project applies social media storytelling to a subset of a collection to facilitate collection understanding at a glance. As part of this work, we developed the DSA Toolkit, which helps archivists and visitors leverage this capability. As part of our recent International Internet Preservation Consortium (IIPC) grant, Los Alamos National Laboratory (LANL) and Old Dominion University (ODU) piloted the DSA toolkit with the National Library of Australia (NLA). Collectively we have made numerous improvements, from better handling of NLA mementos to native Linux installers to more approachable Web User Interfaces. Our goal is to make the DSA approachable for everyone so that end-users and archivists alike can apply social media storytelling to web archives.","M. Jones,Shawn;R. Jayanetti,Himarsha;Osborne,Alex;Koerbin,Paul;Klein,Martin;C. Weigle,Michele;L. Nelson,Michael","Code4Lib","https://journal.code4lib.org/articles/16441","mementos;DSA;project;archived;IIPC;Los Alamos;web archives"
"69600e37a0a04a2491e7aeae4e366f21",2022,"Building CyprusArk a Web Content Management System for Small Museums Collections Online","This article introduces CyprusArk, a work-in-progress solution to the problems that small museums in Cyprus have in providing online access to their collections. CyprusArk is an open-source web content management system for small museums’ online collections. Developed as part of Avgousti’s Ph.D. thesis, based on qualitative data collected from six small museums in Cyprus.","Avgousti, Georgios Papaioannou, and Feliz Ribeiro Gouveia,Avgoustinos","Code4Lib","https://journal.code4lib.org/articles/16722","CyprusArk;museums;cms"
"696b120c40d248b182a23318a5659a7a",2019,"BC Digitized Collections: Towards a Microservices-based Solution to an Intractable Repository Problem","Our Digital Repository Services department faced a crisis point in late 2017. Ourvendor discontinued support for our digital repository software, and an intensive, multi-department, six-month field survey had not turned up any potential replacements that fully met our needs. We began to experiment with a model that, rather than migrating to a new monolithic system, would more closely integrate multiple systems that we had already implemented—ArchivesSpace, Alma, Primo, and MetaArchive—and introduce only one new component, namely Mirador. We determined that this was the quickest way to meet our needs, and began a full migration in spring of 2018. The primary benefit of a microservices-based solutionfor our collections was the potential for customization; we therefore present our experiences in building and migrating to this system not as a blueprint but as a case study with lessons learned. Our hope is that in sharing our experience, we can help institutions in similar situations determine 1) whether a microservices-based solution is a feasible approach to their problem, 2) which services could and should be integrated and how, and 3) whether the trade-offs inherent in this architectural approach are worth the flexibility it offers.","Mayo, Adam Jazairi, Paige Walker, Luke Gaudreau,Chris","Code4Lib","https://journal.code4lib.org/articles/14445","migration;Mirador;microservices"
"69bb0d6356144ed2b8751b01995a439f",2017,"Leveraging Python to improve ebook metadata selection, ingest, and management","Libraries face many challenges in managing descriptive metadata for ebooks, including quality control, completeness of coverage, and ongoing management. The recent emergence of library management systems that automatically provide descriptive metadata for e-resources activated in system knowledge bases means that ebook management models are moving toward both greater efficiency and more complex implementation and maintenance choices. Automated and data-driven processes for ebook management have always been desirable, but in the current environment, they become necessary. In addition to initial selection of a record source, automation can be applied to quality control processes and ongoing maintenance in order to keep manual, eyes-on work to a minimum while providing the best possible discovery and access. In this article, we describe how we are using Python scripts to address these challenges.","Thompson,Kelly;Traill,Stacie","Code4Lib","http://journal.code4lib.org/articles/12828","Python;descriptive metadata;quality control;ebook"
"69f84a270b07476da9bec070a645094c",2010,"Map it @ WSU: Development of a Library Mapping System for Large Academic Libraries","The Wayne State Library System launched its library mapping application in February 2010, designed to help locate materials in the five WSU libraries. The system works within the catalog to show the location of materials, as well as provides a web form for use at the reference desk. Developed using PHP and MySQL, it requires only minimal effort to update using a unique call number overlay mechanism. In addition to mapping shelved materials, the system provides information for any of the over three hundred collections held by the WSU Libraries. Patrons can do more than just locate a book on a shelf: they can learn where to locate reserve items, how to access closed collections, or get driving maps to extension center libraries. The article includes a discussion of the technology reviewed and chosen during development, an overview of the system architecture, and lessons learned during development.","Gallagher,Paul","Code4Lib","http://journal.code4lib.org/articles/3072","Wayne State;library mapping;system"
"6a2db7035d0047ea9e84a3fc65db4c57",2009,"Tree Representations: Graphics Libraries for Displaying Hierarchical Data","Tree representations can be useful for presenting hierarchical data on the screen. In this article I’ll briefly describe building trees using the Dojo, Yahoo User Interface, Java Server Faces, and Google Web Toolkit libraries.","Wilhelm,Mark","Code4Lib","http://journal.code4lib.org/articles/1083","graphic libraries;hierarchical data"
"6a3c8e1ad33744ba9ec60ce293f73d22",2016,"Checking the identity of entities by machine algorithms: the next step to the Hungarian National Namespace","The redundancy of entities coming from different sources caused problems during the building of the personal name authorities for the Petőfi Museum of Literature. It was a top priority to cleanse and unite classificatory records which have different data content but pertain to the same person without losing any data. As a first step in 2013, we found identities in approximately 80,000 name records so we merged the data content of these records. In the second phase a much more complicated algorithm had to be applied to show these identities. We cleansed the database by uniting approximately 36,000 records. The workflow for automatic detection of authority data tries to follow human intelligence. The database scripts normalize and examine about 20 kinds of data elements according to information about dates, localities, occupation and name variations. The result of creating pairs from the database authority records, as potential redundant elements, was a graph, which was condensed to a tree, by human efforts of the curators of the museum.With this, the limit of technological identification was reached. For further data cleansing human intelligence that can be assisted by computerized regular monitoring is needed, based upon the developed algorithm. As a result, the service containing about 620,000 authority name records will be an indispensable foundation to the establishment of the National Name Authorities. This article shows the work process of unification.","Bánki,Zsolt;Mészáros,Tibor;Németh,Márton;Simon,András","Code4Lib","http://journal.code4lib.org/articles/11765","entity redundancy;Petőfi Museum of Literature;authority data;Hungarian National Namespace;hungary;Petőfi"
"6ab360b84ea94692808b5ad97f6df292",2008,"Unveiling Jangle: Untangling Library Resources and Exposing them through the Atom Publishing Protocol","The Jangle project intends to expose the data hidden in library systems by using the Atom Publishing Protocol to provide simple, consistent access to content and resources. The lack of uniform access to the underlying data in library systems is a major impediment to library development. The Jangle project has the potential to enable new development opportunities by leveraging simple to use and easy to understand processes.This article discusses the benefits of the Atom Publishing Protocol and how Jangle utilizes it, including a description of the current JangleR reference implementation and case studies of the simplicity of developing within the framework.","Farrugia,James;Singer,Ross","Code4Lib","http://journal.code4lib.org/articles/109","API;app;atom;atompub;jangle;JangleR;protocol"
"6abbc14098a74bee8db74003891385fe",2012,"Using VuFind, XAMPP, and Flash Drives to Build an Offline Library Catalog for Use in a Liberal Arts in Prison Program","When Grinnell College expanded its Liberal Arts in Prison Program to include the First Year of College Program in the Newton Correctional Facility, the Grinnell College Libraries needed to find a way to support the research needs of inmates who had no access to the Internet. The library used VuFind running on XAMPP installed on flash drives to provide access to the Libraries' catalog. Once the student identified a book, it would be delivered from the Libraries to students on request. This article describes the process of getting VuFind operating in an environment with no Internet access and limited control of the computing environment.","Bauder,Julia","Code4Lib","http://journal.code4lib.org/articles/6225","Grinnell College;prisons;VuFind;XAMPP;computing environment;correctional facilities"
"6ae02ec061bf4a098b50a644b358ed67",2021,"On the Nature of Extreme Close-Range Photogrammetry: Visualization and Measurement of North African Stone Points","Image acquisition, visualization, and measurement are examined in the context of extreme close-range photogrammetric data analysis. Manual measurements commonly used in traditional stone artifact investigation are used as a starting point to better gauge the usefulness of high-resolution 3D surrogates and the flexible digital tool sets that can work with them. The potential of various visualization techniques are also explored in the context of future teaching, learning, and research in virtual environments.","J. Bennett,Michael","Code4Lib","https://journal.code4lib.org/articles/15769","3D;image aquisition;photogrammetry;data analysis;visualization;virtual environments"
"6bcbf89aeb80469fbbff468b2ee77a4a",2010,"Creating an Institutional Repository for State Government Digital Publications","In 2008, the Library of Virginia (LVA) selected the digital asset management system DigiTool to host a centralized collection of digital state government publications. The Virginia state digital repository targets three primary user groups: state agencies, depository libraries and the general public. DigiTool's ability to create depositor profiles for individual agencies to submit their publications, its integration with the Aleph ILS, and product support by ExLibris were primary factors in its selection. As a smaller institution, however, LVA lacked the internal resources to take full advantage of DigiTool's full set of features. The process of cataloging a heterogenous collection of state documents also proved to be a challenge within DigiTool. This article takes a retrospective look at what worked, what did not, and what could have been done to improve the experience.","Lo,Meikiu;M. Thomas,Leah","Code4Lib","http://journal.code4lib.org/articles/2563","Virginia;DigiTool;Aleph ILS;institutional repository;digital publications"
"6bfe6bc8f84a406a800eaa1ad342cb35",2018,"Getting Real in the Library: A Case Study at the University of Florida","In the fall of 2014, the University of Florida (UF) Marston Science Library, in partnership with UF IT, opened a new computer lab for students to learn and develop mobile applications.The Mobile Application Development Environment (MADE@UF) features both software and circulating technology for students to use in an unstructured and minimally-staffed environment.As the technological landscape has shifted in the past few years, virtual and augmented reality have become more prominent and prevalent, signaled by companies like Facebook, Google, and Microsoft making significant financial investments in these technologies.During this evolution, MADE@UF has migrated to focus more on virtual and augmented reality, and we will discuss the opportunities and challenges that hosting and managing such a space has provided to the science library and its staff.","R. Putnam,Samuel;Russell Gonzalez,Sara","Code4Lib","http://journal.code4lib.org/articles/13201","augmented reality;case study;Florida"
"6d29564a5abb4ec79e6707337c7abd04",2014,"Editorial Introduction: Seeking a Diversity of Voices","Making the Journal the best that it can be.","Peterson,Ron","Code4Lib","http://journal.code4lib.org/articles/9345","editorial"
"6d7a791ba5494555a7e4eda1a3bd55bd",2010,"Automatic Aggregation of Faculty Publications from Personal Web Pages","Many researchers make their publications available on personal web pages. In this paper, we propose a simple method for the automatic aggregation of these documents. We search faculty web pages for archived publications and present their full text links together with the author's name and short content excerpts on a comprehensive web page. The excerpts are generated simply by querying a standard web search engine.","Horstmann,Wolfram;Lösch,Mathias;Jahn,Najko","Code4Lib","http://journal.code4lib.org/articles/3765","web pages;search engine"
"6e21dc18b6654183b426e07c2b0b1b85",2021,"Assessing High-volume Transfers from Optical Media at NYPL","NYPL’s workflow for transferring optical media to long-term storage was met with a challenge: an acquisition of a collection containing thousands of recordable CDs and DVDs. Many programs take a disk-by-disk approach to imaging or transferring optical media, but to deal with a collection of this size, NYPL developed a workflow using a Nimbie AutoLoader and a customized version of KBNL’s open-source IROMLAB software to batch disks for transfer. This workflow prioritized quantity, but, at the outset, it was difficult to tell if every transfer was as accurate as it could be. We discuss the process of evaluating the success of the mass transfer workflow, and the improvements we made to identify and troubleshoot errors that could occur during the transfer. A background of the institution and other institutions’ approaches to similar projects is given, then an in-depth discussion of the process of gathering and analyzing data. We finish with a discussion of our takeaways from the project.","Rothrock,Michelle;Rhonemus,Alison;Krabbenhoeft,Nick","Code4Lib","https://journal.code4lib.org/articles/15908","NYPL;optical media;IROMLAB;data analysis;migration"
"6f8b45da822c4970a3bec5b11aad31d3",2011,"From ISIS to CouchDB: Databases and Data Models for Bibliographic Records","For decades bibliographic data has been stored in non-relational databases, and thousands of libraries in developing countries still use ISIS databases to run their OPACs. Fast forward to 2010 and the NoSQL movement has shown that non-relational databases are good enough for Google, Amazon.com and Facebook. Meanwhile, several Open Source NoSQL systems have appeared. This paper discusses the data model of one class of NoSQL products, semistructured, document-oriented databases exemplified by Apache CouchDB and MongoDB, and why they are well-suited to collective cataloging applications. Also shown are the methods, tools, and scripts used to convert, from ISIS to CouchDB, bibliographic records of LILACS, a key Latin American and Caribbean health sciences index operated by the Pan-American Health Organization.","Ramalho,Luciano","Code4Lib","http://journal.code4lib.org/articles/4893","ISIS;CouchDB;databases;bibliographic records;LILACS;MongoDB;Latin America"
"6fe3a0f1098446dbb408f3127427bfcd",2008,"Bringing Sheet Music to Life: My Experiences with OMR","This article describes the process of digitizing sheet music celebrating Pullman porters and rail travel from the 1870s-1920s. The process involves 1) digitizing sheet music, 2) running the digitized sheet music through an Optical Musical Recognition (OMR) software package, 3)cleaning up the resulting file, 4) converting it into an .mp3/MIDI file, and 5) tweaking it to use the voices/instruments of a music editing software program. The pros and cons of some popular OMR programs are discussed.","Bullen,Andrew","Code4Lib","http://journal.code4lib.org/articles/84","music;OMR;Pullman;Optical Musical Recognition;MIDI"
"711147d19b1b4ff6af18998c0387ed51",2015,"User Experience is a Social Justice Issue","When we're building services for people, we often have a lot more practice seeing from the computer's point of view than seeing from another person's point of view. The author asks the library technology community to consider several case studies in this problem, including their root causes, and the negative impact of this problem on achieving our mission as library technologists. The author then recommends specific actions that we, as individual contributors and organizations, can take to increase our empathy and improve the user experience we provide to patrons.","Harihareswara,Sumana","Code4Lib","http://journal.code4lib.org/articles/10482","social justice;patrons;empathy"
"711f88ee637f48e28a8af88ee62fc046",2011,"A Novel Method for Creating a Distributed, Collaborative Commenting Environment for Bibliographic Items","This paper discusses a novel approach to adding user comments to existing platforms for bibliographic information, such as library catalogs. The application is built using simple and free services that support advanced functionality at a low price without requiring high-level technical skills. The strength of the approach described here is that it increases the number of comments available for display in any local catalog by consolidating comments from multiple sites and by clustering comments at the FRBR Work level. To do this, a central store of comments from multiple sites is created. In addition, the application uses ISBNs and OCLC's Work IDs to consolidate comments from different publications (FRBR manifestations) for the same work.","Thomas Greenall,Rurik","Code4Lib","http://journal.code4lib.org/articles/5339","FRBR;bibliographic items;OCLC"
"714b20173454434fa632ee1e588abcd7",2014,"Getting What We Paid for: a Script to Verify Full Access to E-Resources","Libraries regularly pay for packages of e-resources containing hundreds to thousands of individual titles. Ideally, library patrons could access the full content of all titles in such packages. In reality, library staff and patrons inevitably stumble across inaccessible titles, but no library has the resources to manually verify full access to all titles, and basic URL checkers cannot check for access. This article describes the E-Resource Access Checker—a script that automates the verification of full access. With the Access Checker, library staff can identify all inaccessible titles in a package and bring these problems to content providers’ attention to ensure we get what we pay for.","M. Spurgin,Kristina","Code4Lib","http://journal.code4lib.org/articles/9684","e-resources;costs"
"7215f7d1c074425d97307887a925e112",2023,"Utilizing R and Python for Institutional Repository Daily Jobs","In recent years, the programming languages R and Python have become very popular and are being used by many professions. However,they are not just limited to data scientists or programmers; they can also help librarians to perform many tasks more efficiently and possibly achieve goals that were almost impossible before. R and Python are scripting languages, which means they are not very complicated. With minimal programming experience, a librarian can learn how to program in these languages and start to apply them to work. This article provides examples of how to use R and Python to clean up metadata, resize images, and match transcripts with scanned images for the Colorado State University Institutional Repository.","Zhou,Yongli","Code4Lib","https://journal.code4lib.org/articles/17134","R;Python;institutional repository;Colorado"
"726043dbb9f14914add2e181e4df5cf0",2008,"Participatory Design of Websites with Web Design Workshops","At the University of Rochester's River Campus Libraries we have included users in technology development with great success. ""Participatory design"" entails collaboration among designers, developers, and users from the earliest stages of conception through to implementation of websites and other technology. Using participatory methods, a project to redesign the library website began with workshops to identify user needs and preferences. The results of these workshops led to the identification of key tasks for the main page. They also generated a hierarchy of tasks for sub-pages and rich information about how students and faculty members use current websites in their work. In our article, we explain our reasons for running participatory design workshops, describe our methods, review participants and recruitment, and summarize key findings. We also include information about our local implementation and general conclusions about the value of design workshops for website design and development.","Bersani,Alison;Dimmock,Nora;Fried Foster,Nancy","Code4Lib","http://journal.code4lib.org/articles/53","Rochester's River;participatory designs;workshops"
"72821896a84f40b18b91be8da9aff683",2013,"Batch metadata assignment to archival photograph collections using facial recognition software","Useful metadata is essential to giving individual meaning and value within the context of a greater image collection as well as making them more discoverable. However, often little information is available about the photos themselves, so adding consistent metadata to large collections of digital and digitized photographs is a time consuming process requiring highly experienced staff. By using facial recognition software, staff can identify individuals more quickly and reliably. Knowledge of individuals in photos helps staff determine when and where photos are taken and also improves understanding of the subject matter. This article demonstrates simple techniques for using facial recognition software and command line tools to assign, modify, and read metadata for large archival photograph collections.","Banerjee,Kyle;Anderson,Maija","Code4Lib","http://journal.code4lib.org/articles/8486","metadata;photograps;facial recognition"
"72a73299846d41d9acd44aa147ae60b6",2019,"Factor Analysis For Librarians in R","This paper offers a primer in the programming language R for library staff members to perform factor analysis. It presents a brief overview of factor analysis and walks users through the process from downloading the software (R Studio) to performing the actual analysis. It includes limitations and cautions against improper use.","Carlozzi,Michael","Code4Lib","https://journal.code4lib.org/articles/14821","R;primer;factor analysis;Rstudio"
"72c765bda25a47738ac1e29da32f5e4b",2021,"Robustifying Links To Combat Reference Rot","Links to web resources frequently break, and linked content can change at unpredictable rates. These dynamics of the Web are detrimental when references to web resources provide evidence or supporting information. In this paper, we highlight the significance of reference rot, provide an overview of existing techniques and their characteristics to address it, and introduce our Robust Links approach, including its web service and underlying API. Robustifying links offers a proactive, uniform, and machine-actionable way to combat reference rot. In addition, we discuss our reasoning and approach aimed at keeping the approach functional for the long term. To showcase our approach, we have robustified all links în this article.","Jones,Shawn;Klein,Martin;Van de Sompel,Herbert","Code4Lib","https://journal.code4lib.org/articles/15509","link rot;API;robustifying"
"73680aaa15294d2d9c1e26db0e5d1c07",2016,"Consortial-Based Customizations for New Primo UI","Users interested in customizing their Primo installation are required to configure specific settings, files, and code during the View setup process. A consequence of this is that unique customizations are not easily sharable between institutions. With the release of the new Primo User Interface, Ex Libris has enabled institutions to manage interface customizations via the Package Customization Manager. In the summer of 2016, an Orbis Cascade Alliance working group investigated the efficacy of the Package Manager as a means of centrally sharing and deploying Orbis Cascade Alliance Primo Toolkit customizations. By virtue of passively loading customizations to the central package, each institution could pass custom parameters with local JS in order to adapt central customizations to the specific needs of that institution’s users. This article will address both the potential and the limitations of the Primo Package Customization Manager. It will also provide best practices for consortia seeking to centrally manage and share Primo enhancements and it will identify areas of future development for centrally shared customizations.","Moore,Dan;Mealey,Nathan","Code4Lib","https://journal.code4lib.org/articles/11948","Primo;Ex Libris;Orbis Cascade;consortium;customization"
"736ecf558d634c9499968e489040e7a2",2010,"Challenges in Sustainable Open Source: A Case Study","The Archivists' Toolkit is a successful open source software package for archivists, originally developed with grant funding. The author, who formerly worked on the project at a participating institution, examines some of the challenges in making an open source project self-sustaining past grant funding. A consulting group hired by the project recommended that -- like many successful open source projects -- they rely on a collaborative volunteer community of users and developers. However, the project has had limited success fostering such a community. The author offers specific recommendations for the project going forward to gain market share and develop a collaborative user and development community, with more open governance.","Schaefer,Sibyl","Code4Lib","http://journal.code4lib.org/articles/2493","case study;archivists toolkit;open governance"
"75568bdaaac54a74bb3e84647f4ac161",2016,"RSS Feed 2.0: The Crux of a Social Media Strategy","This article explains how the University of Nebraska Kearney Calvin T. Ryan Library improved their social media strategy by using an RSS 2.0 feed to update and sync social media tools and create a slideshow on the library's home page.An example of how to code a well-formed RSS 2.0 feed with XML is given, in addition to PHP, HTML, and JQuery utilized to automate the library home page slideshow.","Sutherland,Michael","Code4Lib","http://journal.code4lib.org/articles/11299","RSS Feed;social media;Nebraska;XML;Jquery"
"75994f2b614943b4b065f26fd8571a9b",2021,"How We Built a Spatial Subject Classification Based on Wikidata","From the fall of 2017 to the beginning of 2020 a project had been carried out to upgrade spatial subject indexing in North Rhine-Westphalian Bibliography (NWBib) from uncontrolled strings to controlled values. For this purpose, a spatial classification with around 4,500 entries was created from Wikidata and published as SKOS (Simple Knowledge Organization System) vocabulary. The article gives an overview over the initial problem and outlines the different implementation steps.","Pohl,Adrian","Code4Lib","https://journal.code4lib.org/articles/15875","NWBib;SKOS;implementation steps;spatial subject classification;Wikidata"
"7603e2b7c57248bb9930f06c1536affb",2013,"Renewing UPEI’s Institutional Repository: New Features for an Islandora-based Environment","In October of 2012, the University of Prince Edward Island (UPEI) launched an updated version of IslandScholar, UPEI’s Institutional repository. The repository, available from http://www.islandscholar.ca, is built on Islandora 6 (http://islandora.ca). The repository includes a number of new features, including: CSL integration for ingest, site display, and export of user-specific bibliographies; MADS-based Authority integration for Departments and Authors (with authorities created automatically using LDAP); batch ingest from Refworks (crosswalked to MODS for storage in the repository); embargo and statistics functions. Features from the first version of IslandScholar were also migrated to the new site, including Sherpa/Romeo integration (which provides just-in-time information about open access policies).","Moses,Donald;Stapelfeldt,Kirsta","Code4Lib","http://journal.code4lib.org/articles/8763","UPEI;Islandora;LDAP;MODS;MADS;Sherpa/Romeo;open access;policies"
"76beb7d3f84b472388587b6078aca0c0",2022,"Ontology for Voice, Instruments, and Ensembles (OnVIE): Revisiting the Medium of Performance Concept for Enhanced Discoverability","Medium of performance—instruments, voices, and devices—is a frequent starting point in library users’ search for music resources. However, content and encoding standards for library cataloging have not been developed in a way that enables clear and consistent recording of medium of performance information. Consequently, unless specially configured, library discovery systems do not display medium of performance or provide this access point. Despite efforts to address this issue in the past decade in RDA, MARC, and the linked data environment, medium of performance information continues to be imprecise, dispersed across multiple fields or properties, and implied in other data elements. This article proposes revised definitions for “part,” “medium,” “performer,” and “ensemble,” along with a linked data model, the Ontology for Voice, Instruments, and Ensembles (OnVIE), that captures precise and complete medium of performance data reflecting music compositional practices, performance practices, and publishing conventions. The result is an independent medium of performance framework for recording searchable and machine-actionable metadata that can be hooked on to established library metadata ontologies and is widely applicable to printed and recorded classical, popular, jazz, and folk music. The clarity, simplicity, and extensibility of this model enable machine parsing so that the data can be searched, filtered, sorted, and displayed in multiple, creative ways.","Szeto,Kimmy","Code4Lib","https://journal.code4lib.org/articles/16608","RDA;MARC;OnVI;ontology;music;medium of performance;performing music"
"76d0b297e52b4cea8f3b8020f6f1c64f",2008,"Reaching Users Through Facebook:A Guide to Implementing Facebook Athenaeum","Facebook Athenaeum is an open source application that integrates library resources directly into the Facebook website. Facebook is one of the single most-visited websites in the world, and its popularity among college-aged students provides a unique opportunity for libraries to redefine how they interact with students. This article walks you through the deployment Facebook Athenaeum, and discusses some of the usage trends and pitfalls of deploying applications using the Facebook API.","Graham,Wayne","Code4Lib","http://journal.code4lib.org/articles/490","API;Facebook Athenaeum;Facebook;implementation"
"77293df963bf482887a2f86eae83ee1e",2018,"Alma Enumerator: Automating repetitive cataloging tasks with Python","In June 2016, the Warburg College library migrated to a new integrated library system, Alma. In the process, we lost the enumeration and chronology data for roughly 79,000 print serial item records. Re-entering all this data by hand seemed an unthinkable task. Fortunately, the information was recorded as free text in each item’s description field. By using Python, Alma’s API and much trial and error, the Wartburg College library was able to parse the serial item descriptions into enumeration and chronology data that was uploaded back into Alma. This paper discusses the design and feasibility considerations addressed in trying to solve this problem, the complications encountered during development, and the highlights and shortcomings of the collection of Python scripts that became Alma Enumerator.","Teal,Wesley","Code4Lib","https://journal.code4lib.org/articles/13947","API;Warburg;library system;Python;Alma API;Alma Enumerator"
"777a5c529e7b495aa3d1630b914d9ac3",2008,"Code4Lib: More than a journal","It is a pleasure and an honor to be able to introduce this, the second issue of Code4Lib Journal. Code4Lib is much more than a journal. It is a thriving community.","Lease Morgan,Eric","Code4Lib","http://journal.code4lib.org/articles/71","editorial"
"77c6daa9099f4be1a9aac4ef0a1730bb",2019,"SCOPE: A digital archives access interface","The Canadian Centre for Architecture (CCA) identified certain technological issues, namely extensive reference workflows and under-utilizing existing metadata, as significant barriers to access for its born-digital archives. In collaboration with Artefactual Systems, the CCA built SCOPE, a digital archives access interface. SCOPE allows for granular file- and item-level searching within and across digital archives, and lets users download access copies of the collection material directly to a local machine. SCOPE is a free, open-source tool. The beta version is available to the public, and a second phase is under-development as of Spring 2019.","Stewart,Kelly;Breitwieser,Stefana","Code4Lib","https://journal.code4lib.org/articles/14283","SCOPE;Canada;interface;searching"
"78189b51b412444786a1875d894a9c54",2016,"Measuring Library Vendor Cyber Security: Seven Easy Questions Every Librarian Can Ask","This article is based on an independent cyber security risk management audit for a public library system completed by the authors in early 2015 and based on a research paper by the same group at Clark University in 2014. We stress that while cyber security must include raising public knowledge in regard to cyber security issues and resources, and libraries are indeed the perfect place to disseminate this knowledge, librarians are also in a unique position as the gatekeepers of information services provided to the public and should conduct internal audits to ensure our content partners and IT vendors take cyber security as seriously as the library and its staff. One way to do this is through periodic reviews of existing vendor relationships. To this end, the authors created a simple grading rubric you can adopt or modify to help take this first step towards securing your library data. It is intended to be used by both technical and non-technical staff as a simple measurement of what vendor agreements currently exist and how they rank, while at the same time providing a roadmap for which security features or policy statements the library can or should require moving forward.","Caro,Alex;Markman,Chris","Code4Lib","http://journal.code4lib.org/articles/11413","security"
"786ea6e2bae64193a81cf68eac4bc569",2012,"Purposeful Development: Being Ready When Your Project Moves From ‘Hobby’ to Mission Critical","Throughout the library community examples can be found of development projects evolving into mission critical components within an organization's workflow. How these projects make that move is unique and varied, but little discussion has been had about how these projects impact their developers and the project community. What responsibilities does a developer have to ensure the long-term viability of their project? Does simply freeing the code meet those long-term responsibilities, or is there an implied commitment to provide long-term ""care and feeding"" to project communities built up over time? Code4Lib represents a group of developers consistently looking to build the next big thing, I'd like to step back and look at some of my own experiences related to the long-term impacts that come with developing successful projects and communities, and try to provide library developers food for thought as they consider their own ongoing responsibilities to their projects and user communities.","Reese,Terry","Code4Lib","http://journal.code4lib.org/articles/6393","mission critical components;long-term responsibilities"
"78d8937b535f409c94b1858eae5d5761",2019,"Consortial RightsStatements.org Implementation and Faceted Search for Reuse Rights in Digital Library Materials","The Florida Academic Library Services Cooperative (FALSC) makes available digital library hosting free-of-charge to all institutions of Florida public higher education. 21 institutions participate in the Islandora digital library platform hosted
through FALSC. Centralized digital library hosting through FALSC, or its predecessor consortium, has been available since 1994. Meanwhile, the RightsStatements.org standard, which provides a controlled vocabulary for indicating the copyright status
of digital library material, was released in 2016. After the standard was released, participating libraries expressed interest in implementing RightsStatements.org for existing digital content. During Fall 2018 and Spring 2019, FALSC implemented
RightsStatements.org values on Islandora sites. This article describes the process undertaken by FALSC, the lessons learned, and recommendations for libraries looking to implement RightsStatements.org values.","Randtke,Wilhelmina;Fischer,Randy;Lewis,Gail","Code4Lib","https://journal.code4lib.org/articles/14745","Florida;FALSC:rights management;consortium"
"79c2c7dfa7c9428f9f9e819d4a13b059",2015,"Editorial Introduction: A Brand New Year","by Terry Reese Happy New Year!  Issue 27 marks the first issue of 2015, a fresh start to a new year.  And an interesting year I think it will be, for both the Code4Lib community and the Journal; especially the Journal as we embark on our first special issue with a guest editorial committee and […]","Reese,Terry","Code4Lib","http://journal.code4lib.org/articles/10375","editorial"
"7a48fc3ac2514eca9e4fb34c067639d3",2011,"Diva.js: A Continuous Document Viewing Interface","Diva.js is a multi-page browser-based document viewer designed to present high-resolution digitized document images as a continuous, scrollable item. This article examines the current state of the art in online document display technologies, and presents a list of functional requirements the authors used to guide the creation of this new online document viewer. The authors then discuss the image processing infrastructure necessary for deploying the Diva.js viewer, and present a brief discussion of how the viewer is currently deployed in their organization.","Hankinson,Andrew;Liu,Wendy;Pugin,Laurent;Fujinaga,Ichiro","Code4Lib","http://journal.code4lib.org/articles/5418","Diva.js;document viewer;interface"
"7a7fd1ddc5ee441db0db26ec7c570e0a",2019,"Building a better book widget: Using Alma Analytics to automate new book discovery","Are we doing enough to market newly acquired book titles? Libraries purchase and subscribe to many new book titles each year, both print and electronic. However, we rely on the expectation that users will periodically search our systems to discover newly acquired titles. Static lists and displays have been traditional marketing methods for libraries, but require tedious time and effort to maintain. Without a practical solution for an academic library, East Tennessee State University developed an automated process to generate book widgets utilizing data from Alma Analytics. These widgets are now deployed in our subject guides, website, and on our digital displays. This article outlines the development and implementation of these widgets. We also discuss the challenges we encountered, such as finding image covers and custom subject tagging.","Clamon,Travis","Code4Lib","https://journal.code4lib.org/articles/14371","book widgets;Alma Analytics;tagging;East Tennessee"
"7abcbadd25ca4029b7c1636720002132",2012,"Editorial Introduction – Share Your Ideas","The Code4Lib Journal's mission is to foster community and share information. It is my hope that reading the articles in this issue will help you develop your own ideas and solutions. And that you will share your ideas with the community.","Peterson,Ron","Code4Lib","http://journal.code4lib.org/articles/7643","editorial"
"7b51e6c9f7904e2ab0b4da4c11eb1ebb",2015,"Generating Standardized Audio Technical Metadata:AES57","Long-term access to digitized audio may be heavily dependent on the quality of technical metadata captured during digitization.The AES57-2011 standard offers a standardized method of documenting fairly comprehensive technical information, but its complexity may be confusing. In an effort to lower the barrier to use, we have developed software that generates valid AES57 files for digitized audio, using output from FITS (File Information Tool Set) and a few fields of information from a tab-delimited spreadsheet.This article will describe the logic used, the fields required, the basic process, applications, and options for further development.","L. DeRidder,Jody","Code4Lib","http://journal.code4lib.org/articles/10828","audio;standard;FITS;AES57"
"7bd8083606a640acb49e81d3776a1f8e",2010,"AudioRegent: Exploiting SimpleADL and SoX for Digital Audio Delivery","AudioRegent is a command-line Python script currently being used by the University of Alabama Libraries’ Digital Services to create web-deliverable MP3s from regions within archival audio files. In conjunction with a small-footprint XML file called SimpleADL and SoX, an open-source command-line audio editor, AudioRegent batch processes archival audio files, allowing for one or many user-defined regions, particular to each audio file, to be extracted with additional audio processing in a transparent manner that leaves the archival audio file unaltered. Doing so has alleviated many of the tensions of cumbersome workflows, complicated documentation, preservation concerns, and reliance on expensive closed-source GUI audio applications.","Arora,Nitin","Code4Lib","http://journal.code4lib.org/articles/2882","AudioRegent;Python;Alabama;SimpleADL;SoXGUI"
"7c50fda16cf04a63bee8a893060cc379",2008,"Editorial Introduction -- Issue 4","Welcome to Issue 4 of the Code4Lib Journal!We are pleased to present articles covering an impressive breadth of topics. The strength of the Code4Lib Journal lies in its readers.You are not only the audience but also the authors for the articles published here.We hope the items you see in this, and future, issues inspire you to innovate and to share your discoveries with the rest of us.","Varnum,Ken","Code4Lib","http://journal.code4lib.org/articles/363","editorial"
"7c86b24dee934e7c916634710caa43e3",2019,"Improving the discoverability and web impact of open repositories: techniques and evaluation","In this contribution we experiment with a suite of repository adjustments and improvements performed on Strathprints, the University of Strathclyde, Glasgow, institutional repository powered by EPrints 3.3.13. These adjustments were designed to support improved repository web visibility and user engagement, thereby improving usage. Although the experiments were performed on EPrints it is thought that most of the adopted improvements are equally applicable to any other repository platform. Following preliminary results reported elsewhere, and using Strathprints as a case study, this paper outlines the approaches implemented, reports on comparative search traffic data and usage metrics, and delivers conclusions on the efficacy of the techniques implemented. The evaluation provides persuasive evidence that specific enhancements to technical aspects of a repository can result in significant improvements to repository visibility, resulting in a greater web impact and consequent increases in content usage. COUNTER usage grew by 33% and traffic to Strathprints from Google and Google Scholar was found to increase by 63% and 99% respectively. Other insights from the evaluation are also explored. The results are likely to positively inform the work of repository practitioners and open scientists.","Macgregor,George","Code4Lib","https://journal.code4lib.org/articles/14180","COUNTER;discoverability;Eprints;open science"
"7ce9922a836744d2af84de548bf5237d",2009,"Deciphering Journal Abbreviations with JAbbr","JAbbr is an online tool developed at Cornell University to help users decipher journal title abbreviations. This article discusses why these abbreviations are so problematic, and how traditional tools are often insufficient, and then describes the novel approach used by JAbbr. Given an abbreviation, JAbbr creates a regular expression for fuzzy matching, tests it against a list of serial titles extracted from the library catalog, and returns a list of possible matches to the user. JAbbr is available as a web site and as a web service.","Jenkins,Keith","Code4Lib","http://journal.code4lib.org/articles/1758","Jabbr;Cornell;abbreviations;fuzzy matching"
"7d9b7166b91b48138e42267c0750df50",2015,"Digital forensics on a shoestring:a case study from the University of Victoria","While much has been written on the increasing importance of digital forensics in archival workflows, most of the literature focuses on theoretical issues or establishing best practices in the abstract. Where case studies exist, most have been written from the perspective of larger organizations with well-resourced digital forensics facilities. However organizations of any size are increasingly likely to receive donations of born-digital material on outdated media, and a need exists for more modest solutions to the problem of acquiring and preserving their contents. This case study outlines the development of a small-scale digital forensics program at the University of Victoria using inexpensive components and open source software, funded by a $2000 research grant from the Canadian Association of Research Libraries (CARL).","Durno,John;Trofimchuk,Jerry","Code4Lib","http://journal.code4lib.org/articles/10279","digital forensics;CARL;Canada;best practices;Victoria"
"7e2f9e01a1d44462bad28586cde6bdd9",2008,"Generating Metadata on a Shoestring sans Programmer, with Our Good Friend, Excel (or Any Spreadsheet)","How to use Excel to generate metadata for any encoded filename or identifier for any digital object whose attributes can be expressed in an abbreviated form.","Strass,Jill","Code4Lib","http://journal.code4lib.org/articles/535","Excel;Excel macros;metadata"
"7e32099fa9c746c083173b963c67dc74",2021,"Editorial","Resuming our publication schedule","Hanson,Eric","Code4Lib","https://journal.code4lib.org/articles/15692","editorial"
"7e4569f3d74c4d739431154ee027007f",2009,"Ead McTaggart: Using VBA to Automate EAD Container List Tagging","Faced with the prospect of converting 200-page container lists to Encoded Archival Description (EAD), the author programmed a Microsoft Access® database using Visual Basic for Applications (VBA) to automatically insert the necessary EAD tags and their attributes. Some work is still required to ensure that the container list is properly formatted before importing into the database. Once formatted, the database, named Ead McTaggart, will convert a 7,000 line Microsoft Excel® container list, where each line represents a series, sub-series, or folder title, into a properly tagged EAD container list in about five minutes. As written, Ead McTaggart will handle up to six component levels, but can be modified to handle more. Although many institutions use Archivists' Toolkit or Archon for this functionality, many libraries and archives who have not implemented those tools will find that EAD McTaggert minimizes the work of converting existing container lists to EAD finding aids with a low time investment for implementation.","Miles,Randall","Code4Lib","http://journal.code4lib.org/articles/2025","EAD;VBA;tags;Archivists' Toolkit;Archon;EAD McTaggert"
"7ec3e2386a654e7abfd59804a38c6031",2016,"Need Help with Your Code? Piloting a Programming and Software Development Consultation Service","In the Spring 2016 semester, George Washington University Libraries (GW Libraries) undertook a pilot to provide programming and software development consultation services for the university community. The consultation services took the form of half hour appointments conducted by librarians with software development expertise, similar to other reference services offered by GW Libraries. The purpose of this paper is to provide an overview and assessment of the pilot project.","Wrubel,Laura;Kerchner,Daniel;Littman,Justin","Code4Lib","https://journal.code4lib.org/articles/11963","George Washington;pilot;programming"
"7ee67e7cd03b412c8a871108aefafa50",2018,"Microdata in the IR: A Low-Barrier Approach to Enhancing Discovery of Institutional Repository Materials in Google","Georgetown University Library curates a multitude of open access resources in its institutional repository and digital collections portal, DigitalGeorgetown. Over the last several years, the Library has experimented with methods for making these items increasingly visible in search engine search results. This article describes the Library’s low-barrier approach to applying Schema.org vocabulary to its DSpace institutional repository using microdata, as well as the challenges with and strategies used for assessing this work. The effects of the application of Schema.org microdata to DigitalGeorgetown on Google search results were tracked over time using three different metrics, providing new insights about its impact.","Pekala,Shayna","Code4Lib","http://journal.code4lib.org/articles/13191","Georgetown University;open access;Dspace;Schema.org;metrics;microdata"
"803fa51153a94f238ff04396b619e3a5",2008,"Mining Data from ISI Web of Science® Reports","Journal citation data is valuable as a selection tool for adding new journals as well as for discontinuing subscriptions that are no longer cost-effective. This article presents and discusses an example of data extraction from a typical ISI Web of Science report. The strategy was developed following a review of the data relationships and embedded data output format. While Perl was used in the example, the method described can be implemented with most programming/scripting languages. The example demonstrates also that citation-based studies and reports can be based on large sets of extracted data rather than the typical, small samples. The value of the data is discussed using a actual decision-making scenario.","Kraemer,Alfred","Code4Lib","http://journal.code4lib.org/articles/110","citation analysis;collection development;microsoft access;perl;web of science;ISI Web of Science;Perl;data;citation data"
"80b5054883e845da8c53aaa4daf79344",2014,"Review of DigitalSignage.com","Digital signage has been used in the commercial sector for decades.As display and networking technologies become more advanced and less expensive, it is surprisingly easy to implement a digital signage program at a minimal cost.In the fall of 2011, the University of Florida (UF), Health Sciences Center Library (HSCL) initiated the use of digital signage inside and outside its Gainesville, Florida facility.This article details UF HSCL's use and evaluation of DigitalSignage.com signage software to organize and display its digital content.","Richmond,Clifford;Daley,Matthew","Code4Lib","http://journal.code4lib.org/articles/9407","Digital signage;Florida"
"80c611db5e0a41ceb0dd9470bd06c04c",2016,"Node-Based Configuration Management Architecture for Private LOCKSS Networks","Node-based configuration management describes a services architecture for Private LOCKSS Networks that transfers administrative services onto a peer preservation node in the network. The architecture also describes techniques for enabling full redundancy of data for configuration administration utilizing the preservation protocols in LOCKSS. The goal of node-based configuration management is a horizontal administrative model where any peer node can assume administrative services with complete redundancy of configuration data across all nodes.","M. Cataldo,Tobin","Code4Lib","https://journal.code4lib.org/articles/11909","LOCKSS;architecture;redundancy;preservation protocols"
"8158638b38794749b570234b45dc8637",2007,"Facet-Based Search and Navigation With LCSH: Problems and Opportunities","Facet-based interfaces demonstrate some limitations of Library of Congress Subject Headings (LCSH), which were designed to deal with constraints that do not exist in the current computerized environment. This paper discusses some challenges for using LCSH for faceted browsing and navigation in library catalogs. Ideas are provided for improving results through system design, changes to LCSH practice, and LCSH structure.","McGrath,Kelley","Code4Lib","http://journal.code4lib.org/articles/23","LCSH;Challenges;search;facets;design"
"825c4f6279814ea4b9a9888aca44ce59",2007,"Editorial Introduction — Issue 1","This mission of the Code4Lib Journal is to cover “the intersection of libraries, technology, and the future.” We hope that this journal can be one more contribution to the developing culture of collaboration around library technology, and we welcome you to join in our experiment.","Rochkind,Jonathan","Code4Lib","http://journal.code4lib.org/articles/39","editorial"
"82b031449996477aa4d462d29b37600c",2012,"Tools for Reducing and Managing Link Rot in LibGuides","While creating content in LibGuides in quite easy, link maintenance is troublesome, and the built-in link checker offers only a partial solution. The authors describe a method of using PURLs and a third-party link checker to effectively manage links within LibGuides.","Randtke,Wilhelmina;D. Burrell,Matthew","Code4Lib","http://journal.code4lib.org/articles/7019","link rot;LibGuides;PURL"
"841ff2cdaa7e4e73a7e22afcedf51eb7",2008,"Alternative Solutions for Off-Campus Authentication","The Ohio State University Libraries created scripts to overcome the local limitations of the proxy server and to offer resource connections at the point of need.All libraries struggle to provide seamless authentication for access to paid resources, such as research databases and electronic journals. In order to obtain access to this content, the libraries must sign contracts promising to limit access to these resources to their user community.The challenge then comes in balancing the patron's need for easy access to these rich data sources from any computer and the vendors' desire to protect their assets.","Muir,James;L. Black,Elizabeth;Kilzer,Rebekah","Code4Lib","http://journal.code4lib.org/articles/73","Ohio;proxy server;authentication"
"8464ab08b8614f528df87e344ffa3520",2010,"Practical Ways to Promote and Support Collaborative Data Analysis Projects","This article is an appeal to technically-oriented library staff to initiate collaborative, bottom-up data-analysis efforts across their libraries. We discuss successful strategies used at North Carolina State University (NCSU) Libraries for initiating cross-departmental outreach for data-analysis work, as well as structuring and storing data, and disseminating findings. We present several specific examples of collaborative data-analysis projects undertaken at NCSU Libraries.","Chapman,Joyce;Lown,Cory","Code4Lib","http://journal.code4lib.org/articles/4258","data analysis;projects;collaborative;NCSU"
"84a86519ca204946801800adf137b7a2",2011,"Editorial Introduction","This Hallowe’en finds our contributors working away like (benign) madscientists, assembling and deploying their creations to bring services and information innovel ways to their patrons and staff, approaching their work with a vital sprit of inventionand discovery.","A. Olson,Tod","Code4Lib","http://journal.code4lib.org/articles/5989","editorial"
"8504bdb1d58f4fa29b0bcd078e1d126c",2016,"Digital Archaeology and/or Forensics: Working with Floppy Disks from the 1980s","While software originating from the domain of digital forensics has demonstrated utility for data recovery from contemporary storage media, it is not as effective for working with floppy disks from the 1980s. This paper details alternative strategies for recovering data from floppy disks employing software originating from the software preservation and retro computing communities. Imaging hardware, storage formats and processing workflows are also discussed.","Durno,John","Code4Lib","https://journal.code4lib.org/articles/11986","digital archeology;digital forensics"
"857cf980e8e34b73bb272c9f22fb1b5f",2011,"Using Amazon Mechanical Turk to Transcribe Historical HandwrittenDocuments","The developing “information age” is continually unraveling new ways ofdiscovering, presenting and sharing information. Most new academic material is digitallyformatted upon its creation and is thus easy to find and query. However, there remains a gooddeal of material from times prior to the “information age” that has yet to be converted todigital form. Much of this material can be found in library collections—whether academic,public or private—and thus remains available only to a limited number of locals orwilling-and-able sojourners. Using OCR technology, most typeset documents can be digitized andmade available online; and there are several projects underway to do exactly this. However,there remains little to be done for handwritten materials. Those who own collections of handwritten documents are increasingly wanting to make the content thereof available to thegeneral public. Unfortunately, traditional transcription models typically prove to beexpensive or inefficient and pdf snapshots are not searchable. We have developed a model fordigital transcription using Google Docs and Amazon's Mechanical Turk. Using this model, onecan use an online workforce to efficiently transcribe handwritten texts and perform qualitycontrol at a cost much lower than professional transcription services. To illustrate the modelwe used Amazon’s Mechanical Turk to transcribe and then proofread the Frederick Douglass Diarywhich we have made available on a public searchable wiki. The total cost of transcription andproofreading for the 72 page diary was less than $25.00 with some pages being transcribed andproofread for as little as $0.04. Our results show that using Amazon’s Mechanical Turk holdsgreat promise for providing an affordable transcription method for hand-written historical documents making them easily sharable and fully searchable.","S.I.D. Lang,Andrew;Rio-Ross,Joshua","Code4Lib","http://journal.code4lib.org/articles/6004","information age;Amazon;Mechanical Turk;gamification;OCR;hand-written historical documents;transcription"
"8597dc9175aa43b9bbd0ce3c2ec779b5",2017,"Developing an online platform for gamified library instruction","Gamification is a concept that has been catching fire for a while now in education, particularly in libraries. This article describes a pilot effort to create an online gamified platform for use in the Woodbury University Library’s information literacy course. The objectives of this project were both to increase student engagement and learning, and to serve as an opportunity for myself to further develop my web development skills. The platform was developed using the CodeIgniter web framework and consisted of several homework exercises ranging from a top-down two-dimensional library exploration game to a tutorial on cleaning up machine-generated APA citations. This article details the project’s planning and development process, the gamification concepts that helped guide the conceptualization of each exercise, reflections on the platform’s implementation in four course sections, and aspirations for the future of the project. It is hoped that this article will serve as an example of the opportunities–and challenges–that await both librarians and instructors who wish to add coding to their existing skill set.","Cowing,Jared","Code4Lib","http://journal.code4lib.org/articles/12122","gamification;Woodbury;library instruction"
"859e44ded6054538bc770a8e4fd2d47b",2016,"Editorial Introduction: New Year Resolutions","While New Year’s day came and went with very little fanfare at my house (well, if you don’t count our Star Wars marathon), I think I’d be remiss if I didn’t take the time to mark the passing of the new year, with a look ahead to the future.  And I think it is fitting, then, […]","Reese,Terry","Code4Lib","http://journal.code4lib.org/articles/11316","editorial"
"85d64fee7494430cab3361715ff5d332",2013,"Arduino-enabled Patron Interaction Counting","Using the Arduino development board (http://arduino.cc) has become avery popular way to create hardware prototypes that bridge the divide between the physicalworld and the Internet. This article outlines how to use an Arduino, some off-the-shelfelectronic parts, the Processing programming language, and Google Documents to create apush-button reference desk transaction tally device. The design: plugged into a computer atthe reference desk, staff members push the appropriate button on the device when a reference transaction occurs, and the action is instantly tallied in a Google Document. Having aphysical device on the desktop increases chances of proper collection of information since itis constantly visible and easily accessible, versus requiring staff members to click through aseries of options in a piece of software running on the PC. The data can be tabulated inGoogle Documents or any other source that processes form-based HTML data. This article coversall of the major components of creating the project: - Constructing the Arduino circuit and programming it - Creating the Google Docs form - Creating the Processing program that will listen for information from the Arduino and send it to the Google Docs form","Ribaric,Tim;Younker,Jonathan","Code4Lib","http://journal.code4lib.org/articles/8200","arduino;eference transaction;Google Docs"
"85f84e3acdf34a54ad8c5f43fc4012f9",2009,"Integrating Process Management with Archival Management Systems: Lessons Learned","The Integrated Digital Special Collections (INDI) system is a prototype of a database-driven, Web application designed to automate and manage archival workflow for large institutions and consortia. This article discusses the how the INDI project enabled the successful implementation of a process to manage large technology projects in the Harold B. Lee Library at Brigham Young University. It highlights how the scope of these technology projects is set and how the major deliverables for each project are defined. The article also talks about how the INDI system followed the process and still failed to be completed. It examines why the process itself is successful and why the INDI project failed. It further underscores the importance of process management in archival management systems.","Gordon Daines, III,J.;L. Nimer,Cory","Code4Lib","http://journal.code4lib.org/articles/1016","INDI;system;archival management system"
"863e49f826564c678cdd79683d4a0c3c",2011,"Implementing Time Travel for the Web","This article discusses the challenges and solutions discovered for implementing the Memento protocol in a variety of browser environments. It describes the design and deployment of the client technologies which have been developed: a web application that functioned as a browser, an add-on for FireFox called MementoFox, a plugin for Internet Explorer and an Android-based client application. The design and technical solutions identified during the development will be of interest to those considering implementation of a Memento based platform, especially on the client side, however the interactions are also important for building conformant server-side systems.","Sanderson,Robert;Shankar,Harihar;Ainsworth,Scott;McCown,Frank;Adams,Sam","Code4Lib","http://journal.code4lib.org/articles/4979","time travel;Amazon;recommendations;mobile application"
"876d33bc684146deb744d27bce9eef68",2012,"Modular Mobile Application Design","This article describes the development of the Minrva library app for Android phones. The decisions to build a native application with Java and use a modular design are discussed. The application includes five modules: catalog search, in-building navigation, a barcode scanning feature, and up to date notifications of circulating technology availability. A sixth module, Amazon recommendations, that is not included in the version of the app that was released is also discussed. The article also reports on the findings of two rounds of usability testing and the plans for future development of the app.","Hahn,Jim;Ryckman,Nathaniel","Code4Lib","http://journal.code4lib.org/articles/7336","Minrva;mobile application;design;usability"
"878335d852f74c5fbc23fd1f4d9476b4",2010,"Using an Agile-based Approach to Develop a Library Mobile Website","This article discusses how the UC San Diego Libraries developed and implemented a mobile website by giving a small collaborative group decision-making authority for all of the library stakeholders. The group used rapid development and testing cycles with an understanding that delivering a fast and “good enough” service was preferable over slow and seemingly perfect development.","Critchlow,Matt;Friedman,Lia;Suchy,Dan","Code4Lib","http://journal.code4lib.org/articles/4642","UC San Diego;mobile website;good enogh"
"87beca82e37141fa987ec3651b922f2e",2008,"Affinity Strings: Enterprise Data for Resource Recommendations","The University of Minnesota Libraries have created a MyLibrary portal, with databases and e-journals targeted to users, based on their affiliations. The University's enterprise authentication system provides an ""affinity string"", now used to personalize the MyLibrary portal. This affinity string automates discovery of a user's relationship to the University--describing a user's academic department and degree program or position at the University. Affinity strings also provide the Libraries with an anonymized view of resource usage, allowing data collection that respects users' privacy and lays the groundwork for automated recommendation of relevant resources based on the practices and habits of their peers.","Nackerud,Shane;Jensen,Kristi;Hanson,Cody","Code4Lib","http://journal.code4lib.org/articles/501","Minnesota;MyLibrary;portal;e-journals;affinity strings;recommendations"
"87ef3537ff884725b897e3787ba5be7e",2019,"Editorial: A modest proposal for the mitigation of impostor syndrome","Thoughts on impostor syndrome and participation in the Code4Lib community","Hanson,Eric","Code4Lib","https://journal.code4lib.org/articles/14689","editorial"
"8a249daa17964d53b69ffeb3fcb9d9ec",2008,"LibraryH3lp: A New Flexible Chat Reference System","LibraryH3lp is an integrated IM and web chat system designed specifically for Virtual Reference services in libraries. The software was designed for, and is currently used by, a night-time chat reference collaboraton between several large academic libraries. LibraryH3lp is designed for the workflow of chat reference, supporting multiple simultaneous operators and routing to queues of operators in a particular service area. It also supports web page embeddable chat 'widgets', as well as simultaneous gateways to multiple IM protocols.This article discusses the motivation for the development of the software, and provides an overview of LibraryH3lp's features and technical architecture.Parts of LibraryH3lp are available as open source. The complete application is available as a low-cost hosted service, and will eventually be available to be licensed for local hosting.","Sessoms,Pam;Sessoms,Eric","Code4Lib","http://journal.code4lib.org/articles/107","LibraryH3lp;IM;chat;virtual refference;widgets;open source"
"8b8ce1283a2145af817864ce3bdea7c1",2017,"DuEPublicA: Automated bibliometric reports based on the University Bibliography and external citation data","This paper describes a web application to generate bibliometric reports based on the University Bibliography and the Scopus citation database. Our goal is to offer an alternative to easy-to-prepare automated reports from commercial sources. These often suffer from an incomplete coverage of publication types and a difficult attribution to people, institutes and universities. Using our University Bibliography as the source to select relevant publications solves the two problems. As it is a local system, maintained and set up by the library, we can include every publication type we want. As the University Bibliography is linked to the identity management system of the university, it enables an easy selection of publications for people, institutes and the whole university. The program is designed as a web application, which collects publications from the University Bibliography, enriches them with citation data from Scopus and performs three kinds of analyses:1. A general analysis (number and type of publications, publications per year etc.), 2. A citation analysis (average citations per publication, h-index, uncitedness), and 3. An affiliation analysis (home and partner institutions) We tried to keep the code highly generic, so that the inclusion of other databases (Web of Science, IEEE) or other bibliographies is easily feasible. The application is written in Java and XML and uses XSL transformations and LaTeX to generate bibliometric reports as HTML pages and in pdf format. Warnings and alerts are automatically included if the citation analysis covers only a small fraction of the publications from the University Bibliography. In addition, we describe a small tool that helps to collect author details for an analysis.","T. Spielberg,Eike","Code4Lib","http://journal.code4lib.org/articles/12549","DuEPublicA;bibliometry;repors;Scopus;citation database;Java;XML;XSL;LaTeX"
"8b8d6a19649a44348587e59f740af71d",2019,"Editorial: Just Enough of a Shared Vision","What makes a vibrant community?A shared vision!When we live into a shared vision, we can accomplish big goals even when our motivations are not completely aligned.","Murray,Peter","Code4Lib","https://journal.code4lib.org/articles/14341","editorial"
"8c82a31292ba4a80a8c3c37847c9ffb7",2017,"Recount: Revisiting the 42nd Canadian Federal Election to Evaluate the Efficacy of Retroactive Tweet Collection","In this paper, we report the development and testing of a methodology for collecting tweets from periods beyond the Twitter API’s seven-to-nine day limitation. To accomplish this, we used Twitter’s advanced search feature to search for tweets from past the seven to nine day limit, and then used JavaScript to automatically scan the resulting webpage for tweet IDs. These IDs were then rehydrated (tweet metadata retrieved) using twarc. To examine the efficacy of this method for retrospective collection, we revisited the case study of the 42nd Canadian Federal Election. Using comparisons between the two datasets, we found that our methodology does not produce as robust results as real-time streaming, but that it might be useful as a starting point for researchers or collectors. We close by discussing the implications of these findings.","T. Pinter,Anthony;Goldman,Ben","Code4Lib","http://journal.code4lib.org/articles/12676","API;Twitter;Canada;election;JavaScript;findings"
"8c9598411ac340fda9358eae06fa9965",2022,"Teaching AI when to care about gender","Natural Language Processing (NLP) is a branch of Artificial Intelligence (AI) concerned with solving language tasks by modeling large amounts of textual data. Some NLP techniques use word embeddings which are semantic models where machine learning (ML) is used to learn to cluster semantically related words by learning about word co-occurrences in the original training text. Unfortunately, these models tend to reflect or even exaggerate biases that are present in the training corpus. Here we describe the Word Embedding Navigator (WEN), which is atool for exploring word embedding models. We examine a specific potential use case for this tool: interactive discovery and neutralization of gender bias in word embedding models, and compare this human-in-the-loop approach to reducing bias in word embeddings with a debiasing post-processing technique.","Powell, Kari Sentz, Elizabeth Moyer, Martin Klein,James","Code4Lib","https://journal.code4lib.org/articles/16718","AI;NLP;machine learning;natural language processing;WEN;Word Embedding Navigator;gender bias"
"8d1b33922e8740b6b95558e074ee5651",2010,"The Integrated Library System’s APIs, an Open-source Web 2.0 Catalog, and University Computing Live Happily Ever After","It is widely accepted that students prefer a library catalog that offers the features that they find using Google or Amazon. One of these features would be dynamically delivered services. This article describes the obstacles faced trying to integrate traditional integrated library system (ILS) architecture with an open source Web 2.0 search interface, and outlines the path to a solution for delivering user services such as the hold and recall functions.","Ho,Birong","Code4Lib","http://journal.code4lib.org/articles/4165","API;ILS;search;web 2.0"
"8d8dd5d8e6df44189f3950b3f62063a1",2014,"Parsing and Matching Dates in VIAF","The Virtual International Authority File (OCLC Online Computer Library Center 2013) http://viaf.org is built from dozens of authority files with tens of millions of names in more than 150 million authority and bibliographic records expressed in multiple languages, scripts and formats.One of the main tasks in VIAF is to bring together personal names which may have various dates associated with them, such as birth, death or when they were active. These dates can be quite complicated with ranges, approximations, BCE dates, different scripts, and even different calendars. Analysis of the nearly 400,000 unique date strings in VIAF led us to a parsing technique that relies on only a few basic patterns for them.Our goal is to correctly interpret at least 99% of all the dates we find in each of VIAF’s authority files and to use the dates to facilitate matches between authority records. Python source code for the process described here is available at https://github.com/OCLC-Developer-Network/viaf-dates.","A. Toves,Jenny;B. Hickey,Thomas","Code4Lib","http://journal.code4lib.org/articles/9607","VIAF;Python;authority records"
"8dd5111ddb29498291cbb2d7e51e9084",2010,"XForms for Libraries, An Introduction","XForms applications can be used to create XML metadata that is well-formed and valid according to the schema, and then saved to (or loaded from) a datastore that communicates via REST or SOAP. XForms applications provide a powerful set of tools for data creation and manipulation, as demonstrated by some projects related to library workflows that are described in this paper.","Gruber,Ethan;Fitzpatrick,Chris;Parod,Bill;Prater,Scott","Code4Lib","http://journal.code4lib.org/articles/3916","Xforms;XML;metadata;REST;SOAP;API"
"8e53689dae0c444b9eb8febc2a4afccf",2021,"Editorial : The Cost of Knowing Our Users","Some musings on the difficulty of wanting to know our users' secrets and simultaneously wanting to not know them.","Swenson,Mark","Code4Lib","https://journal.code4lib.org/articles/16208","editorial"
"8e77f1cc577c4964ba744edd4285e84e",2020,"Leveraging the RBMS/BSC Latin Place Names File with Python","To answer the relatively straight-forward question “Which rare materials in my library catalog were published in Venice?” requires an advanced knowledge of geography, language, orthography, alphabet graphical changes, cataloging standards, transcription practices, and data analysis. The imprint statements of rare materials transcribe place names more faithfully as it appears on the piece itself, such as Venetus, or Venetiae, rather than a recognizable and contemporary form of place name, such as Venice, Italy. Rare materials catalogers recognize this geographic discoverability and selection issue and solve it with a standardized solution. To add consistency and normalization to imprint locations, rare materials catalogers utilize hierarchical place names to create a special imprint index. However, this normalized and contemporary form of place name is often missing from legacy bibliographic records. This article demonstrates using a traditional rare materials cataloging aid, the RBMS/BSC Latin Place Names File, with programming tools, Jupyter Notebook and Python, to retrospectively populate a special imprint index for 17th-century rare materials. This methodology enriched 1,487 MAchine Readable Cataloging (MARC) bibliographic records with hierarchical place names (MARC 752 fields) as part of a small pilot project. This article details a partially automated solution to this geographic discoverability and selection issue; however, a human component is still ultimately required to fully optimize the bibliographic data.","Knudson Davis,kalan","Code4Lib","https://journal.code4lib.org/articles/15143","RBMS/BSC;place names;MARC;Python"
"8ead7d28d1504e96a39c47a5709ee1b5",2011,"An Android/LAMP Mobile In/Out Board Based on Wi-Fi Fingerprinting","Library technology and other professionals with diverse skills must beable to locate each other during the workday, in order to most responsively serve theirclients. While staff often carry cellular phones, contact can be especially challenging giventhe constant, highly mobile nature of library work, especially on larger campuses withvariable cellular phone service. Western Michigan University (WMU) Libraries has developed anAndroid/LAMP application that library staff may use on their increasingly prevalent Wi-Fienabled mobile devices to “check in” at various locations where they do work, so that theircolleagues may locate them as needed. The application takes advantage of WMU’s widespread Wi-Fi network, a set of free platform and software development tools and open standards, andmethods from the computer science literature, and overcomes GPS and telephony limitations.This article describes the application, which is based on Wi-Fi fingerprinting, and suggestshow other developers could use it and new methods from the computer science literature asstarting points to create their own applications.","Kelley,Keith;Kaugars,Karlis;Garrison,Scott","Code4Lib","http://journal.code4lib.org/articles/5859","Western Michigan;LAMP;GPS;WI-FI;fingerprinting"
"8fb0958da9d44c8a82346b6e0bf186e7",2015,"Collected Work Clustering in WorldCat","WorldCat records are clustered into works, and within works, into content and manifestation clusters. A recent project revisited the clustering of collected works that had been previously sidelined because of the challenges posed by their complexity. Attention was given to both the identification of collected works and to the determination of the component works within them. By extensively analysing cast-list information, performance notes, contents notes, titles, uniform titles and added entries, the contents of collected works could be identified and differentiated so that correct clustering was achieved. Further work is envisaged in the form of refining the tests and weights and also in the creation and use of name/title authority records and other knowledge cards in clustering. There is a requirement to link collected works with their component works for use in search and retrieval.","Gatenby,Janifer;Thornburg,Gail;Weitz,Jay","Code4Lib","http://journal.code4lib.org/articles/10963","WorldCat;clustering"
"904fd760a7d040feb8f097455847ba6b",2014,"Exposing Library Services with AngularJS","This article provides an introduction to the JavaScript framework AngularJS and specific AngularJS modules for accessing library services. It shows how information such as search suggestions, additional links, and availability can be embedded in any website. The ease of reuse may encourage more libraries to expose their services via standard APIs to allow usage in different contexts.","Voß,Jakob;Horn,Moritz","Code4Lib","http://journal.code4lib.org/articles/10023","API;AngularJS"
"90e38e421b3d40e79362d93dd22af11d",2009,"How to Build an XML Web Client for the Gold Rush Link Resolver’s XML Gateway Web Services Layer","The Gold Rush link resolver (GRLR) is part of a suite of programs developed by the Colorado Alliance of Research Libraries (CARL) which help manage a library's electronic resources. It contains the essential features required to perform link resolution, and comes at a substantial discount compared to other commercial Link Resolvers. After a comprehensive review of the available options, the library at the University of Tennessee at Chattanooga (UTC) chose to implement Gold Rush over the summer of 2008. The UTC library also decided to take advantage of the release of the Gold Rush XML Gateway Web Services Layer by the Colorado Alliance in the spring of 2008. This article is a case study of how the UTC XML Web client was built and the steps necessary to successfully deploy such a client.","Kysela,Brian","Code4Lib","http://journal.code4lib.org/articles/1324","GRLR;CARL;XML;case study"
"92ca80231d594df1abd65087c06f9e99",2010,"Editorial Introduction: The Code4Lib Journal isn’t just for Coders","Although the primary goal of the Code4Lib Journal is to provide practical solutions for technologists working in libraries, it has a lot to offer non-technologists. Technology affects all of the work that our libraries are doing and will define what the future of libraries will look like.","Peterson,Ron","Code4Lib","http://journal.code4lib.org/articles/4587","editorial"
"92d46889c40f45df928e527d2ba6cf55",2013,"Crafting Linked Open Data for Cultural Heritage: Mapping and Curation Tools for the Linked Jazz Project","This paper describes tools and methods developed as part of Linked Jazz, a project that uses Linked Open Data (LOD) to reveal personal and professional relationships among jazz musicians based on interviews from jazz archives. The overarching aim of Linked Jazz is to explore the possibilities offered by LOD to enhance the visibility of cultural heritage materials and enrich the semantics that describe them. While the full Linked Jazz dataset is still under development, this paper presents two applications that have laid the foundation for the creation of this dataset: the Mapping and Curator Tool, and the Transcript Analyzer. These applications have served primarily for data preparation, analysis, and curation and are representative of the types of tools and methods needed to craft linked data from digital content available on the web. This paper discusses these two domain-agnostic tools developed to create LOD from digital textual documents and offers insight into the process behind the creation of LOD in general.","Cristina Pattuelli,M.;Miller,Matt;Lange,Leanora;Fitzell,Sean;Li-Madeo,Carolyn","Code4Lib","http://journal.code4lib.org/articles/8670","linked open data;cultural heritage;linked jazz;lod"
"938e04fb9d5f408bac982e1e9b4764b3",2016,"Practical Digital Forensics at Accession for Born-Digital Institutional Records","Archivists have developed a consensus that forensic disk imaging is the easiest and most effective way to preserve the authenticity and integrity of born-digital materials. Yet, disk imaging also has the potential to conflict with the needs of institutional archives – particularly those governed by public records laws. An alternative possibility is to systematically employ digital forensics tools during accession to acquire a limited amount of contextual metadata from filesystems. This paper will discuss the development of a desktop application that enables records creators to transfer digital records while employing basic digital forensics tools records’ native computing environment to gather record-events from NTFS filesystems.","Wiedeman,Gregory","Code4Lib","http://journal.code4lib.org/articles/11239","NTFS;archivists;digital forensics;institutional records"
"94305524f5a24fab928c821397444f43",2022,"“You could use the API!”:A Crash Course in Working with the Alma APIs using Postman","While there are those within libraries that are able to take vendor APIs and use them to power applications and innovative workflows in their respective systems, there are those of us that may have heard of APIs but have only the slightest idea of how to actually make use of them. Often colleagues in various forums will mention that a task could be “just done with the API” but provide little information to take us from “this is what an API is” or “here’s the API documentation” to actually putting them to use. Looking for a way to automate tasks in Alma, the authors of this article both found themselves in such a position and then discovered Postman, an API platform with a user-friendly interface that simplifies sending API calls as well as using bulk and chained requests. This article gives a basic primer in how to set up Postman, how to use it to work with ExLibris’ Alma APIs, as well as the authors’ use cases in working with electronic inventory and course reserves.","Hyams and Tamara Pilko,Rebecca","Code4Lib","https://journal.code4lib.org/articles/16597","API;Alma API;Postman;ExLibris"
"95bbbccb5c9e45e1a31257def91551c3",2018,"Assessing the Potential Use of High Efficiency Video Coding (HEVC) and High Efficiency Image File Format (HEIF) in Archival Still Images","Both HEVC (ISO/IEC 23008–2) video compression and the HEIF (ISO/IEC 23008-12) wrapper format are relatively new and evolving standards. Though attention has been given to their recent adoption as a JPEG replacement for more efficient local still image use on consumer electronic devices, the standards are written to encompass far broader potential application. This study examines current HEVC and HEIF tools, and the standards’ possible value in the context of digital still image archiving in cultural heritage repositories.","J. Bennett,Michael","Code4Lib","https://journal.code4lib.org/articles/13746","HEVC;JPEG;HEIF;cultural heritage;repositories"
"95dc20f2d30c4650b217230fa7577ebe",2018,"Are we still working on this? A meta-retrospective of a digital repository migration in the form of a classic Greek Tragedy (in extreme violation of Aristotelian Unity of Time)","In this paper we present a retrospective of a 2.5 year project to migrate a major digital repository system from one open source software platform to another. After more than a decade on DSpace, Oregon State University’s institutional repository was in dire need of a variety of new functionalities. For reasons described in the paper, we deemed it appropriate to migrate our repository to a Samvera platform. The project faced many of the challenges one would expect (slipping deadlines, messy metadata) and many that one might hope never to experience (exceptional amounts of turnover and uncertainty in personnel, software, and community). We talk through our experiences working through the three major phases of this project, using the structure of the Greek Tragedy as a way to reflect (with Stasimon) on these three phases (Episode). We then conclude the paper with the Exodus, wherein we speak at a high level of the lessons learned in the project including Patience, Process, and Perseverance, and why these are key to technical projects broadly. We hope our migration story will be helpful to developers and repository managers as a map of development hurdles and an aspiration of success.","Van Tuyl,Steve;Gum,Josh;Mellinger,Margaret;Luis Ramirez,Gregorio;Straley,Brandon;Wick,Ryan;Zhang,Hui","Code4Lib","https://journal.code4lib.org/articles/13581","Dspace;Samvera;Oregon;migration"
"95ff060884314f37a7796824776827eb",2014,"Customizing Android Tablets for a Shared Environment","The Valley Library at Oregon State University Libraries & Press supports access to technology by lending laptops and e-readers. As a newcomer to tablet lending, The Valley Library chose to implement its service using Google Nexus tablets and an open source custom firmware solution, CyanogenMod, a free, community-built Android distribution.They created a custom build of CyanogenMod featuring wireless updates, website shortcuts, and the ability to quickly and easily wipe devices between patron uses.This article shares code that simplifies Android tablet maintenance and addresses Android application licensing issues for shared devices.","Nichols,Jane;Hussong-Christian,Uta;Ordway,Ryan","Code4Lib","http://journal.code4lib.org/articles/9482","Oregon;CyanogenMod;tablets;Android"
"963af56a62b2420fa77be78c91a29a9e",2013,"Metadata Analysis at the Command-Line","Over the past few years the University of North Texas Libraries' Digital Projects Unit (DPU) has developed a set of metadata analysis tools, processes, and methodologies aimed at helping to focus limited quality control resources on the areas of the collection where they might have the most benefit. The key to this work lies in its simplicity: records harvested from OAI-PMH-enabled digital repositories are transformed into a format that makes them easily parsable using traditional Unix/Linux-based command-line tools. This article describes the overall methodology, introduces two simple open-source tools developed to help with the aforementioned harvesting and breaking, and provides example commands to demonstrate some common metadata analysis requests. All software tools described in the article are available with an open-source license via the author's GitHub account.","Phillips,Mark","Code4Lib","http://journal.code4lib.org/articles/7818","metadata;analysis;OAI-PMH;Unix;Linux;GitHub"
"96feb0c5655c416881dc39c7f712a8a8",2018,"What's in a Name? On 'Meaningfulness' and Best Practices in Filenaming within the LAM Community","Cultural institutions such as libraries, archives and museums (LAM) face many challenges with managing digital collections, particularly when it comes to organizing the individual files that make up each collection. While tools such as metadata and collection management systems support identification and arrangement for digital files, administrative control depends significantly on the mere filenaming in use beneath the surface. Anecdotal evidence has shown that many LAM institutions have specialized filenaming schemes in place for their digital collections. This paper includes a literature review of filenaming practices in the LAM community, followed by a description and analysis of survey data regarding filenaming practices in the LAM community. The purpose of the survey was to learn about filenaming conventions in use within LAM organizations who have filenaming policies in place. The data suggests that: similarities and differences exist in filenaming approaches between museums/galleries, archives/special collections, and academic institutions; it is preferred that filenaming be simultaneously meaningful to both humans and computers; and conventions that affect sortability are deemed more important than those that affect readability. The data also indicate several subtopics related to filenaming that would benefit from further study.","Krewer,Drew;Wahl,Mary","Code4Lib","http://journal.code4lib.org/articles/13438","LAM;survey;filenaming"
"980eb33b9423466c802b1ee7d95c56c2",2011,"Conference Reports: Code4Lib 2011","Conference reports from the 6th Code4Lib Conference, held in Bloomington, IN, from February 7 to 10, 2011. The Code4Lib conference is a collective volunteer effort of the Code4Lib community of library technologists. Included are two brief reports on the conference from some recipients of conference scholarships.","Kim,Bohyun;Tzoc,Elias","Code4Lib","http://journal.code4lib.org/articles/4960","report"
"988303efd7bd432d9c77cdf4c671ebc9",2022,"Editorial — New name change policy","The Code4Lib Journal Editorial Committee is implementing a new name change policy aimed to facilitate the process and ensure timely and comprehensive name changes for anyone who needs to change their name within the Journal.","Peterson,Ron","Code4Lib","https://journal.code4lib.org/articles/16465","editorial"
"994de15de429488da4c25de6b48846a4",2016,"Video Playback Modifications for a DSpace Repository","This paper focuses on modifications to an institutional repository system using the open source Dspace software to support playback of digital videos embedded within item pages. The changes were made in response to the formation and quick startup of an event capture group within the library that was charged with creating and editing video recordings of library events and speakers. This paper specifically discusses the selection of video formats, changes to the visual theme of the repository to allow embedded playback and captioning support, and modifications and bug fixes to the file downloading subsystem to enable skip-ahead playback of videos via byte-range requests. This paper also describes workflows for transcoding videos in the required formats, creating captions, and depositing videos into the repository.","Gilbertson,Keith;McVoy,Liz","Code4Lib","http://journal.code4lib.org/articles/11215","Dspace;video;repository;transcoding"
"99d0007ccb6a4dd885030b57854783cb",2015,"Recognizing Cultural Diversity in Library Interface Development","The rapid increase in complex library digital infrastructures has enabled a more full-featured set of resources to become accessible by autonomous users, whether onsite or remote. However, this trend also necessitates careful consideration of the usability of new interfaces for populations with increasing cultural, geographic, and socioeconomic diversity. Researcher Aron Marcus has become an authority on how cultural principles affect interface perceptions and inform their development. This article will explore Marcus’ work to contextualize diversity issues within usability before exploring the redevelopment strategy for the New York University Libraries’ web presence, which serves a broad and global set of users.","Dragovic,Nik","Code4Lib","http://journal.code4lib.org/articles/10456","infrastructure;interfaces"
"9ab8259834b04f86b678bdd62eea97be",2009,"Using OAI-ORE to Transform Digital Repositories into Interoperable Storage and Services Applications","In the digital age libraries are required to manage large numbers of diverse objects. One advantage of digital objects over fixed physical objects is the flexibility of 'binding' them into publications or other useful aggregated intellectual entities while retaining the ability to reuse them independently in other contexts. An emerging framework for managing flexible aggregations of digital objects is provided by the Open Archives Initiative (OAI) with its work on Object Reuse and Exchange (ORE). This paper will show how OAI-ORE is being used to manage content in digital repositories, in particular institutional repositories, and has the potential ultimately to transform the conception of digital repositories.","Hitchcock,Steve;Brody,Tim;O'Steen,Ben;Tarrant,David;Jefferies,Neil;Carr,Leslie","Code4Lib","http://journal.code4lib.org/articles/1062","OAI-ORE;repositories;standards;interoprable storage"
"9abe6e46f7644547ad81d10afe243c25",2015,"But Then You Have to Make It Happen","Librarianship as a profession has a strong commitment to diversity and tends to attract professionals ethically inclined to champion inclusion. The authors, both from historically underrepresented populations in library information technology, have a half-century of combined experience in the field and have held positions ranging from technician, systems librarian, instructional technologist, head of circulation, and digital scholarship and services librarian to associate dean in an academic library.The authors share their experiences and discuss how diversity and inclusion must be embraced at the individual level in order to develop a culture of diversity within an organization and to attract and retain diverse technology teams.Internal commitments to supporting a diverse environment are ultimately critical to recognizing, assessing, and fulfilling the needs of patrons.The authors identify and detail individual and grassroots efforts that have led to library technology programming for underserved populations, including programs involving outreach to diverse student and prospective student communities over the course of their careers. They reflect on strategies to create and retain a diverse technology group within the library and to advance and support diversity within the day-to-day work environment. They posit that a mix of experiences is necessary to advocate for access to underrepresented patron populations and to negotiate and implement a truly diverse environment with regard to ethnicity, gender, age, and socioeconomic background.","Williams III,James;van Arnhem,Joland-Pieta","Code4Lib","http://journal.code4lib.org/articles/10487","librarianship;diversity"
"9b9d4f5d0c334b1eb9d06db887449063",2011,"Look What We Got! How Inherited Data Drives Decision-Making: UNC-Chapel Hill’s 19th-Century American Sheet Music Collection","Have you inherited a digital collection containing valuable, but inconsistent metadata? And wondered how to transform it into a usable, quality resource while accepting that it can’t meet your idea of perfection? This article describes such an experience at the University of North Carolina at Chapel Hill University Library with its CONTENTdm-based 19th-Century American Sheet Music Collection, addressing issues such as field construction, the use of controlled vocabularies, development of a project data dictionary, and metadata clean-up.","McBride,Renée","Code4Lib","http://journal.code4lib.org/articles/4916","CONTENTdm;Chape Hill;metadata cleaning;controlled vocabularies"
"9b9df34d832c4dd5aecf3897512d2820",2011,"Applying Lessons from 8 Things We Hate About IT to Libraries","Book review of 8 Things We Hate About IT with commentary on how Susan Cramm's points can be applied to libraries.","M. McGeary,Timothy","Code4Lib","http://journal.code4lib.org/articles/4944","book review"
"9d0f1d94b7a34b65b6cfcaaf23a6aa37",2019,"Designing Shareable Tags: Using Google Tag Manager to Share Code","Sharing code between libraries is not a new phenomenon and neither is Google Tag Manager (GTM). GTM launched in 2012 as a JavaScript and HTML manager with the intent of easing the implementation of different analytics trackers and marketing scripts on a website. However, it can be used to load other code using its tag system onto a website. It’s a simple process to export and import tags facilitating the code sharing process without requiring a high degree of coding experience. The entire process involves creating the script tag in GTM, exporting the GTM content into a sharable export file for someone else to import into their library’s GTM container, and finally publishing that imported file to push the code to the website it was designed for. This case study provides an example of designing and sharing a GTM container loaded with advanced Google Analytics configurations such as event tracking and custom dimensions for other libraries using the Summon discovery service. It also discusses processes for designing GTM tags for export, best practices on importing and testing GTM content created by other libraries and concludes with evaluating the pros and cons of encouraging GTM use.","Farney,Tabatha","Code4Lib","https://journal.code4lib.org/articles/14853","code sharing;Google Tag;GTM;JavaScript"
"9dc392b7c57146349df87975d1bfd6d7",2020,"Using Integrated Library Systems and Open Data to Analyze Library Cardholders","The Harrison Public Library in Westchester County, New York operates two library buildings in Harrison: The Richard E. Halperin Memorial Library Building (the library’s main building, located in downtown Harrison) and a West Harrison branch location. As part of its latest three-year strategic plan, the library sought to use existing resources to improve understanding of its cardholders at both locations. To do so, we needed to link the circulation data in our integrated library system, Evergreen, to geographic data and demographic data. We decided to build a geodemographic heatmap that incorporated all three aforementioned types of data. Using Evergreen, American Community Survey (ACS) data, and Google Maps, we plotted each cardholder’s residence on a map, added census boundaries (called tracts) and our town’s borders to the map, and produced summary statistics for each tract detailing its demographics and the library card usage of its residents. In this article, we describe how we acquired the necessary data and built the heatmap. We also touch on how we safeguarded the data while building the heatmap, which is an internal tool available only to select authorized staff members. Finally, we discuss what we learned from the heatmap and how libraries can use open data to benefit their communities.","Sohanchyk,Greg;Briem,Dan","Code4Lib","https://journal.code4lib.org/articles/15340","Evergreen;Google Maps;open data"
"9df344206596485881bdfab67c5f4792",2015,"SierraDNA – Demonstrating the Usefulness of Direct ILS Database Access","Innovative Interface’s Sierra(™) Integrated Library System (ILS) brings with it a Database Navigator Application (SierraDNA) - in layman's terms SierraDNA gives Sierra sites read access to their ILS database. Unlike the closed use cases produced by vendor supplied APIs, which restrict Libraries to limited development opportunities, SierraDNA enables sites to publish their own APIs and scripts based upon custom SQL code to meet their own needs and those of their users and processes. In this article we give examples showing how SierraDNA can be utilized to improve Library services.We highlight three example use cases which have benefited our users, enhanced online security and improved our back office processes. In the first use case we employ user access data from our electronic resources proxy server (WAM) to detect hacked user accounts. Three scripts are used in conjunction to flag user accounts which are being hijacked to systematically steal content from our electronic resource provider’s websites. In the second we utilize the reading histories of our users to augment our search experience with an Amazon style “People who borrowed this book also borrowed…these books” feature. Two scripts are used together to determine which other items were borrowed by borrowers of the item currently of interest. And lastly, we use item holds data to improve our acquisitions workflow through an automated demand based ordering process. Our explanation and SQL code should be of direct use for adoption or as examples for other Sierra customers willing to exploit their ILS data in similar ways, but the principles may also be useful to non-Sierra sites that also wish to enhancement security, user services or improve back office processes.","Padgett,James;Hooper,Jonathan","Code4Lib","http://journal.code4lib.org/articles/10924","API;SierraDNA;ILS"
"9dfb36c5527546269ce8004bff29f359",2014,"An Introduction to Optical Media Preservation","As the archival horizon moves forward, optical media will become increasingly significant and prevalent in collections.This paper sets out to provide a broad overview of optical media in the context of archival migration.We begin by introducing the logical structure of compact discs, providing the context and language necessary to discuss the medium.The article then explores the most common data formats for optical media: Compact Disc Digital Audio, ISO 9660, the Joliet and HFS extensions, and the Universal Data Format (with an eye towards DVD-Video).Each format is viewed in the context of preservation needs and what archivists need to be aware of when handling said formats.Following this, we discuss preservation workflows and concerns for successfully migrating data away from optical media, as well as directions for future research.","Duryee,Alexander","Code4Lib","http://journal.code4lib.org/articles/9581","preservation;archive;migration;compact disks;preservation workflows;data migration"
"9e44cfa47e2f43039df3c9a74e18877b",2014,"Editorial introduction: On libraries, code, support, inspiration, and collaboration","Reflections on the occasion of the 25th issue of the Code4Lib Journal: sustaining a community for support, inspiration, and collaboration at the intersection of libraries and information technology.","Scott,Dan","Code4Lib","http://journal.code4lib.org/articles/9987","editorial"
"9f243ae27c9a41e88ce54325dd411132",2015,"Finding and Supporting New Voices: Code4Lib Journal’s Issue 28 on Diversity in Library Technology","Welcome to Code4Lib Journal’s special issue on diversity in library technology. As C4LJ’s first-ever special issue, 28 brings together a plethora of voices from the library tech world in order to approach the challenge of inclusivity within our field from all directions. Over a year of development has gone into this project, which has involved […]","Elaine Dowding,Heidi","Code4Lib","http://journal.code4lib.org/articles/10518","editorial"
"9fa148ca8abb4fb191d95a14866d52e2",2021,"Digitization Decisions: Comparing OCR Software for Librarian and Archivist Use","This paper is intended to help librarians and archivists who are involved in digitization work choose optical character recognition (OCR) software. The paper provides an introduction to OCR software for digitization projects, and shares the method we developed for easily evaluating the effectiveness of OCR software on resources we are digitizing. We tested three major OCR programs (Adobe Acrobat, ABBYY FineReader, Tesseract) for accuracy on three different digitized texts from our archives and special collections at the University of Western Ontario. Our test was divided into two parts: a word accuracy test (to determine how searchable the final documents were), and a test with a screen reader (to determine how accessible the final documents were). We share our findings from the tests and make recommendations for OCR work on digitized documents from archives and special collections.","Olson,Leanne;Berry,Veronica","Code4Lib","https://journal.code4lib.org/articles/16132","OCR;ABBYY Finereader;Otario;special collection;digitization"
"9fc6dbec1d0e45289d07b798c3c9cfa7",2021,"Advancing ARKs in the Historical Ontology Space","This paper presents the application of Archival Resource Keys (ARKs) for persistent identification and resolution of concepts in historical ontologies. Our use case is the 1910 Library of Congress Subject Headings (LCSH), which we have converted to the Simple Knowledge Organization System (SKOS) format and will use for representing a corpus of historical Encyclopedia Britannica articles. We report on the steps taken to assign ARKs in support of the Nineteenth-Century Knowledge Project, where we are using the HIVE vocabulary tool to automatically assign subject metadata from both the 1910 LCSH and the contemporary LCSH faceted, topical vocabulary to enable the study of the evolution of knowledge.","Kelly,Mat;B. Rauch,Christopher;Greenberg,Jane;Grabus,Sam;Boone,Joan;Kunze,John;M. Logan,Peter","Code4Lib","https://journal.code4lib.org/articles/15608","ARK;persistent identifiers;SKOS;LCSH;HIVE vocabulary;evolution of knowledge"
"9fc6e7f700c44d5aad9f69fa7a139601",2014,"Opening the Door: A First Look at the OCLC WorldCat Metadata API","Libraries have long relied on OCLC’s WorldCat database as a way to cooperatively share bibliographic data and declare library holdings to support interlibrary loan services.As curator, OCLC has traditionally mediated all interactions with the WorldCat database through their various cataloging clients to control access to the information.As more and more libraries look for new ways to interact with their data and streamline metadata operations and workflows, these clients have become bottlenecks and an inhibitor of library innovation.To address some of these concerns, in early 2013 OCLC announced the release of a set of application programming interfaces (APIs) supporting read and write access to the WorldCat database.These APIs offer libraries their first opportunity to develop new services and workflows that directly interact with the WorldCat database, and provide opportunities for catalogers to begin redefining how they work with OCLC and their data.","Reese,Terry","Code4Lib","http://journal.code4lib.org/articles/9863","API;OCLC;metadata;bibliographic data"
"a02c87d0973349208f629d193094618e",2021,"An XML-Based Migration from Digital Commons to Open Journal Systems","The Oregon Library Association has produced its peer-reviewed journal, the OLA Quarterly (OLAQ), since 1995, and OLAQ was published in Digital Commons beginning in 2014. When the host institution undertook to move away from Bepress, their new repository solution was no longer a good match for OLAQ. Oregon State University and University of Oregon agreed to move the journal into their joint instance of Open Journal Systems (OJS), and a small team from OSU Libraries carried out the migration project. The OSU project team declined to use PKP’s existing migration plugin for a number of reasons, instead pursuing a metadata-centered migration pipeline from Digital Commons to OJS. We used custom XSLT to convert tabular data exported from Bepress into PKP’s Native XML schema, which we imported using the OJS Native XML Plugin. This approach provided a high degree of control over the journal’s metadata and a robust ability to test and make adjustments along the way. The article discusses the development of the transformation stylesheet, the metadata mapping and cleanup work involved, as well as advantages and limitations of using this migration strategy.","M. Key,Cara","Code4Lib","https://journal.code4lib.org/articles/15988","XML;OLAQ;Oregon;PKP;OJS;Digital Commons;XML;Bepress;migration;XSLT"
"a07bac4f3aa44249adb5c799286fdf7a",2017,"Building a Scalable and Flexible Library Data Dashboard","Data dashboards provide libraries with the means to demonstrate their ongoing activities and usage in an engaging and communicative fashion. Yet, due to the number of service platforms used by libraries, and the wide-ranging technical specifications they entail, bringing all of this content together in a sustainable way is a significant challenge. This article describes Portland State University’s project to design and build a data dashboard based on a scalable and flexible infrastructure that would enable them to present data in a visually compelling and dynamic interface.","Mealey,Nathan","Code4Lib","http://journal.code4lib.org/articles/12152","data dashboard;Portland;interface"
"a0b1e1cf5c4c48f7ba2831f2bd0b27d8",2015,"Data Munging Tools in Preparation for RDF: Catmandu and LODRefine","Data munging, or the work of remediating, enhancing and transforming library datasets for new or improved uses, has become more important and staff-inclusive in many library technology discussions and projects. Many times we know how we want our data to look, as well as how we want our data to act in discovery interfaces or when exposed, but we are uncertain how to make the data we have into the data we want. This article introduces and compares two library data munging tools that can help: LODRefine (OpenRefine with the DERI RDF Extension) and Catmandu. The strengths and best practices of each tool are discussed in the context of metadata munging use cases for an institution's metadata migration workflow. There is a focus on Linked Open Data modeling and transformation applications of each tool, in particular how metadataists, catalogers, and programmers can create metadata quality reports, enhance existing data with LOD sets, and transform that data to a RDF model. Integration of these tools with other systems and projects, the use of domain specific transformation languages, and the expansion of vocabulary reconciliation services are mentioned.","Harlow,Christina","Code4Lib","http://journal.code4lib.org/articles/11013","LODRefine;OpenRefine;DERI;data munging;RDF;Catmandu;LOD"
"a0ea61f0efe94eeea0e9719934651801",2015,"3D Adaptive Virtual Exhibit for the University of Denver Digital Collections","While the gaming industry has taken the world by storm with its three-dimensional (3D) user interfaces, current digital collection exhibits presented by museums, historical societies, and libraries are still limited to a two-dimensional (2D) interface display. Why can’t digital collections take advantage of this 3D interface advancement? The prototype discussed in this paper presents to the visitor a 3D virtual exhibit containing a set of digital objects from the University of Denver Libraries’ digital image collections, giving visitors an immersive experience when viewing the collections. In particular, the interface is adaptive to the visitor’s browsing behaviors and alters the selection and display of the objects throughout the exhibit to encourage serendipitous discovery.Social media features were also integrated to allow visitors to share items of interest and to create a sense of virtual community.","Yeh,Shea-Tinn;Rynhart,Jeff;Dressler,Thomas;Reyes,Fernando","Code4Lib","http://journal.code4lib.org/articles/10653","3D;interface;Denver;behaviours;exhibit;virtual exhibit"
"a112a74e3b72409996237a634f22f949",2016,"Editorial Introduction: People","by Meghan Finch Two issues ago, coordinating editor Carol Bean identified a focus on data, in our profession and in the Issue 30 articles, and also recognized that as information professionals, it goes beyond just the data to the conventions and standards necessary for working with data. [1] I’d like to offer a similar sentiment […]","Finch,Meghan","Code4Lib","http://journal.code4lib.org/articles/11533","editorial"
"a194d4e0581f47ea88383c9c547972fa",2007,"The Rutgers Workflow Management System: Migrating a Digital Object Management Utility to Open Source","This article examines the development, architecture, and future plans for the Workflow Management System, software developed by Rutgers University Libraries (RUL) to create and catalog digital objects for repository ingest and access. The Workflow Management System (WMS) was created as a front-end utility for the Fedora open source repository platform and a vehicle for a flexible, extensible metadata architecture, to serve the information needs of a large university and its collaborators. The next phase of development for the WMS shifted to a re-engineering of the WMS as an open source application. This paper discusses the design and architecture of the WMS, its re-engineering for open source release, remaining issues to be addressed before application release, and future development plans for the WMS.","Agnew,Grace;Yu,Yang","Code4Lib","http://journal.code4lib.org/articles/25","Rutgers;workflow management system;WMS;design;architecture"
"a2c70ba9787545108594a1977262cc74",2018,"Piloting a Homegrown Streaming Service with IaaS","Bridgewater State University’s Maxwell Library has offered streaming film & video as a service in some form since 2008. Since 2014 this has been done through the use of the Infrastructure as a Service (IaaS) cloud provider Amazon Web Services (AWS) and their CloudFront content delivery network (CDN). This has provided a novel and low-cost alternative to various subscription and hosted platforms. However, with CloudFront’s reliance on external media players and Flash via Adobe’s Real-Time Messaging Protocol (RTMP) to stream content, the upcoming end of support for Flash in 2020, and other security and accessibility concerns of library staff, an alternative method of delivery for this extremely popular and successful service was sought in summer and fall of 2017. With budget limitations, a flawed video streaming service currently in place, and University IT’s desire to move much of its infrastructure to the IaaS and cloud provider, Microsoft Azure, a pilot of a secure, multi-bitrate HTML5 streaming service via Azure Media Services was conducted. This article describes the background of Maxwell Library’s streaming service, the current state of streaming services and technologies, Azure IaaS configuration, implementation, and findings.","T. Wilson,Robert;Dubinsky,Ellen","Code4Lib","https://journal.code4lib.org/articles/13823","Bridgewater;streaming;IaaS;cloud;Amazon;HTML5"
"a3a103dc563e460690eaafa328fd0953",2009,"BOOK REVIEW: Semantic Web for the Working Ontologist","Written by two of the leading authorities on the semantic web, the ""Semantic Web for the Working Ontologist"" is a timely and thorough introduction to the topic. Covering RDF, RDFS, and OWL, the book takes a logical, trainerly approach, with practical and illuminating examples. Well worth a read.","Keays,Tom","Code4Lib","http://journal.code4lib.org/articles/1480","book review"
"a408d033573d4e31bb56357b3bfff4f9",2021,"Always Be Migrating","At the University of California, Los Angeles, the Digital Library Program is in the midst of a large, multi-faceted migration project. This article presents a narrative of migration and a new mindset for technology and
library staff in their ever-changing infrastructure and systems. This article posits that migration from system to system should be integrated into normal activities so that it is not a singular event or major project, but so that it is a process built into the core activities of a unit.","McAulay,Elizabeth","Code4Lib","https://journal.code4lib.org/articles/15568","California;migration;infrastructure"
"a55f8ca49e3142bd86ae31234d3e5f0e",2018,"Editorial Edit","A few words about our editors.A farewell to one editor.A solicitation for new editors.","Darby,Andrew","Code4Lib","https://journal.code4lib.org/articles/13988","editorial"
"a598dcec8eff4a8f826a537fc1ef7c27",2012,"Using XSLT's SQL Extension with Encyclopedia Virginia","This paper explores how to integrate data across a hybrid relational database and XML-based management system. It examines specifically how XSLT's SQL extension can be used to communicate information between SQL tables and TEI-conformant XML documents to make data-centric content more manageable and flexible and thereby leverage the strengths of both systems. In what follows, one will learn about some of the methods, benefits, and shortcomings of XSLT's SQL extension in the context of Encyclopedia Virginia, an open access publication of the Virginia Foundation for the Humanities that utilizes a suite of digital humanities and digital library XML vocabularies such as TEI and METS.","Gibson,Matthew","Code4Lib","http://journal.code4lib.org/articles/6486","XSLT;XML;TEI;METSSQL;vocabularies"
"a63890d739f044d58e3e9f31e91c171b",2020,"Automated Collections Workflows in GOBI: Using Python to Scrape for Purchase Options","The NC State University Libraries has developed a tool for querying GOBI, our print and ebook ordering vendor platform, to automate monthly collections reports. These reports detail purchase options for missing or long-overdue items, as well as popular items with multiple holds. GOBI does not offer an API, forcing staff to conduct manual title-by-title searches that previously took up to 15 hours per month. To make this process more efficient, we wrote a Python script that automates title searches and the extraction of key data (price, date of publication, binding type) from GOBI. This tool can gather data for hundreds of titles in half an hour or less, freeing up time for other projects.This article will describe the process of creating this script, as well as how it finds and selects data in GOBI. It will also discuss how these results are paired with NC State’s holdings data to create reports for collection managers. Lastly, the article will examine obstacles that were experienced in the creation of the tool and offer recommendations for other organizations seeking to automate collections workflows.","Frazier,Katharine","Code4Lib","https://journal.code4lib.org/articles/15334","API;GOBI;Python;workflow"
"a7c0601744a843039764e24f1fa5fd3f",2014,"Processing Government Data: ZIP Codes, Python, and OpenRefine","While there is a vast amount of useful US government data on the web, some of it is in a raw state that is not readily accessible to the average user. Data librarians can improve accessibility and usability for their patrons by processing data to create subsets of local interest and by appending geographic identifiers to help users select and aggregate data. This case study illustrates how census geography crosswalks, Python, and OpenRefine were used to create spreadsheets of non-profit organizations in New York City from the IRS Tax-Exempt Organization Masterfile. This paper illustrates the utility of Python for data librarians and should be particularly insightful for those who work with address-based data.","Donnelly,Frank","Code4Lib","http://journal.code4lib.org/articles/9652","OpenRefine;Python;data librarians;data;government data;case study"
"a7fc0ef1b99e40ca99646969feac6819",2013,"From Finding Aids to Wiki Pages: Remixing Archival Metadata with RAMP","The Remixing Archival Metadata Project (RAMP) is a lightweight web-based editing tool that is intended to let users do two things: (1) generate enhanced authority records for creators of archival collections and (2) publish the content of those records as Wikipedia pages. The RAMP editor can extract biographical and historical data from EAD finding aids to create new authority records for persons, corporate bodies, and families associated with archival and special collections (using the EAC-CPF format). It can then let users enhance those records with additional data from sources like VIAF and WorldCat Identities. Finally, it can transform those records into wiki markup so that users can edit them directly, merge them with any existing Wikipedia pages, and publish them to Wikipedia through its API.","González,David;Little,James;A. Thompson,Timothy;Darby,Andrew;Carruthers,Matt","Code4Lib","http://journal.code4lib.org/articles/8962","API;RAMP;archival metadata;EAD;VIAF;WorldCat;Wikipedia"
"a803c236b8574b2db4d6eb2370a6f72a",2019,"Create Efficient, Platform-neutral, Web-Based Augmented Reality Content in the Library","Augmented reality (AR) is an interactive experience of viewing computed-generated objects onto your view of the real world. Since the Pokemon Go craze in 2016, many libraries have tested the waters with AR programs. Some went on to the next step of developing their own AR content to enhance library services and marketing. While there are many AR applications that libraries can use for this purpose, it usually thwarts customers that they must install various AR mobile apps in order to enjoy these experiences on their own devices. This becomes the major hurdle of making AR more enjoyable and accessible at the library. What's more, libraries cannot share home-grown AR content across different platforms easily because of the technical barriers in various AR platforms. In this article, I would like to introduce a completely open source AR developing tool that allows library staff to create fast and efficient AR content with pure web solutions. It is standard and works on mobile devices with no installation required. I have created a basic AR experience with the tool for a regional Pacific Library Partnership conference and it proved to be a success in improving the accessibility and shareability of AR content.","Lou,Dan","Code4Lib","https://journal.code4lib.org/articles/14632","augmented reality"
"a816b548bd2540a9ab7ecc78deb072b5",2016,"Shining a Light on Scientific Data: Building a Data Catalog to Foster Data Sharing and Reuse","The scientific community's growing eagerness to make research data available to the public provides libraries -- with our expertise in metadata and discovery -- an interesting new opportunity. This paper details the in-house creation of a ""data catalog"" which describes datasets ranging from population-level studies like the US Census to small, specialized datasets created by researchers at our own institution. Based on Symfony2 and Solr, the data catalog provides a powerful search interface to help researchers locate the data that can help them, and an administrative interface so librarians can add, edit, and manage metadata elements at will. This paper will outline the successes, failures, and total redos that culminated in the current manifestation of our data catalog.","Lamb,Ian;Larson,Catherine","Code4Lib","http://journal.code4lib.org/articles/11421","data catalog;data sharing;Solr;Symfony"
"a850989610884acd89a551ee23f4447f",2010,"FRBRizing an E-Library : Migrating from Dublin Core to FRBR and MODS","Western State College in Gunnison, Colorado developed an open-source eCataloger Framework, based on Dublin Core metadata, on Google's App Engine to manage and serve electronic resources to the library's patrons. Pressed to find new solutions for failing manual workflows for serials and government document resource management, the eCataloger Framework was extended to FRBR to automate and enhance serials management and government documents receiving. Based on successfully FRBRizing the eCataloger, Western State College converted their e-Library management from Dublin Core to FRBR and MODS. This paper examines the processes of each of these implementations using Python, AJAX, and jQuery, the details of the FRBR data model, including using FRBRoo, and the successful user interface supported by a FRBRized catalog.","Nelson,Jeremy;Cleary,Alan","Code4Lib","http://journal.code4lib.org/articles/4357","FRBR00;FRBR;MODSDublin Core;Python;AJAX;jQuery"
"a90729bc5ecc460ea119417a3e11d7fa",2021,"Institutional Data Repository Development, a Moving Target","At the end of 2019, the Research Data Service (RDS) at the University of Illinois at Urbana-Champaign (UIUC) completed its fifth year as a campus-wide service. In order to gauge the effectiveness of the RDS in meeting the needs of Illinois researchers, RDS staff developed a five-year review consisting of a survey and a series of in-depth focus group interviews. As a result, our institutional data repository developed in-house by University Library IT staff, Illinois Data Bank, was recognized as the most useful service offering by our unit. When launched in 2016, storage resources and web servers for Illinois Data Bank and supporting systems were hosted on-premises at UIUC. As anticipated, researchers increasingly need to share large, and complex datasets. In a responsive effort to leverage the potentially more reliable, highly available, cost-effective, and scalable storage accessible to computation resources, we migrated our item bitstreams and web services to the cloud. Our efforts have met with success, but also with painful bumps along the way. This article describes how we supported data curation workflows through transitioning from on-premises to cloud resource hosting. It details our approaches to ingesting, curating, and offering access to dataset files up to 2TB in size--which may be archive type files (e.g., .zip or .tar) containing complex directory structures.","Fallaw,Colleen;Schmitt,Genevieve;Luong,Hoa;Colwell,Jason;Strutz,Jason","Code4Lib","https://journal.code4lib.org/articles/15821","UIUC;RDS;data repositories;data curation"
"a930476b5be9439e9d7acd58128e0d93",2020,"How to Use an API Management platform to Easily Build Local Web Apps","Setting up an API management platform like DreamFactory can open up a lot of possibilities for potential projects within your library. With an automatically generated restful API, the University Libraries at Virginia Tech have been able to create applications for gathering walk-in data and reference questions, public polling apps, feedback systems for service points, data dashboards and more. This article will describe what an API management platform is, why you might want one, and the types of potential projects that can quickly be put together by your local web developer.","Bradley,Jonathan","Code4Lib","https://journal.code4lib.org/articles/15190","API;DreamFactory;RESTfull API"
"a93c082876e449c7a57ac5c11346e783",2018,"Redux: Tabulating Transactions with Raspberry Pi and Visualizing Results","Often in the library tech world we are not given the opportunity to attempt a project again. Effort spent re-doing a previous project in a different way, in some sense, means wasting time that could be used to work on new initiatives. This article describes a redux of a project, a revenge story so to speak. In 2013 the Arduino based Tabulatron first entered production at Brock University Library. The device had its flaws, an attempt to rectify those flaws was manifested in the creation of the PiTab, the story of which is presented here.","Ribaric,Tim","Code4Lib","http://journal.code4lib.org/articles/13385","Redux;Raspberry Pi;PiTab"
"a9fc5108b6b74633a1a2885f2fdbedad",2017,"Web-Scraping for Non-Programmers: Introducing OXPath for Digital Library Metadata Harvesting","Building up new collections for digital libraries is a demanding task. Available data sets have to be extracted which is usually done with the help of software developers as it involves custom data handlers or conversion scripts. In cases where the desired data is only available on the data provider's website custom web scrapers are needed. This may be the case for small to medium-size publishers, research institutes or funding agencies. As data curation is a typical task that is done by people with a library and information science background, these people are usually proficient with XML technologies but are not full-stack programmers. Therefore we would like to present a web scraping tool that does not demand the digital library curators to program custom web scrapers from scratch. We present the open-source tool OXPath, an extension of XPath, that allows the user to define data to be extracted from websites in a declarative way. By taking one of our own use cases as an example, we guide you in more detail through the process of creating an OXPath wrapper for metadata harvesting. We also point out some practical things to consider when creating a web scraper (with OXPath). On top of that, we also present a syntax highlighting plugin for the popular text editor Atom that we developed to further support OXPath users and to simplify the authoring process.","Neumann,Mandy;Steinberg,Jan;Schaer,Philipp","Code4Lib","http://journal.code4lib.org/articles/13007","web scraping;OXPath;metadata harvesting;XML;data curationXPath;authoring process"
"ab1d769c3dae4614bf920ec4ff48f7ec",2012,"A Hybrid Solution for Improving Single Sign-On to a Proxy Service with Squid and EZproxy through Shibboleth and ExLibris’ Aleph X-Server","This paper describes an implementation of a hybrid solution for improving the library's proxy service by integrating Shibboleth and ExLibris' Aleph’s X-server using a proxy server running both EZproxy and Squid applications. We will describe in detail the hybrid solution of a proxy service within the context of our institution and explain how this service improves the user experience. We will explain how we developed and implemented this solution with a minimum of development cost and describe some of the preliminary empirical research undertaken. The main benefit of this solution is that instead of relying on e-resource vendors to become Shibboleth-compliant, we are able to prepare and deploy a Shibboleth-ready environment while granting our patrons reliable and stable access to e-resources via different types of connections. As of December 2011, the hybrid solution is running in production.","Jerabek,Alexander;Nguyen,Minh-Quang","Code4Lib","http://journal.code4lib.org/articles/7470","Ezproxy;ExLibris;Aleph;Shibboleth"
"abf337200cfb476299ecccc8a3cceb5d",2019,"“With One Heart”: Agile approaches for developing Concordia and crowdsourcing at the Library of Congress","In October 2018, the Library of Congress launched its crowdsourcing program By the People (https://crowd.loc.gov) . The program is built on Concordia (https://github.com/libraryofcongress/concordia), a transcription and tagging tool developed to power crowdsourced transcription projects. Concordia is open source software designed and developed iteratively at the Library of Congress using Agile methodology and user-centered design. Applying Agile principles allowed us to create a viable product while simultaneously pushing at the boundaries of capability, capacity, and customer satisfaction. In this article, we share more about the process of designing and developing Concordia, including our goals, constraints, successes, and next steps.","Ferriter,Meghan;Zwaard,Kate;Kamlley,Elaine;Storey,Rosie;Adams,Chris;Algee,Lauren;Van Hyning,Victoria;Bresner,Jamie;Potter,Abigail;Jakeway,Eileen;Brunton,David","Code4Lib","https://journal.code4lib.org/articles/14901","Library of Congress;crowdsourcing;tagging;Agile principles;Concordia"
"acfa09f2a1964201ac8513eee6d1fcc3",2021,"Core Concepts and Techniques for Library Metadata Analysis","Metadata analysis is a growing need in libraries of all types and sizes, as demonstrated in many recent job postings. Data migration, transformation, enhancement, and remediation all require strong metadata analysis skills. But there is no well-defined body of knowledge or competencies list for library metadata analysis, leaving library staff with analysis-related responsibilities largely on their own to learn how to do the work effectively. In this paper, two experienced metadata analysts will share what they see as core knowledge areas and problem solving techniques for successful library metadata analysis. The paper will also discuss suggested tools, though the emphasis is intentionally not to prescribe specific tools, software, or programming languages, but rather to help readers recognize tools that will meet their analysis needs. The goal of the paper is to help library staff and their managers develop a shared understanding of the skill sets required to meet their library’s metadata analysis needs. It will also be useful to individuals interested in pursuing a career in library metadata analysis and wondering how to enhance their existing knowledge and skills for success in analysis work.","Traill,Stacie;Patrick,Martin","Code4Lib","https://journal.code4lib.org/articles/16078","metadata analysis;tools;skills"
"ad54548a37cc4b2a9bd09eedd2ad9cad",2014,"EgoSystem: Where are our Alumni?","Comprehensive social search on the Internet remains an unsolved problem. Social networking sites tend to be isolated from each other, and the information they contain is often not fully searchable outside the confines of the site. EgoSystem, developed at Los Alamos National Laboratories (LANL), explores the problems associated with automated discovery of public online identities for people, and the aggregation of the social, institution, conceptual, and artifact data connected to these identities. EgoSystem starts with basic demographic information about former employees and uses that information to locate person identities in various popular online systems. Once identified, their respective social networks, institutional affiliations, artifacts, and associated concepts are retrieved and linked into a graph containing other found identities. This graph is stored in a Titan graph database (http://titan.thinkaurelius.com/) and can be explored using the Gremlin graph query-traversal language (http://gremlin.tinkerpop.com/) and with the EgoSystem Web interface.","Powell,James;Shankar,Harihar;Rodriguez,Marko;Van de Sompel,Herbert","Code4Lib","http://journal.code4lib.org/articles/9519","Los Alamos;LANL;EgoSystem;graph database"
"ad722e9cabd64e9e851a227a2f046efb",2015,"“What If I Break It?”: Project Management for Intergenerational Library Teams Creating Non-MARC Metadata","Libraries are constantly challenged to meet new user needs and to provide access to new types of materials.We are in the process of launching many new technology-rich initiatives and projects which require investments of staff time, a resource which is at a premium for most new library hires.We simultaneously have people on staff in our libraries with more traditional skill sets who may be able to contribute time and theoretical expertise to these projects, but require training.Incorporating these “seasoned” employees into new initiatives can be a daunting task. In this article, I will share some of the strategies I have used as a metadata project manager for bridging diverse generations of library staff who have various levels of comfort and expertise with technology, and strategies that I have used to reduce the barriers to participation for staff with diverse perspectives and skill sets.These strategies can also be helpful in assisting a new librarian with technology-rich skill sets to more successfully orient themselves when embedded in a “traditional” library setting.","Thompson,Kelly","Code4Lib","http://journal.code4lib.org/articles/10395","project management;skills;librarians;metadata;strategies"
"ada446c3469a40bbaa8d15c34c2a6241",2014,"How the WSLS-TV News Digitization Project Helped to Launch a Project Management Office","This article discusses how the WSLS-TV News Digitization Project at the University of Virginia Libraries was the catalyst for creating a more formalized project workflow and the eventual creation of a Project Management Office. The project revealed the need for better coordination between various groups in the library and more transparent processes. By creating well documented policies and processes, the new project workflow clarified roles, improved communication, and created greater transparency. The new processes enabled staff to understand how decisions are made and resources allocated which allowed them to work more efficiently.","Glendon,Ivey;Baumann,Melinda","Code4Lib","http://journal.code4lib.org/articles/8652","WSLS-TV;digitization project;news"
"adfdb642d5694acab30e57a85e7e6c0d",2011,"ISBN and QR Barcode Scanning Mobile App for Libraries","This article outlines the development of a mobile application for the Ryerson University Library. The application provides for ISBN barcode scanning that results in a lookup of library copies and services for the book scanned, as well as QR code scanning. Two versions of the application were developed, one for iOS and one for Android. The article includes some details on the free packages used for barcode scanning functionality. Source code for the Ryerson iOS and Android applications are freely available, and instructions are provided on customizing the Ryerson application for use in other library environments. Some statistics on the number of downloads of the Ryerson mobile app by users are included.","McCarthy,Graham;Wilson,Sally","Code4Lib","http://journal.code4lib.org/articles/5014","ISBN;Reyerson;QR codes;iOS;Android"
"ae87123c1f624be8882127c416f627d8",2009,"Editorial Introduction - Code4Lib: Long May You Run","The Code4Lib Journal mirrors the diversity and depth of interests and expertise of its readership. Our successes, indeed, are yours.","Keays,Tom","Code4Lib","http://journal.code4lib.org/articles/1695","editorial"
"ae9f5bdcf2294da5b710966cfdf0e2dc",2013,"Indexing Linked Bibliographic Data with JSON-LD, BibJSON and Elasticsearch","Linked Data is a powerful tool for sharing bibliographic metadata. By combining the decentralization of the web with the use of globally defined metadata vocabularies, data from many sources can be treated as a single, aggregated graph. Supporting search across these distributed data sources within the same application, however, requires considerable work in vocabulary alignment and data transformation. Aggregate systems must convert data into a unified model which must (almost inevitably) be generic at the expense of the structure and granularity of the original data. This paper presents a novel solution for representing and indexing bibliographic resources that retains the data integrity and extensibility of Linked Data while supporting fast, customizable indexes in an application-friendly data format. The methodology makes use of JSON-LD to represent RDF graphs in JSON suitable for indexing with Elasticsearch. BibJSON is used as a common index format capable of handling a wide range of library resources. Since all three technologies (RDF/JSON-LD, BibJSON and Elasticsearch) share an emphasis on extensibility, it is possible to create an index of bibliographic data that is both generalized and flexible enough to handle Linked Data from multiple sources.","Johnson,Thomas","Code4Lib","http://journal.code4lib.org/articles/7949","JSON-LD;BibJSON;Elasticsearch;bibliographic data;linked data;RDF;graphs;indexing"
"af298169e78c417f9555533a569dc611",2008,"Collecting Virtual Reference Statistics with an IM Chat-Bot","A perennial problem in libraries is capturing accurate statistics. This article addresses this problem with the creative use of Web 2.0 tools: Meebo and AOL Instant Messenger. It describes the development and implementation of an instant messaging ""stat-bot"" that prompts staff to record virtual reference statistics via IM. Step-by-step guidelines and the perl script are provided.","R.K. Hall,Mason","Code4Lib","http://journal.code4lib.org/articles/85","statistics;Meebo;AOL Instant Messenger;Perl"
"afa8f02e62e44b6e9569d51b5953f74f",2021,"Editorial: Closer to 100 than to 1","With the publication of Issue 51, the Code4Lib Journal is now closer to Issue 100 than we are to Issue 1.Also, we are developing a name change policy.","M. Corrado,Edward","Code4Lib","https://journal.code4lib.org/articles/15971","editorial"
"b0283977b9904888baba08cc37e7ee9a",2008,"SPECIAL REPORT: Creating Conference Video","Capturing video at a conference is easy. Doing it so the product is useful is another matter. Many subtle problems come into play so that video and audio obtained can be used to create a final product. This article discusses what the author learned in the two years of shooting and editing video for Code4Lib conference.","F. Peden,Noel","Code4Lib","http://journal.code4lib.org/articles/555","report"
"b10359a8dea1443babc801e92d66179d",2011,"iRoam: Leveraging Mobile Technology to Provide Innovative Point of Need Reference Services","The University of Northern British Columbia’s Geoffrey R. Weller Library can boast of a healthy and stable reference service. While statistical analysis reveals that patron use of this service is on the decline, this is not unlike current trends experienced by many libraries today. The library averages a total of 6300 reference transactions per year, a significant number for a small, research-intensive university serving 3500 FTE. The unanswered question is why are the numbers dropping? One theory is that providing research and reference assistance in a traditional manner is affecting the number of transactions. Reference service is traditionally provided in a stationary manner, whereby patrons are required to visit the reference desk of their own volition. Recognizing that a stationary librarian cannot reach a stationary patron, UNBC library began an innovative roaming reference pilot project in September, 2010. Combining the power of wireless networks, tablet computing and chat services, 5 librarians provided point-of-need, face-to-face and virtual reference services during peak reference hours over the fall 2010 semester. This article outlines the project and technologies employed to make it happen (iPad, apps, instant messaging widgets and wireless networks).","MacDonald,James;McCabe,Kealin","Code4Lib","http://journal.code4lib.org/articles/5038","iRoam;UNBC;statistical analysis;reference service"
"b186e5a52a7449cb8e5553454ea869e5",2017,"Bridging Technologies to Efficiently Arrange and Describe Digital Archives: the Bentley Historical Library’s ArchivesSpace-Archivematica-DSpace Workflow Integration Project","In recent years, ArchivesSpace and Archivematica have emerged as two of the most exciting open source platforms for working with digital archives. The former manages accessions and collections and provides a framework for entering descriptive, administrative, rights, and other metadata. The latter ingests digital content and prepares information packages for long-term preservation and access.In October 2016, the Bentley Historical Library wrapped up a two-year, $355,000 grant from the Andrew W. Mellon Foundation to partner with the University of Michigan Library on the integration of these two systems in an end-to-end workflow that will include the automated deposit of content into a DSpace repository. This article provides context of the project and offers an in-depth exploration of the project’s key development tasks, all of which were provided by Artefactual Systems, the developers of Archivematica (code available at https://github.com/artefactual-labs/appraisal-tab).","Eckard,Max;Pillen,Dallas;Shallcross,Mike","Code4Lib","http://journal.code4lib.org/articles/12105","ArchivesSpace;Arhivematica;long-term preservation;Dspace"
"b1d0b1e151ed4d08b155a78155f4a9a9",2011,"Using Web Services for a Mobile OPAC","The purpose of this paper is to discuss the creation and intended evolution of the Rice University mobile online public access catalog (OPAC). The focus of the article is on how SirsiDynix’s Symphony Web Services can be used to create a mobile OPAC.","Galvin,Denis;Sun,Mang","Code4Lib","http://journal.code4lib.org/articles/4810","OPAC;Rice;SirsiDynix;mobile"
"b2267e10e6064b2ea352c2fbc1895e07",2013,"Fedora Commons With Apache Hadoop: A Research Study","The Digital Collections digital repository at the University of Maryland Libraries is growing and in need of a new backend storage system to replace the current filesystem storage. Though not a traditional storage management system, we chose to evaluate Apache Hadoop because of its large and growing community and software ecosystem. Additionally, Hadoop’s capabilities for distributed computation could prove useful in providing new kinds of digital object services and maintenance for ever increasing amounts of data. We tested storage of Fedora Commons data in the Hadoop Distributed File System (HDFS) using an early development version of Akubra-HDFS interface created by Frank Asseg. This article examines the findings of our research study, which evaluated Fedora-Hadoop integration in the areas of performance, ease of access, security, disaster recovery, and costs.","Rasheed,Abdul;Mohideen,Mohamed","Code4Lib","http://journal.code4lib.org/articles/8988","Fedora Commons;digital repository;Maryland;Apache Hadoop"
"b2430450e95a4faf900b8c82d9259657",2018,"Adaptation: the Continuing Evolution of the New York Public Library’s Digital Design System","A design system is crucial for sustaining both the continuity and the advancement of a website's design. But it's hard to create such a system when content, technology, and staff are constantly changing. This is the situation faced by the Digital team at the New York Public Library. When those are the conditions of the problem, the design system needs to be modular, distributed, and standardized, so that it can withstand constant change and provide a reliable foundation. NYPL's design system has gone through three major iterations, each a step towards the best way to manage design principles across an abundance of heterogeneous content and many contributors who brought different skills to the team and department at different times. Starting from an abstracted framework that provided a template for future systems, then a specific component system for a new project, and finally a system of interoperable components and layouts, NYPL's Digital team continues to grow and adapt its digital design resource.","L. Anderson,Jennifer;Guzman,Edwin","Code4Lib","https://journal.code4lib.org/articles/13657","NYPL;design;layout"
"b3813f67e0da46f1abd6e17917b1017d",2014,"A Video Digital Library to Support Physicians’ Decision-making About Autism","A prototype Digital Video Library was developed as part of a project to assist rural primary care clinics with diagnosis of autism, funded by the National Network of Libraries of Medicine.The Digital Video Library takes play sample videos generated by a rural clinic and makes it available to experts at the Autism Spectrum Disorders (ASD) Clinic at The University of Alabama.The experts are able to annotate segments of the video using an integrated version of the Childhood Autism Ratings Scale-Second Edition Standard Version (CARS2).The Digital Video Library then extracts the annotated segments, and provides a robust search and browse feature.The videos can then be accessed by the subject's primary care physician.This article summarizes the development and features of the Digital Video Library.","A. Griffin,Matthew;Albertson,Dan;B. Barber,Angela","Code4Lib","http://journal.code4lib.org/articles/9281","autism;Alabama;CARS2;video;annotation"
"b523df66c22d4cd3bdbb6a55c523cccc",2017,"Testing Three Types of Raspberry Pi People Counters","The Hudson County Community College (HCCC) Library tested three different types of Raspberry Pi based people counters between 6/14/2017 and 7/9/2017. This article will describe how we created each type of counter, will compare the accuracy of each sensor, and will compare them to the college’s existing 3M 3501 gate counters. It will also describe why and how our team decided to make this project, discuss lessons learned, and provide instructions for how other libraries can create their own gate counters.","Cintron,Johnathan;Courtier,Devlyn;DeLooper,John","Code4Lib","http://journal.code4lib.org/articles/12947","Raspberry Pi;gate counters"
"b5f321af0298429da96672d30ac31010",2008,"Rasmuson Library DVD Browser:Fun with Screen Scraping and Drupal","The DVD Browser is a simple application that lets library patrons browse movie covers, titles, and reviews.It works by screen scraping the the Rasmuson Library catalog for DVD movies and dumps the data into a Drupal MySQL database. This paper describes the process of setting up the DVD Browser.","Morlino,Mark;Kingsley,Ilana","Code4Lib","http://journal.code4lib.org/articles/469","Drupal;DVD;Rasmuson"
"b7d8fd362033428e9210fcce079a19aa",2021,"Conspectus: A Syllabi Analysis Platform for Leganto Data Sources","In recent years, higher education institutions have implemented electronic solutions for the management of syllabi, resulting in new and exciting opportunities within the area of large-scale syllabi analysis. This article details an information pipeline that can be used to harvest, enrich and use such information.","Massey,David;Sødring,Thomas","Code4Lib","https://journal.code4lib.org/articles/15995","Conspectus;syllabi;information piipeline;harvesting;enrichment"
"b80eeada5ebc4d6b9a28da28e9c6f62b",2018,"Copyright and access restrictions–providing access to the digital collections of Leiden University Libraries with conditional access rights","To provide access to the digitized collections without breaking any copyright laws, Leiden University Library built a copyright module for their Islandora-based repository. The project was not just about building a technical solution, but also addressed policy, metadata, and workflows. A fine-grained system of access rights was set up, distinguishing conditions based on metadata, IP address, authentication and user role.","van Bergen,Saskia;van Schaik,Lucas","Code4Lib","https://journal.code4lib.org/articles/13588","copyright;access restriction;Leiden;access rights;project;Islandora"
"b8126cc458654a2fb3215320dac621b1",2019,"Responsive vs. Native Mobile Search: A Comparative Study of Transaction Logs","The Consortium of Academic and Research Libraries in Illinois (or CARLI) is comprised of 130 libraries, a majority of which participate in the union catalog I-Share for resource sharing. The consortium implemented VuFind 4, a responsive web interface, as their shared union catalog in December 2017. This study compared search transaction logs from a native mobile app that serves the consortium with search transactions in the responsive mobile browser.Library professionals in the consortium sought to understand the nature of mobile search features by evaluating the relative popularity of mobile devices used, search terms, and search facets within the two mobile search options.The significance of this research is that it provides comparative data on mobile search features to the library UX community.","Hahn,Jim","Code4Lib","https://journal.code4lib.org/articles/14419","CARL;consortium;study;logs analysis;VuFind"
"b850c7e40c0e4b7c893960f9700560f2",2012,"Patron-Driven Expedited Cataloging Enhancement to WebPAC Pro","This article outlines the development of an integrated patron-driven expedited cataloging feature in the catalog of the Connecticut State University Library System (CONSULS). The proposed enhancement to the library’s Innovative Millennium ILS provides users with a direct method for obtaining newly-arrived library materials and allows the Cataloging & Metadata Services Departments at the four Connecticut State University campuses a way to better identify priority materials in their queues. While the project was developed with a single ILS in mind, the idea behind it can easily be implemented on most any other integrated library system. Two versions of the enhancement are covered: one for standalone libraries and one for libraries that share a union catalog. The source-codes for both versions of the enhancement are provided, as are instructions for implementing the enhancement on any Millennium installation.","Jay Bernstein,Steven","Code4Lib","http://journal.code4lib.org/articles/7179","WebPAC;Connecticut;ILS;Millenium"
"b85c021a41294e368885a7d27803d197",2018,"Using Static Site Generators for Scholarly Publications and Open Educational Resources","Libraries that publish scholarly journals, conference proceedings, or open educational resources can use static site generators in their digital publishing workflows. Northwestern University Libraries is using Jekyll and Bookdown, two open source static site generators, for its digital publishing service. This article discusses motivations for experimenting with static site generators and walks through the process for using these technologies for two publications.","Diaz,Chris","Code4Lib","https://journal.code4lib.org/articles/13861","static sites;Jekyll;digital publishing"
"b8ffb79c6af943d9b821fa122836dcb9",2010,"Implementing a Real-Time Suggestion Service in a Library Discovery Layer","As part of an effort to improve user interactions with authority data in its online catalog, the UNC Chapel Hill Libraries have developed and implemented a system for providing real-time query suggestions from records found within its catalog. The system takes user input as it is typed to predict likely title, author, or subject matches in a manner functionally similar to the systems found on commercial websites such as google.com or amazon.com. This paper discusses the technologies, decisions and methodologies that went into the implementation of this feature, as well as analysis of its impact on user search behaviors.","Pennell,Benjamin;Sexton,Jill","Code4Lib","http://journal.code4lib.org/articles/3022","UNC;Chapel Hill;suggestion service;search; search behaviours"
"b969bf77fee14848b502902059dd8ae0",2015,"Homegrown WorldCat Reclamation: Utilizing OCLC’s WorldCat Metadata API to Reconcile Your Library’s Holdings","OCLC’s WorldCat Metadata API now allows libraries to set and delete their OCLC holdings without using Connexion or Batch Services. St. Olaf College Libraries had used up our “one free turn” at a reclamation several years ago. Unfortunately due to the normal inconsistencies that accumulate over time, as well as problems with holdings being set for us by external entities, we had reached a point where we were once again in need of reconciling our holdings with OCLC's. This time we wanted to accomplish the reclamation in a low-cost way that would also allow us to have more local control over the process. Using the WorldCat Search API and Metadata API in tandem, we first retrieved all OCLC numbers with holdings currently set and deleted these holdings with a fairly simple Perl script. We then pulled from our local catalog all the OCLC numbers for which we wanted holdings set and updated again using the Metadata API. The result, in the words of one of our catalogers, is that “For the first time since I got here, 15 years ago, I feel our holdings finally reflect what we really own.” In this article, I will discuss the issues to consider if you wish to do a similar project with your OCLC holdings, share the Perl scripts I wrote for processing, and reflect on the pros and cons of the process overall.","Johnston,Sarah","Code4Lib","http://journal.code4lib.org/articles/10328","API;OCLC;WorldCat;Perl"
"b97cee0533de4424b204d5e1107a946d",2008,"Developing an Academic Image Collection with Flickr","A group at Lewis & Clark College in Portland are in the process of developing an educational collection of contemporary ceramics images using the photo sharing site Flickr as a back end. This article discusses the evolution of the project, Flickr machine tags, and the concept of Flickr as an application database layer. The article includes code samples for creating and querying machine tags using the Flickr API.","McWilliams,Jeremy","Code4Lib","http://journal.code4lib.org/articles/74","API;Portland;Flikr;machine tags;image collection"
"b99cdae5d3eb4f5f838101bef147ed27",2011,"Web-Based Software Integration For Dissemination Of Archival Images: The Frontiers Of Science Website","The Frontiers of Science illustrated comic strip of 'science fact' ran from 1961 to 1982, syndicated worldwide through over 600 newspapers. The Rare Books and Special Collections Library at the University of Sydney, in association with Sydney eScholarship, digitized all 939 strips. We aimed to create a website that could disseminate these comic strips to scholars, enthusiasts and the general public. We wanted to enable users to search and browse through the images simply and effectively, with an intuitive and novel viewing platform. Time and resource constraints dictated the use of (mostly open source) code modules wherever possible and the integration and customisation of a range of web-based applications, code snippets and technologies (DSpace, eXtensible Text Framework (XTF), OmniFormat, JQuery Tools, Thickbox and Zoomify), stylistically pulled together using CSS. This approach allowed for a rapid development cycle (6 weeks) to deliver the site on time as well as provide us with a framework for similar projects.","Browne,Gary","Code4Lib","http://journal.code4lib.org/articles/5387","archives;images;newspapers;Sydney"
"b9a1c03118f24814b56efc41f106ebe7",2022,"Fractal in detail: What information is in a file format identification report?","A file format identification report, such as those generated by digital preservation tools, DROID, Siegfried, or FIDO, contain an incredible wealth of information. Used to scan discrete sets of files comprising a part of, or the entirety of a digital collection, these datasets can serve as entry points for further activities including appraisal, identification of future work efforts, and the facilitation of transfer of digital objects into preservation storage. The information contained in them is fractal in detail and there are numerous outputs that can be generated from that detail. This paper describes the purpose of a file format identification report and the extensive information that can be extracted from one. It summarizes a number of ways of transforming them into the inputs for other systems and describes a handful of the tools already doing so. The paper concludes that describing a format identification report is a pivotal artefact in the digital transfer process, and asks the reader to consider how they might leverage them and the benefits doing so might provide.","Spencer,Ross","Code4Lib","https://journal.code4lib.org/articles/16351","DROID;FIDO;Siegfried;preservation storage;format identification"
"b9e5c1ca02274902a633083fc603852d",2009,"Repurposing ProQuest Metadata for Batch Ingesting ETDs into an Institutional Repository","This article describes the workflow used by the University of Iowa Libraries to populate their institutional repository and their catalog with the data collected by ProQuest UMI Dissertation Publishing during the submission of students' theses and dissertations. Re-purposing the metadata from ProQuest allowed the University of Iowa Libraries to streamline the process for ingesting theses and dissertations into their institutional repository The article includes a discussion of the benefits and limitations of the workflow described.","Lee,Joanna;Averkamp,Shawn","Code4Lib","http://journal.code4lib.org/articles/1647","ProQuest;University of Iowa;ETD;institutional repository;workflow"
"b9f0b5fb8e3a487388ec8aba4041bfa7",2014,"Editorial Introduction: On Being on The Code4Lib Journal Editorial Committee","Behind the scenes of the The Code4Lib Journal...","McGrath,Kelley","Code4Lib","http://journal.code4lib.org/articles/10182","editorial"
"ba3ac4ba0651442882898e6c8ce6ad38",2009,"Extracting User Interaction Information from the Transaction Logs of a Faceted Navigation OPAC","This paper discusses the analysis of Apache web server logs from a faceted catalog interface (OPAC) at North Carolina State University. By grouping individual HTTP requests into user sessions and analyzing in that context, requests can be understood as particular user actions, with more specificity as to purpose and effect of an action. Client IP address and time are used as a sufficient proxy for determining user sessions from logs. Some initial exploratory findings of user behavior in the NCSU OPAC are provided, including that users make use of facets less than of text searching, and that some facet groups are used significantly more than others. Links are provided to the scripts used to make this session-based analysis, which could be modified for use with other facetted OPACs which use an Apache front-end.","Hemminger,Brad;Lown,Cory","Code4Lib","http://journal.code4lib.org/articles/1633","OPAC;North Carolina;log analysis;Apache"
"ba74f278b38e4403a94ee5ff2dd8921d",2018,"Machine Learning and the Library or: How I Learned to Stop Worrying and Love My Robot Overlords","Machine learning algorithms and technologies are becoming a regular part of daily life - including life in the libraries. Through this article, I hope to: * To introduce the reader to the basic terminology and concepts of machine learning * To make the reader consider the potential ethical and privacy issues that libraries will face as machine learning permeates society * To demonstrate hypothetical possibilities for applying machine learning to circulation and collections data using TensorFlow/Keras and open datasets Through these goals, it is my hope that this article will inspire a larger, ongoing conversation about the utility and dangers of machine learning in the library (and concurrently society as a whole). In addition, the tripartite division of the article is meant to make the material accessible to readers with different levels of technical proficiency. In approaching the first two goals, the discussion is focused on high level terms and concepts, and it includes specific public cases of machine learning (ab)use that are of broad interest. For the third goal, the discussion becomes more technical and is geared towards those interested in exploring practical machine learning applications in the library.","Charlie,Harper,","Code4Lib","https://journal.code4lib.org/articles/13671","machine learning;Tensor Flow;Keras"
"be4554ab447e4107a9ecc7c8d9969dd9",2015,"Training the Next Generation of Open Source Developers: A Case Study of OSU Libraries & Press’ Technology Training Program","The Emerging Technologies & Services department at Oregon State University Libraries & Press has implemented a training program for our technology student employees on how and why they should engage in Open Source community development. This article will outline what they've done to implement this program, discuss the benefits they've seen as a result of these changes, and will talk about what they viewed as necessary to build and promote a culture of engagement in open communities.","Weinraub Lajoie,Evviva;Terrell,Trey;Eaton,Mike","Code4Lib","http://journal.code4lib.org/articles/10350","OSU;Oregon;culture"
"bef17679bdd64bfbbe3e7c0345297e81",2012,"HTML5 Microdata and Schema.org","On June 2, 2011, Bing, Google, and Yahoo! announced the joint effort Schema.org. When the big search engines talk, Web site authors listen. This article is an introduction to Microdata and Schema.org. The first section describes what HTML5, Microdata and Schema.org are, and the problems they have been designed to solve. With this foundation in place section 2 provides a practical tutorial of how to use Microdata and Schema.org using a real life example from the cultural heritage sector. Along the way some tools for implementers will also be introduced. Issues with applying these technologies to cultural heritage materials will crop up along with opportunities to improve the situation.","Ronallo,Jason","Code4Lib","http://journal.code4lib.org/articles/6400","HTML5;Schema.org;microdata"
"bf5cc0add96f42d199c1eb58b67d6b0f",2015,"Manifold: a Custom Analytics Platform to Visualize Research Impact","The use of research impact metrics and analytics has become an integral component to many aspects of institutional assessment. Many platforms currently exist to provide such analytics, both proprietary and open source; however, the functionality of these systems may not always overlap to serve uniquely specific needs. In this paper, I describe a novel web-based platform, named Manifold, that I built to serve custom research impact assessment needs in the University of Minnesota Medical School. Built on a standard LAMP architecture, Manifold automatically pulls publication data for faculty from Scopus through APIs, calculates impact metrics through automated analytics, and dynamically generates report-like profiles that visualize those metrics. Work on this project has resulted in many lessons learned about challenges to sustainability and scalability in developing a system of such magnitude.","Braun,Steven","Code4Lib","http://journal.code4lib.org/articles/10948","API;Manifold;LAMP;Scopus;impact metrics;automatic analytics"
"bff3f8c5f285429db6ba382651258103",2010,"Hacking Summon","When the Oregon State University Libraries selected Serials Solutions' Summon as its discovery tool, the implementation team realized that they had an opportunity to implement a set of ""hacks"" that that would improve the overall user experience. This article will explore the space between Summon's out-of-the-box user interface and full developer API, providing practical advice on tweaking configuration information and catalog exports to take full advantage of Summon's indexing and faceting features. The article then describes the creation of OSUL's home-grown open source availability service which replaced and enhanced the availability information that Summon would normally pull directly from the catalog.","Klein,Michael","Code4Lib","http://journal.code4lib.org/articles/3655","API;Oregon;Summon;OSUL"
"bffe41a6b9c044d484cc1efd2dbffd7f",2009,"The Wise Use of Statistics in a Library-Oriented Environment","As with most businesses, libraries use statistics to justify expenses, to monitor the library’s expansion and to predict prospective developments. This article describes SQL and shell techniques for data retrieval as well as further processing of the data using the open source statistical environment R. The article emphasizes some of the pitfalls and reasoning errors librarians could easily slip into. Having an academic background on statistics, the author is appointed to projects and tasks which need mathematical and statistical methods to be successfully accomplished.","Weyland,Mathias","Code4Lib","http://journal.code4lib.org/articles/1275","SQL;statistics;expenses"
"c05763371c7d494cb02688d21aed1ee7",2022,"Editorial:On FOSS in Libraries","Some thoughts on the state of free and open source software in libraries.","Darby,Andrew","Code4Lib","https://journal.code4lib.org/articles/16820","editorial"
"c0e36e19f35b48e9999d1f87640bb979",2019,"Content Dissemination from Small-scale Museum and Archival Collections: Community Reusable Semantic Metadata Content Models for Digital Humanities","This paper highlights the challenges incontent dissemination in Cultural Heritage (CH) institutions by digital humanities scholars and small Museums and Archival Collections.It showcases a solution based on Community Reusable Semantic Metadata Content Models (RM’s) available for download from our community website. Installing the RM's will extend the functionality of the state of the art Content Management Framework (CMF) towards numismatic collections. Furthermore, it encapsulates metadata using the Resource Description Framework in Attributes (RDFa), and the Schema.org vocabulary. Establishing a community around RM’s will help the development, upgrading and sharing of RM's models and packages for the benefit of the Cultural Heritage community. A distributed model for Community Reusable Semantic Metadata Content Models will allow the community to grow and improve, serving the needs and enabling the infrastructure to scale for the next generation of humanities scholars.","Avgousti,Avgoustinos;Papaioannou,Georgios;Ribeiro Gouveia,Feliz","Code4Lib","https://journal.code4lib.org/articles/14054","semantic metadata;RDFa;Schema.org;cultural heritage;humanities scholars"
"c0ff37d6bdca414f8e956ed88dda9a39",2020,"Update OCLC Holdings Without Paying Additional Fees: A Patchwork Approach","Accurate OCLC holdings are vital for interlibrary loan transactions. However, over time weeding projects, replacing lost or damaged materials, and human error can leave a library with a catalog that is no longer reflected through OCLC. While OCLC offers reclamation services to bring poorly maintained collections up-to-date, the associated fee may be cost prohibitive for libraries with limited budgets. This article will describe the process used at Austin Peay State University to identify, isolate, and update holdings using OCLC Collection Manager queries, MarcEdit, Excel, and Python. Some portions of this process are completed using basic coding; however, troubleshooting techniques will be included for those with limited previous experience.","Wood,Nicole;Shumate,Scott","Code4Lib","https://journal.code4lib.org/articles/15385","OCLC;MarcEdit;Austin Peay;Excel;Python"
"c18eaea3f51a4a51b9d4b8eded662f77",2013,"Actions Speak Louder than Words: Analyzing large-scale query logs to improve the research experience","Analyzing anonymized query and click-through logs leads to a better understanding of user behaviors and intentions, and provides opportunities to create an improved search experience. As a large-scale provider of SaaS services that returns search results against a single unified index, Serials Solutions is uniquely positioned to learn from the dataset of queries issued to its Summon® service by millions of users at hundreds of libraries around the world. In this paper, we describe the Relevance Metrics Framework that we use to analyze our query logs and provide examples of insights we have gained during development and implementation. We also highlight the ways our analysis is inspiring changes to the Summon® service to improve the academic research experience.","Diamond,Ted;Price,Susan;Chandrasekar,Raman","Code4Lib","http://journal.code4lib.org/articles/8693","Summon;SaaS;relevance metrics;log analysis"
"c1e9aad23c134761a8bcdf1dc35d0934",2017,"Usability Analysis of the Big Ten Academic Alliance Geoportal: Findings and Recommendations for Improvement of the User Experience","The Big Ten Academic Alliance (BTAA) Geospatial Data Project is a collaboration between twelve member institutions of the consortium and works towards providing discoverability and access to geospatial data, scanned maps, and web mapping services. Usability tests and heuristic evaluations were chosen as methods of evaluation, as they have had a long standing in measuring and managing website engagement and are essential in the process of iterative design. The BTAA project hopes to give back to the community by publishing the results of our usability findings with the hope that it will benefit other portals built with GeoBlacklight.","Blake,Mara;Majewicz,Karen;Tickner,Amanda;Lam,Jason","Code4Lib","http://journal.code4lib.org/articles/12932","big ten academic alliance;geospatial data;GeoBlacklight"
"c22201e3f5c64257a2be2174aa9ea323",2008,"Building an Archival Collections Portal","Columbia University Libraries has developed the Archival Collections Portal, a unified search system helping users discover archival resources in a streamlined way. We combined the power of Lucene and Solr to search XML, parse JSON objects, create EAD-compliant documents, and deliver results in an easy-to-use interface. By reusing MARC records and employing new search engine features and techniques, we are able to bring important and hard-to-find collections to researchers and archivists. The canonical home page of the Portal is http://www.columbia.edu/library/archival.","Marquis,Stuart;DiPasquale,Joanna;Catapano,Terry","Code4Lib","http://journal.code4lib.org/articles/77","Columbia University;archival portal;XML;JSON;EAD;MARC"
"c2b8dc0ab47448db9139ab9914cfd1d1",2008,"‡biblios: An Open Source Cataloging Editor","‡biblios is an open source cataloging editor designed to allow libraries to perform copy and original cataloging in a web based environment. ‡biblios allows users to search for, edit, and save bibliographic records in the MARC21/MARCXML formats. It also allows users to send records directly to integrated library systems such as the Koha ILS. Where most MARC editors are part of an integrated library system (and therefore require logging in), ‡biblios allows users to catalog with an open source standalone system available anywhere via a web browser. Unlike other cataloging editors, it offers an attractive user interface for searching, saving and editing cataloging records. This article describes the system architecture and design of ‡biblios.","Catalfo,Chris","Code4Lib","http://journal.code4lib.org/articles/657","biblios;liblime;marc editor;metadata editor;open source;MARC21;architecture"
"c377bad477ac4004b5264402c9d2ff80",2012,"Ref2RIS: Importing Word-Processed Bibliographies into Bibliographic Management Software","Many who would benefit the most from timesaving bibliographic managers hesitate to adopt the technology due to the difficulties in importing legacy bibliographies developed over years. Existing shortcuts rely on manual reformatting or on re-searching online databases for the records - often almost as laborious as retyping the references. Ref2RIS was developed to automate the task of converting a bibliography in specific citation styles from common word processing document formats into the widely used RIS format. It uses the Unix stream editor sed and the conversion options of Apple's textutil. It can be invoked as a series of simple shell commands on any Linux terminal, or more simply as a drag-and-drop Applescript application on MacOS 10.4 or higher.","Fitchett,Deborah","Code4Lib","http://journal.code4lib.org/articles/6286","Ref2RIS;Unix;bibliographies;RIS"
"c41e9cacf4e84ccebcf992df74fe654f",2009,"Editorial Introduction - Issue 6","The intelligent use of technology in libraries continues to be one of our most crucial challenges. For those of us who became librarians because we loved to explore the book stacks, we are now finding new ways to explore both old and new content in digital form. With issue 6 of the Code4Lib Journal we hope you will find new ways to explore, experiment, and bring to your library users what they want and need.","Schwartz,Christine","Code4Lib","http://journal.code4lib.org/articles/1376","editorial"
"c44cf768957044c1a7f6f43d2489eb63",2018,"OneButton: A Link Resolving Application to Guide Users to Optimal Fulfillment Options","Like many consortia, institutional members of the Private Academic Library Network of Indiana (PALNI) provide multiple fulfillment options to obtain requested items for their users. Users can place on shelf holds on items, or they can request material that isn’t held by their institution through a group circulation resource sharing network (dubbed PALShare) or through traditional InterLibrary Loan (ILL) (through WorldShare ILL or ILLiad). All of these options can be confusing to users who may not understand the best or fastest way to get access to needed materials. A PHP application, OneButton, was developed that replaces multiple fulfillment buttons in institutional discovery interfaces with a single OpenURL link. OneButton looks up holdings and availability at a user’s home institution and across the consortium and routes the user to the optimal fulfillment option for them. If an item is held by and available at their institution, the user can be shown a stack map to help guide them to the item on the shelf; if an item is held by and available at the consortium, the user is routed to a group circulation request form; otherwise, the user is routed to an ILL request form. All routing and processing are handled by the OneButton application – the user doesn’t need to think about what the ‘best’ fulfillment option is. This article will discuss the experiences of one institution using OneButton in production since fall 2017, analytics data gathered, and how other institutions can adopt the application (freely available on GitHub: https://github.com/PALNI/onebutton).","Magnuson,Lauren;Stutzman,Karl;Peters,Roger;Brubaker,Noah","Code4Lib","https://journal.code4lib.org/articles/13951","OneButton;PALShare;PHP;OpenURL;ILL"
"c467347f8594499d805e356221997d8e",2015,"Barriers to Initiation of Open Source Software Projects in Libraries","Libraries share a number of core values with the Open Source Software (OSS) movement, suggesting there should be a natural tendency toward library participation in OSS projects. However Dale Askey’s 2008 Code4Lib column entitled “We Love Open Source Software. No, You Can’t Have Our Code,” claims that while libraries are strong proponents of OSS, they are unlikely to actually contribute to OSS projects. He identifies, but does not empirically substantiate, six barriers that he believes contribute to this apparent inconsistency. In this study we empirically investigate not only Askey’s central claim but also the six barriers he proposes. In contrast to Askey’s assertion, we find that initiation of and contribution to OSS projects are, in fact, common practices in libraries. However, we also find that these practices are far from ubiquitous; as Askey suggests, many libraries do have opportunities to initiate OSS projects, but choose not to do so. Further, we find support for only four of Askey’s six OSS barriers. Thus, our results confirm many, but not all, of Askey’s assertions.","Thacker,Curtis;Knutson,Charles","Code4Lib","http://journal.code4lib.org/articles/10665","OSS"
"c54db329b0d844e7a1c736d7ec2225f3",2021,"Using Low Code to Automate Public Service Workflows: Three Cases","Public service librarians without coding experience or technical education may not always be aware of or consider automation to be an option to streamline their regular work tasks, but the new prevalence of enterprise-level low code solutions allows novices to take advantage of technology to make their work more efficient and effective. Low code applications apply a graphic user interface on top of a coding platform to make it easy for novices to leverage automation at work. This paper presents three cases of using low code solutions for automating public service problems using the prevalent Microsoft Power Automate application, available in many library workplaces that use the Microsoft Office ecosystem. From simplifying the communication and scheduling process for instruction classes to connecting our student workers’ hourly floor counts to our administrators’ dashboard of building occupancy, we’ve leveraged simple low code automation in a scalable and replicable manner. Pseudo-code examples provided.","Morganti,Dianna;Williams,Jess","Code4Lib","https://journal.code4lib.org/articles/16096","automation;low code;cases"
"c554db31f9e94cb5908b32fe505453fd",2010,"Using Amazon S3 in Digital Preservation in a mid sized academic library: A case study of CCSU ERIS digital archive system","With the increasing numbers of born digital and digitized objects in academic libraries from sources such as digital collections and institutional repositories many academic libraries need to seriously consider implementing some form of digital preservation system. In 2009 the Central Connecticut State University Library decided to use Amazon S3 for digital preservation storage despite some drawbacks. The library has developed a system, ERIS Digital Archive, to manage all digital preservation processes and to make the system as compliant with the OAIS model and ""Trustworthy Digital Repositories"" as possible.","Iglesias,Edward;Meesangnil,Wittawat","Code4Lib","http://journal.code4lib.org/articles/4468","Amazon S3;digital preservation;case study;CCSU ERIS;digital archive;Connecticut;OAIS"
"c58d6ac65c9642fe97df9995f91e9122",2014,"Enhancing Descriptive Metadata Records with Freely-Available APIs","This article describes how the University of North Texas Libraries' Digital Projects Unit used simple, freely-available APIs to add place names to metadata records for over 8,000 maps in two digital collections. These textual place names enable users to easily find maps by place name and to find other maps that feature the same place, thus increasing the accessibility and usage of the collections. This project demonstrates how targeted large-scale, automated metadata enhancement can have a significant impact with a relatively small commitment of time and staff resources.","Phillips,Mark;Tarver,Hannah","Code4Lib","http://journal.code4lib.org/articles/9415","API;North Texas;metadata records;metadata enhancement"
"c6152d2d28bb4f8d8361fb6a030f13ca",2018,"EnviroPi: Taking a DIY Internet-of-Things approach to an environmental monitoring system","Monitoring environmental conditions in cultural heritage organizations is vitally important to ensure effective preservation of collections.Environmental monitoring systems may range from stand-alone data-loggers to more complex networked systems and can collect a variety of sensor data such as temperature, humidity, light, or air quality measures.However, such commercial systems are often costly and limited in customizability and extensibility.This article describes a do-it-yourself network of Bluetooth Low Energy-based wireless sensors, which seeks to manage earlier-identified trade-offs in cost, required technical skill, and maintainability, based on the Raspberry Pi™ single-board computer and a series of microcontroller boards.This builds on the author’s prior work exploring the construction of a low-cost Raspberry-Pi™-based datalogger, iterating upon reviewer and practitioners’ feedback to implement and reflect upon suggested improvements.","Maceli,Monica","Code4Lib","https://journal.code4lib.org/articles/13943","Raspberry Pi;EnviroPi;DiY;IoT;monitoring;sensor data;Buetooth"
"c6bfa7ad00e64a67b24c97910dbbd41d",2023,"The Brooklyn Health Map: Reflections on a Health Data Dashboard for Brooklyn, NY","Recent years have put a spotlight on the importance of searchers of all kinds being able to quickly and easily find relevant, timely, and useful health information. This article provides a general overview of the process used when creating the Brooklyn Health Map, an interactive Brooklyn-based health data dashboard that visualizes community health information at the census tract, zip code, and neighborhood levels. Built using HTML, CSS, Bootstrap, and JavaScript, the Brooklyn Health Map presents information in the form of interactive web maps, customizable graphs, and local level data summaries. This article also highlights the tools used to simplify the creation of various dynamic features of the dashboard.  by Sheena Philogene","Philogene,Sheena","Code4Lib","https://journal.code4lib.org/articles/17158","Brooklyn;dashboard;Boostrap;JavaScript"
"c7ae02a5d80040f6a5df761efa36153d",2009,"How Hard Can It Be? : Developing in Open Source","In 2000 a small public library system in New Zealand developed and released Koha, the world’s first open source library management system. This is the story of how that came to pass and why, and of the lessons learnt in their first foray into developing in open source.","Blake,Rosalie;Cormack,Chris;Ransom,Joann","Code4Lib","http://journal.code4lib.org/articles/1638","Kohs;open source"
"c7d28e2f8c794a119af0bec222efe483",2018,"Automated Playlist Continuation with Apache PredictionIO","The Minrva project team, a software development research group based at the University of Illinois Library, developed a data-focused recommender system to participate in the creative track of the 2018 ACM RecSys Challenge, which focused on music recommendation. We describe here the large-scale data processing the Minrva team researched and developed for foundational reconciliation of the Million Playlist Dataset using external authority data on the web (e.g. VIAF, WikiData). The secondary focus of the research was evaluating and adapting the processing tools that support data reconciliation. This paper reports on the playlist enrichment process, indexing, and subsequent recommendation model developed for the music recommendation challenge.","Hahn,Jim","Code4Lib","https://journal.code4lib.org/articles/13850","Minrva;project;RecSys;authority data;plylist enrichment;indexing;music;recommendation"
"c7f9b0bed93743d1a217615261a4fe19",2020,"Editorial: For Pandemic Times Such as This","A pandemic changes the world and changes libraries.","Murray,Peter","Code4Lib","https://journal.code4lib.org/articles/15475","editorial"
"c8639b3802ff4fe280a1b064bfe84838",2023,"Editorial: Forget the AI, We Have Live Editors","Welcoming new editors to the Code4Lib Journal","Amato,Sara","Code4Lib","https://journal.code4lib.org/articles/17352","editorial"
"c87bc9c0be764f618f272e1175978b7f",2007,"Communicat: The Next Generation Catalog That Almost Was…","Georgia Tech Libraries broke ground and made considerable headway on “the Communicat”: a content management system designed to improve access to the library’s collections (including records from the catalog, institutional repository and other sources) as well as allow individuals and groups to create their own localized libraries (similar to a social bookmarking service), that in turn helps build and grow the main collection.","Singer,Ross","Code4Lib","http://journal.code4lib.org/articles/24","Georgia Tech;catalog"
"c883f6a44ea94a83ac45f1696b486ec0",2016,"Metadata Analytics, Visualization, and Optimization: Experiments in statistical analysis of the Digital Public Library of America (DPLA)","This paper presents the concepts of metadata assessment and “quantification” and describes preliminary research results applying these concepts to metadata from the Digital Public Library of America (DPLA). The introductory sections provide a technical outline of data pre-processing, and propose visualization techniques that can help us understand metadata characteristics in a given context. Example visualizations are shown and discussed, leading up to the use of ""metadata fingerprints"" -- D3 Star Plots -- to summarize metadata characteristics across multiple fields for arbitrary groupings of resources. Fingerprints are shown comparing metadata characterisics for different DPLA ""Hubs"" and also for used versus not used resources based on Google Analytics ""pageview"" counts.The closing sections introduce the concept of metadata optimization and explore the use of machine learning techniques to optimize metadata in the context of large-scale metadata aggregators like DPLA. Various statistical models are used to predict whether a particular DPLA item is used based only on its metadata. The article concludes with a discussion of the broad potential for machine learning and data science in libraries, academic institutions, and cultural heritage.","A. Harper,Corey","Code4Lib","http://journal.code4lib.org/articles/11752","DPLA;metadata assessment;statistical analysis"
"c8b2281d8f9945d88f9ef8b594726258",2017,"Extending Omeka for a Large-Scale Digital Project","In September 2016, the department of Special Collections and Archives, Kent State University Libraries, received a Digital Dissemination grant from the National Historical Publications and Records Commission (NHPRC) to digitize roughly 72,500 pages from the May 4 collection, which documents the May 1970 shootings of thirteen students by Ohio National Guardsmen at Kent State University. This article will highlight the project team’s efforts to adapt the Omeka instance with modifications to the interface and ingestion processes to assist the efforts of presenting unique archival collections online, including an automated method to create folder level links on the relevant finding aids upon ingestion; implementing open source Tesseract to provide OCR to uploaded files; automated PDF creation from the raw image files using Ghostscript; and integrating Mirador to present a folder level display to reflect archival organization as it occurs in the physical collections. These adaptations, which have been shared via GitHub, will be of interest to other institutions looking to present archival material in Omeka.","Antell,Haley;Corall,Joe;Dressler,Virginia;Gilgenbach,Cara","Code4Lib","http://journal.code4lib.org/articles/12529","Omeka;Tesseract;OCR;Ghostscript;Mirador;GitHub"
"c9311ae1f6c24243abe45d95a2bd4cfc",2020,"Git and GitLab in Library Website Change Management Workflows","Library websites can benefit from a separate development environment and a robust change management workflow, especially when there are multiple authors. This article details how the Oakland University William Beaumont School of Medicine Library use Git and GitLab in a change management workflow with a serverless development environment for their website development team. Git tracks changes to the code, allowing changes to be made and tested in a separate branch before being merged back into the website. GitLab adds features such as issue tracking and discussion threads to Git to facilitate communication and planning. Adoption of these tools and this workflow have dramatically improved the organization and efficiency of the OUWB Medical Library web development team, and it is the hope of the authors that by sharing our experience with them others may benefit as well.","Engwall,Keith;Roe,Mitchell","Code4Lib","https://journal.code4lib.org/articles/15250","GitLab;OUWB;workflows;web development"
"c970308743274fa6a167cbcb7d7240a7",2008,"Reviving Digital Projects","What do you do when you are in charge of assessing and reviving an abandoned digital project you had no part in creating or implementing? This article will talk about the unique challenges and issues involved in such a project, drawing from a specific example at the University of Michigan Library. We contended with unfamiliar software, limited technical documentation, proprietary file formats and platform migration, and will discuss how we approached each of these specific technical issues. After reviving our project and reflecting on our process, we put together a list of guidelines that we feel will help assist others who may find themselves in similar situations.","Scholtz,Nicole;Green,Jen;Doty,Jennifer;Dietrich,Dianne","Code4Lib","http://journal.code4lib.org/articles/685","digital project;Michigan;guideline;migration"
"ca21d94fa27949ea93e82b2983673295",2015,"How to Hack it as a Working Parent","The problems faced by working parents in technical fields in libraries are not unique or particularly unusual. However, the cross-section of work-life balance and gender disparity problems found in academia and technology can be particularly troublesome, especially for mothers and single parents. Attracting and retaining diverse talent in work environments that are highly structured or with high expectations of unstated off-the-clock work may be impossible long term. (Indeed, it is not only parents that experience these work-life balance problems but anyone with caregiver responsibilities such as elder or disabled care.) Those who have the energy and time to devote to technical projects for work and fun in their off-work hours tend to get ahead. Those tied up with other responsibilities or who enjoy non-technical hobbies do not get the same respect or opportunities for advancement. Such problems mirror the experiences of women on the tenure track in academia, particularly women working in libraries, and they provide a useful corollary for this discussion. We present some practical solutions for those in technical positions in libraries. Such solutions involve strategic use of technical tools, and lightweight project management applications. Technical workarounds are not the only answer; real and lasting change will involve a change in individual priorities and departmental culture such as sophisticated and ruthless time management, reviewing workloads, cross-training personnel, hiring contract replacements, and creative divisions of labor.Ultimately, a flexible environment that reflects the needs of parents will help create a better workplace culture for everyone, kids or no kids.","Bedoya,Jaclyn;Heller,Margaret;Salazar,Christina;Yan,May","Code4Lib","http://journal.code4lib.org/articles/10409","parents;technocal positions"
"ca2688ff9fc84c179844e56dfb798697",2017,"The Devil’s Shoehorn: A case study of EAD to ArchivesSpace migration at a large university","A band of archivists and IT professionals at Harvard took on a project to convert nearly two million descriptions of archival collection components from marked-up text into the ArchivesSpace archival metadata management system.  Starting in the mid-1990s, Harvard was an alpha implementer of EAD, an SGML (later XML) text markup language for electronic inventories, indexes, and finding aids that archivists use to wend their way through the sometimes quirky filing systems that bureaucracies establish for their records or the utter chaos in which some individuals keep their personal archives.  These pathfinder documents, designed to cope with messy reality, can themselves be difficult to classify.  Portions of them are rigorously structured, while other parts are narrative.  Early documents predate the establishment of the standard; many feature idiosyncratic encoding that had been through several machine conversions, while others were freshly encoded and fairly consistent.  In this paper, we will cover the practical and technical challenges involved in preparing a large (900MiB) corpus of XML for ingest into an open-source archival information system (ArchivesSpace). This case study will give an overview of the project, discuss problem discovery and problem solving, and address the technical challenges, analysis, solutions, and decisions and provide information on the tools produced and lessons learned.  The authors of this piece are Kate Bowers, Collections Services Archivist for Metadata, Systems, and Standards at the Harvard University Archive, and Dave Mayo, a Digital Library Software Engineer for Harvard’s Library and Technology Services.  Kate was heavily involved in both metadata analysis and later problem solving, while Dave was the sole full-time developer assigned to the migration project.","Mayo,Dave;Bowers,Kate","Code4Lib","http://journal.code4lib.org/articles/12239","archivists;Harvard;project;ArchivesSpace;metadata conversion;EAD;SGML;case study;migration"
"ca559c60ff33453a90e6b7b2a08dec80",2016,"Creation of a Library Tour Application for Mobile Equipment using iBeacon Technology","We describe the design, development, and deployment of a library tour application utilizing Bluetooth Low Energy devices know as iBeacons. The tour application will serve as library orientation for incoming students. The students visit stations in the library with mobile equipment running a special tour app. When the app detects a beacon nearby, it automatically plays a video that describes the current location. After the tour, students are assessed according to the defined learning objectives. Special attention is given to issues encountered during development, deployment, content creation, and testing of this application that depend on functioning hardware, and the necessity of appointing a project manager to limit scope, define priorities, and create an actionable plan for the experiment.","Bradley,Jonathan;Henshaw,Neal;McVoy,Liz;French,Amanda;Gilbertson,Keith;Becksford,Lisa;Givens,Elisabeth","Code4Lib","http://journal.code4lib.org/articles/11338","library tour;iBeacons;Bluetooth"
"ca57f04055b646d283bfa9503be29ddf",2015,"Query Translation in Europeana","Europeana – a database containing European digital cultural heritage objects – recently introduced query translation in order to aid users in searching the collections regardless of language. The user enters query terms, and the portal searches for those terms in multiple languages. This article discusses the technical details of query translation with the aim of assisting similar projects to implement similar features.","Király,Péter","Code4Lib","http://journal.code4lib.org/articles/10285","Europeana;query translaton"
"cba1d96b94e9438eb17567e849393837",2019,"Natural Language Processing in the Humanities: A Case Study in Automated Metadata Enhancement","The Black Book Interactive Project at the University of Kansas (KU) is developing an expanded corpus of novels by African American authors, with an emphasis on lesser known writers and a goal of expanding research in this field. Using a custom metadata schema with an emphasis on race-related elements, each novel is analyzed for a variety of elements such as literary style, targeted content analysis, historical context, and other areas. Librarians at KU have worked to develop a variety of computational text analysis processes designed to assist with specific aspects of this metadata collection, including text mining and natural language processing, automated subject extraction based on word sense disambiguation, harvesting data from Wikidata, and other actions.","Wolfe,Erin","Code4Lib","https://journal.code4lib.org/articles/14834","automated metadata enhancement;case study;Kansas;metadata schema;automated subject creaion;word sense disambiguation;Wikidata"
"cc30d9ae67e84da098d9d6418dea6115",2017,"Recommendations for the application of Schema.org to aggregated Cultural Heritage metadata to increase relevance and visibility to search engines: the case of Europeana","Europeana provides access to more than 54 million cultural heritage objects through its portal Europeana Collections. It is crucial for Europeana to be recognized by search engines as a trusted authoritative repository of cultural heritage objects.
Indeed, even though its portal is the main entry point, most Europeana users come to it via search engines. Europeana Collections is fuelled by metadata describing cultural objects, represented in the Europeana Data Model (EDM). This paper presents the research and consequent recommendations for publishing Europeana metadata using the Schema.org vocabulary and best practices. Schema.org html embedded metadata to be consumed by search engines to power rich services (such as Google Knowledge Graph). Schema.org is an open and widely adopted initiative (used by over 12 million domains) backed by Google, Bing, Yahoo!, and Yandex, for sharing metadata across the web It underpins the emergence of new web techniques, such as so called Semantic SEO. Our research addressed the representation of the embedded metadata as part of the Europeana HTML pages and sitemaps so that the re-use of this data can be optimized. The practical objective of our work is to produce a Schema.org representation of Europeana resources described in EDM, being the richest as possible and tailored to Europeana's realities and user needs as well the search engines and their users.","Wallis,Richard;Isaac,Antoine;Charles,Valentine;Manguinhas,Hugo","Code4Lib","http://journal.code4lib.org/articles/12330","Schema.org;EDM;Europeana;embded metadata;search;sitemaps"
"cd161d1e248b483a9fcc5bb9dc9a420e",2012,"GLIMIR: Manifestation and Content Clustering within WorldCat","The GLIMIR project at OCLC clusters and assigns an identifier to WorldCat records representing the same manifestation. These include parallel records in different languages (e.g., a record with English descriptive notes and subject headings and one for the same book with French equivalents). It also clusters records that probably represent the same manifestation, but which could not be safely merged by OCLC's Duplicate Detection and Resolution (DDR) program for various reasons. As the project progressed, it became clear that it would also be useful to create content-based clusters for groups of manifestations that are generally equivalent from the end user perspective (e.g., the original print text with its microform, ebook and reprint versions, but not new editions). Lessons from the GLIMIR project have improved OCLC's duplicate detection program through the introduction of new matching techniques. GLIMIR has also had unexpected benefits for OCLC's FRBR algorithm by providing new methods for identifying outliers thus enabling more records to be included in the correct work cluster.","Gatenby,Janifer;O. Greene,Richard;Michael Oskins,W.;Thornburg,Gail","Code4Lib","http://journal.code4lib.org/articles/6812","GLIMIR;OCLC;clusters;FRBR;duplicate detection;manifestation"
"cd45cf354dc74308b96aa83d103bf0d4",2018,"Preparing Existing Metadata for Repository Batch Import: A Recipe for a Fickle Food","In 2016, the University of Waterloo began offering a mediated copyright review and deposit service to support the growth of our institutional repository UWSpace. This resulted in the need to batch import large lists of published works into the institutional repository quickly and accurately. A range of methods have been proposed for harvesting publications metadata en masse, but many technological solutions can easily become detached from a workflow that is both reproducible for support staff and applicable to a range of situations. Many repositories offer the capacity for batch upload via CSV, so our method provides a template Python script that leverages the Habanero library for populating CSV files with existing metadata retrieved from the CrossRef API. In our case, we have combined this with useful metadata contained in a TSV file downloaded from Web of Science in order to enrich our metadata as well. The appeal of this ‘low-maintenance’ method is that it provides more robust options for gathering metadata semi-automatically, and only requires the user’s ability to access Web of Science and the Python program, while still remaining flexible enough for local customizations.","Roy,William;Gray,Chris","Code4Lib","https://journal.code4lib.org/articles/13895","metadata;Waterloo;UWSpace;batch import;CSV;CrossRef API;metadata enrichment;Web of Science;Python"
"cd7e1d886f7f402cbc988ae260d0186c",2015,"Open Journal Systems and Dataverse Integration– Helping Journals to Upgrade Data Publication for Reusable Research","This article describes the novel open source tools for open data publication in open access journal workflows. This comprises a plugin for Open Journal Systems that supports a data submission, citation, review, and publication workflow; and an extension to the Dataverse system that provides a standard deposit API. We describe the function and design of these tools, provide examples of their use, and summarize their initial reception. We conclude by discussing future plans and potential impact.","Altman,Micah;Castro,Eleni;Crosas,Mercè;Durbin,Philip;Garnett,Alex;Whitney,Jen","Code4Lib","http://journal.code4lib.org/articles/10989","OJS;API;Dataverse;integration;impact"
"cde5bc1cee3b4d9a81758ca5f96356a5",2017,"An Interactive Map for Showcasing Repository Impacts","Digital repository managers rely on usage metrics such as the number of downloads to demonstrate research visibility and impacts of the repositories. Increasingly, they find that current tools such as spreadsheets and charts are ineffective for revealing important elements of usage, including reader locations, and for attracting the targeted audiences. This article describes the design and development of a readership map that provides an interactive, near-real-time visualization of actual visits to an institutional repository using data from Google Analytics. The readership map exhibits the global impacts of a repository by displaying the city of every view or download together with the title of the scholarship being read and a hyperlink to its page in the repository. We will discuss project motivation and development issues such as authentication with Google API, metadata integration, performance tuning, and data privacy.","Zhang,Hui;Lopez,Camden","Code4Lib","http://journal.code4lib.org/articles/12349","API;usage metrics;readership map;visualization;Google Analytics;metadata integration;data privacy"
"ce122f9470714b8e8e3f3c59ad0aeb79",2015,"Connecting Historical and Digital Frontiers: Enhancing Access to the Latah County Oral History Collection Utilizing OHMS (Oral History Metadata Synchronizer) and Isotope","The University of Idaho Library received a donation of oral histories in 1987 that were conducted and collected by a local county historical society in the 1970s. The audio cassettes and transcriptions were digitized in 2013 and 2014, producing one of the largest digital collections of oral histories - over 300 interviews and over 569 hours - in the Pacific Northwest. To provide enhanced access to the collection, the Digital Initiatives Department employed an open-source plug-in called the Oral History Metadata Synchronizer (OHMS) - an XML and PHP driven system that was created at the Louie B. Nunn Center for Oral History at the University of Kentucky Libraries - to deliver the audio MP3 files together with their  indexes and transcripts. OHMS synchronizes the transcribed text with timestamps in the audio and provides a viewer that connects search results of a transcript to the corresponding moment in the audio file. This article will discuss how we created the infrastructure by importing existing metadata, customized the interface and visual presentation by creating additional levels of access using complex XML files, enhanced descriptions using the Getty Art and Architecture Thesaurus for keywords and subjects, and tagged locations discussed in the interviews that were later connected to Google Maps via latitude and longitude coordinates. We will also discuss the implementation of and philosophy behind our use of the layout library Isotope as the primary point of access to the collection. The Latah County Oral History Collection is one of the first successful digital collections created using the OHMS system outside of the University of Kentucky.","Becker,Devin;Passehl-Stoddart,Erin","Code4Lib","http://journal.code4lib.org/articles/10643","Idaho;oral histories;Oral Histories Metadata Synchronizer;XML;PHP;MP3;transcripts;AAT;Kentucky"
"cecee58d9c7f43c1bfd6971146f2e57c",2013,"Developing a Digital Video Library with the YouTube Data API","MSU Library has created a digital video library using the YouTube APIto power our local library channel. It is a complete search and browse application with itemlevel views, microdata, a caching and optimization routine, and a file backup routine. Thearticle will discuss applying the YouTube API as a database application layer: workflowefficiencies, metadata procedures and local backup and optimization procedures. Code samplesin PHP, .htaccess examples, and shell commands used in developing the application and routineswill be explained at length. And finally, a complete prototype application will be released ongithub for other libraries to get started using the lessons learned. A live version of theapplication is here: http://www.lib.montana.edu/channel/. The real benefit of this method is the lowoverhead for smaller shops and the ability to scale production and distribution of digitalvideo.","Clark,Jason","Code4Lib","http://journal.code4lib.org/articles/7847","YouTube;API;MSU;video library;microdata;prototype"
"d1f4ec0a722148febdc410e805293241",2008,"Distributed Version Control and Library Metadata","Distributed version control systems (DVCSs) are effective tools for managing source code and other artifacts produced by software projects with multiple contributors.This article describes DVCSs and compares them with traditional centralized version control systems, then describes extending the DVCS model to improve the exchange of library metadata.","M. Charlton,Galen","Code4Lib","http://journal.code4lib.org/articles/86","version control;source code management;version control;metadata"
"d39b1f985033423aaa524950e728f611",2016,"How We Went from Worst Practices to Good Practices, and Became Happier in the Process","Our application team was struggling. We had good people and the desire to create good software, but the library as an organization did not yet have experience with software development processes. Work halted. Team members felt unfulfilled. The once moderately competent developer felt frustrated, ashamed, helpless, and incompetent.Then, miraculously, a director with experience in software project management and an experienced and talented systems administrator were hired and began to work with the team.People in the group developed a sense of teamwork that they had not experienced in their entire time at the library. Now we are happy, excited, and energetic.We hope that you will appreciate our “feel-good” testimony of how excellent people and appropriate processes transformed an unhealthy work environment into a fit and happy team.","French,Amanda;Kayiwa,Francis;Lawrence,Anne;Gilbertson,Keith;Lohrey,Melissa","Code4Lib","http://journal.code4lib.org/articles/11398","teamwork;application team;software development;management"
"d41764b5cbc34af4ae00970bdfd7dc57",2013,"Library Widget for Moodle","Any course within a course management system is generally considered the intellectual space of the professor teaching it. Research tools and guides, such as search boxes for discovery services or links to course-specific and subject-specific guides, are created and maintained by librarians. In trying to get our tools and services closer to where students spend their time devoted to coursework, Oakland University libraries have developed a library widget – a self-serve code generator that allows professors to select what tools and services they want to bring into their course space. This approach has proven to be flexible, because it does not depend on a library presence within the course management system. It also offers persistent presence within courses since professors can archive courses, including the library widget, at the end of a semester and restore them in the system in future semesters. We are using the library widget as a pilot to inform decisions on future full integration of such functionality into Moodle.","Hristova,Mariela","Code4Lib","http://journal.code4lib.org/articles/7922","Moodle;Oakland;widget"
"d4c8cc0b4f9341d9931d2b9a8b835848",2023,"To Everything There Is a Session: A Time to Listen, a Time to Read Multi-session CDs","When the cost of CD burners dropped precipitously in the late 1990s, consumers had access to the CD-R, a format with far greater storage capacity than floppy disks. Multiple session standards allowed users the flexibility to add subsequent content to an already-burned CD-R, which made them an attractive option for personal backups. In a digital preservation context, CDs with multiple sessions can pose significant challenges to workflows and can lead to data errantly not being acquired or reviewed if users are using a workflow designed for single-session, single-track CDs.In workflows that include CDs as software installation or transmission media, extra-session behavior can have an impact on software supply chain review. This article provides an overview of the structure of a multi-session CD and outlines tool behavior of disk images generated from multi-session CDs. To support testing in specific contexts, we provide a guide to creating a multi-session CD that can be used when developing workflows. Finally, we provide techniques for extracting content from physical media as well as existing disk images generated from multi-session CDs.","Dietrich and Alex Nelson,Dianne","Code4Lib","https://journal.code4lib.org/articles/17208","multi-session CD;content extraction"
"d4f6db3545bd4a3c8210b02d150551fa",2021,"Optimizing Elasticsearch Search Experience Using a Thesaurus","The Belgian Art Links and Tools (BALaT) is the continuously expanding online documentary platform of the Royal Institute for Cultural Heritage (KIK-IRPA), Brussels (Belgium). BALaT contains over 750,000 images of KIK-IRPA’s unique collection of photo negatives on the cultural heritage of Belgium, but also the library catalogue, PDFs of articles from KIK-IRPA’s Bulletin and other publications, an extensive persons and institutions authority list, and several specialized thematic websites, each of those collections being multilingual as Belgium has three official languages. All these are interlinked to give the user easy access to freely available information on the Belgian cultural heritage. During the last years, KIK-IRPA has been working on a detailed and inclusive data management plan. Through this data management plan, a new project HESCIDA (Heritage Science Data Archive) will upgrade BALaT to BALaT+, enabling access to searchable registries of KIK-IRPA datasets and data interoperability. BALaT+ will be a building block of DIGILAB, one of the future pillars of the European Research Infrastructure for Heritage Science (E-RIHS), which will provide online access to scientific data concerning tangible heritage, following the FAIR-principles (Findable-Accessible-Interoperable-Reusable). It will include and enable access to searchable registries of specialized digital resources (datasets, reference collections, thesauri, ontologies, etc.). In the context of this project, Elasticsearch has been chosen as the technology empowering the search component of BALaT+. An essential feature of this search functionality of BALaT+ is the need for linguistic equivalencies, meaning a term query in French should also return the matching results containing the equivalent term in Dutch. Another important feature is to offer a mechanism to broaden the search with elements of more precise terminology: a term like ""furniture"" could also match records containing chairs, tables, etc. This article will explain how a thesaurus developed in-house at KIK-IRPA was used to obtain these functionalities, from the processing of that thesaurus to the production of the configuration needed by Elasticsearch.","Di Pretoro,Emmanuel;De Roock,Edwin;Fremout,Wim;Buelinckx,Erik;Buyle,Stephanie;Van der Stede,Véronique","Code4Lib","https://journal.code4lib.org/articles/15749","elasticsearch;BALaT;Belgium;project;HESCIDA;DIGILAB;FAIR;E-RIHS;thesaurus"
"d539e06d74b94924aa27a325fe8f4673",2020,"Tweeting Tennessee’s Collections: A Case Study of a Digital Collections Twitterbot Implementation","This article demonstrates how a Twitterbot can be used as an inclusive outreach initiative that breaks down the barriers between the web and the reading room to share materials with the public. These resources include postcards, music manuscripts, photographs, cartoons and any other digitized materials. Once in place, Twitterbots allow physical materials to converge with the technical and social space of the Web. Twitterbots are ideal for busy professionals because they allow librarians to make meaningful impressions on users without requiring a large time investment. This article covers the recent implementation of a digital collections bot (@UTKDigCollBot) at the University of Tennessee, Knoxville (UTK), and provides documentation and advice on how you might develop a bot to highlight materials at your own institution.","L. Hale,Meredith","Code4Lib","https://journal.code4lib.org/articles/15112","Twitterbot;Tennessee"
"d56c2c1e2db848f5ab1c3a765fa8abb9",2022,"Supporting open access, integrating distributed research platforms, and building a research information management platform","Academic libraries are often called upon by their university communities to collect, manage, and curate information about the research activity produced at their campuses. Proper research information management (RIM) can be leveraged for multiple institutional contexts, including networking, reporting activities, building faculty profiles, and supporting the reputation management of the institution. In the last ten to fifteen years the adoption and implementation of RIM infrastructure has become widespread throughout the academic world. Approaches to developing and implementing this infrastructure have varied, from commercial and open-source options to locally developed instances. Each piece of infrastructure has its own functionality, features, and metadata sources. There is no single application or data source to meet all the needs of these varying pieces of research information, many of these systems together create an ecosystem to provide for the diverse set of needs and contexts. This paper examines the systems at Pennsylvania State University that contribute to our RIM ecosystem; how and why we developed another piece of supporting infrastructure for our Open Access policy and the successes and challenges of this work.","M. Coughlin,Daniel;Hudson Vitale,Cynthia","Code4Lib","https://journal.code4lib.org/articles/16479","research information management;infrastructure;open access;Pennsylvania"
"d5d31e75d0e44764a62a3c10be51210e",2019,"Digitization Selection Criteria as Anti-Racist Action","By deciding what to digitize in special collections and archives, we choose what narratives to promote, what history to highlight, and what legacies to further. This paper details a new initiative at LSU Libraries to integrate diversity and inclusion goals into digitization policies. After reviewing examples of how digitization can be either beneficial or harmful to individuals represented in the historical record, the author uses Ibram Kendi's definition of racist policy -- that which leads to racial inequalities -- as a starting point for exploring how digitization selection can help counteract histories of exclusion.","L. Ziegler,S.","Code4Lib","https://journal.code4lib.org/articles/14667","digitization;LSU;exclusion"
"d60392cb23f8483f9eb7c37c0f159377",2012,"Discovering Digital Library User Behavior with Google Analytics","Google Analytics has advanced features for tracking search queries, events such as clicking external links or downloading files, which you can use to track user behavior that is normally difficult to track with traditional web logging software. By tracking behavior, you can use Google Analytics API to extract data and integrate it with data from your digital repository to show granular data about individual items. Using this information, digital libraries can learn how users use the site without extensive HCI studies, and can use this information to improve the user experience.","Hess,Kirk","Code4Lib","http://journal.code4lib.org/articles/6942","API;Google Analytics;user experience;data integration"
"d705b5b1ef7a4c38ad45a2c8718fc481",2020,"Building Strong User Experiences in LibGuides with Bootstrapr and Reviewr","With nearly fifty subject librarians creating LibGuides, the LibGuides Management Team at Notre Dame needed a way to both empower guide authors to take advantage of the powerful functionality afforded by the Bootstrap framework native to LibGuides, and to ensure new and extant library guides conformed to brand/identity standards and the best practices of user experience (UX) design. To accomplish this, we developed an online handbook to teach processes and enforce styles; a web app to create Twitter Bootstrap components for use in guides (Bootstrapr); and a web app to radically speed the review and remediation of guides, as well as better communicate our changes to guide authors (Reviewr). This article describes our use of these three applications to balance empowering guide authors against usefully constraining them to organizational standards for user experience. We offer all of these tools as FOSS under an MIT license so that others may freely adapt them for use in their own organization.","Sean Harrison,Randal","Code4Lib","https://journal.code4lib.org/articles/15182","LibGuides;Notre Dame;Bootrap;UX;user experience;FOSS"
"d72cfd471f644eabaf390a7e4d4f5440",2018,"Analysis of 2018 International Linked Data Survey for Implementers","OCLC Research conducted an International Linked Data Survey for Implementers in 2014 and 2015. Curious about what might have changed since the last survey, and eager to learn about new projects or services that format metadata as linked data or make subsequent uses of it, OCLC Research repeated the survey between 17 April and 25 May 2018. A total of 143 institutions in 23 countries responded to one or more of the surveys. This analysis covers the 104 linked data projects or services described by the 81 institutions which responded to the 2018 survey—those that publish linked data, consume linked data, or both. This article provides an overview of the linked data projects or services institutions have implemented or are implementing; what data they publish and consume; the reasons given for implementing linked data and the barriers encountered; and some advice given by respondents to those considering implementing a linked data project or service. Differences with previous survey responses are noted, but as the majority of linked projects and services described are either not yet in production or implemented within the last two years, these differences may reflect new trends rather than changes in implementations.","Smith-Yoshimura,Karen","Code4Lib","https://journal.code4lib.org/articles/13867","link data survey;OCLC;trends"
"d7fa2630b4b24c3a9dff6732838752ea",2014,"Indexing Bibliographic Database Content Using MariaDB and Sphinx Search Server","Fast retrieval of digital content has become mandatory for library and archive information systems. Many software applications have emerged to handle the indexing of digital content, from low-level ones such Apache Lucene, to more RESTful and web-services-ready ones such Apache Solr and ElasticSearch. Solr’s popularity among library software developers makes it the “de-facto” standard software for indexing digital content. For content (full-text content or bibliographic description) already stored inside a relational DBMS such as MariaDB (a fork of MySQL) or PostgreSQL, Sphinx Search Server (Sphinx) is a suitable alternative. This article will cover an introduction on how to use Sphinx with MariaDB databases to index database content as well as some examples of Sphinx API usage.","Nugraha,Arie","Code4Lib","http://journal.code4lib.org/articles/9793","indexing;RESTful;Solr;API;Apache Lucene;ElasticSearch;MariaDB;Sphinx API;bibliographic database"
"d8812e2bb26a453191dc7bc2a4049016",2010,"Subject Guides & More: Creatively Transforming an Open Source Management System","This article describes the implementation of SubjectsPlus to manage the subject guides at the Wichita State University Libraries. The decision to implement an open source solution, the implementation process, and customizations to the software are discussed. In addition to the subject guides, SubjectsPlus is also used to manage course specific and miscellaneous topic guides, the library staff directory, and database links. The article also covers the reception of SubjectsPlus by the librarians and teaching faculty.","Blackburn,Gemma;Walker,Mary","Code4Lib","http://journal.code4lib.org/articles/4161","SubjectsPlus;Wichita"
"d88589d822624693aeccbea4bfc186bf",2016,"Editorial Introduction – Summer Reading List","New additions for your summer reading list!","Peterson,Ron","Code4Lib","http://journal.code4lib.org/articles/11859","editorial"
"d98f214b1b914a8788bbd99d3525339e",2012,"Prototyping as a Process for Improved User Experience with Library and Archives Websites","Prototypes can be persuasive tools for proposing changes within an organization through “imagine if” scenarios. They not only show how to enhance the online experience, but can provide a way to improve the overall organizational environment as well. In redesigning the Princeton University Finding Aids site (http://findingaids.princeton.edu), we used a flexible subset of Agile practices based around measurable goals, iterative prototypes, meetings with institutional stakeholders, and “discount usability testing” to deliver an innovative and much-improved user experience. This article discusses how integrating relatively untested, but promising new ideas for online finding aids required us to adopt a development process that would allow us to better understand the goals of both general and staff users and in turn foster an environment for innovation that thrives on collaboration, iteration, and managed risk.","EllisPeterson,Shaun;Callahan,Maureen","Code4Lib","http://journal.code4lib.org/articles/7394","prototypes;Princetosn;Agile;development process;risk"
"da30ae0a64a042c289b413fe2fa6c42b",2014,"Docker: a Software as a Service, Operating System-Level Virtualization Framework","Docker is a relatively new method of virtualization available natively for 64-bit Linux. Compared to more traditional virtualization techniques, Docker is lighter on system resources, offers a git-like system of commits and tags, and can be scaled from your laptop to the cloud.","Fink,John","Code4Lib","http://journal.code4lib.org/articles/9669","Docker;virtualization"
"dad1abe4c4de4160aef317c56784ea00",2010,"Editorial Introduction &#8211; Moving Forward","Welcoming new editors, and reflecting on the sustainability factor.","Bean,Carol","Code4Lib","http://journal.code4lib.org/articles/2569","editorial"
"dae76320e5414fec82f61da4fc65a717",2011,"MARC21 as Data: A Start","The forty-five-year-old MARC format, currently at version MARC21, is an obvious barrier to the provision of library services in a web-based environment. There is a growing consensus that the time has come for libraries to move to a new format. We cannot, however, decide on a new data format until we at least have an inventory of the data elements that are carried in our current one. Listing those data elements is not simple: over the years this record format has undergone constant change that has pushed the limits of the record structure and introduced inconsistencies in the way that data is coded. This article describes one person's attempt to decode the content of MARC21.","Coyle,Karen","Code4Lib","http://journal.code4lib.org/articles/5468","MARC21;MARC"
"db63f59d0a294e9ebfcf3fca0dd98795",2017,"Using the ‘rentrez’ R Package to Identify Repository Records for NCBI LinkOut","In this article, we provide a brief overview of the National Center for Biotechnology Information (NCBI) LinkOut service for institutional repositories, a service that allows links from the PubMed database to full-text versions of articles in participating institutional repositories (IRs). We discuss the criteria for participation in NCBI LinkOut for IRs, current methods for participating, and outline our solution for automating the identification of eligible articles in a repository using R and the ‘rentrez’ package. Using our solution, we quickly processed 4,400 open access items from our repository, identified the 557 eligible records, and sent them to the NLM. Direct linking from PubMed resulted in a 17% increase in web traffic.","Young Lee,Yoo;D. Foster,Erin;E. Polley,David;Odell,Jere","Code4Lib","http://journal.code4lib.org/articles/12792","R;biotechnology;PubMed"
"dc7f6ed3f3d44264861a32fff6b44910",2008,"Using Google Calendar to Manage Library Website Hours","The management and display of hours of operation on a library website can be needlessly complicated. One relatively simple solution is to manage the library hours in Google Calendar, and then use the Google API to extract this data for use on the public website. This article outlines how the Ithaca College Library used Google Calendar, PHP and MySQL to manage and report against our library's operational hours. Example code is included.","Darby,Andrew","Code4Lib","http://journal.code4lib.org/articles/46","Google Calendar;Google API;operational hours"
"dcd46c771e5845a5882c0feddf1df0b6",2010,"Querying OCLC Web Services for Name, Subject, and ISBN","Using Web services, search terms can be sent to WorldCat's centralized authority and identifier files to retrieve authorized terminology that helps users get a comprehensive set of relevant search results. This article presents methods for searching names, subjects or ISBNs in various WorldCat databases and displaying the results to users. Exploiting WorldCat's databases in this way opens up future possibilities for more seamless integration of authority-controlled vocabulary lists into new discovery interfaces and a reduction in libraries’ dependence on local name and subject authority files.","Ziso,Ya’aqov;LeVan,Ralph;Lease Morgan,Eric","Code4Lib","http://journal.code4lib.org/articles/2481","OCLC;WorldCatsearch methods"
"dd4caf32bd0c4f8abbf416682781ef2b",2022,"Works, Expressions, Manifestations, Items: An Ontology","The concepts first introduced in the FRBR document and known as ""WEMI"" have been employed in situations quite different from the library bibliographic catalog. This is evidence that a definition of similar classes that are more general than those developed for library usage would benefit metadata developers broadly. This article proposes a minimally constrained set of classes and relationships that could form the basis for a useful model of created works.","Coyle,Karen","Code4Lib","https://journal.code4lib.org/articles/16491","FRBR;WEMI;ontology"
"dd716cfeb45848c597fce52ba4e581b3",2019,"Large-Scale Date Normalization in ArchivesSpace with Python, MySQL, and Timetwister","Normalization of legacy date metadata can be challenging, as standards and local practices for formulating dates have varied widely over time. With the advent of archival management systems such as ArchivesSpace, structured, machine-actionable date metadata is becoming increasingly important for search and discovery of archival materials. This article describes a recent effort by a group of Yale University archivists to add ISO 8601-compliant dates to nearly 1 million unstructured date records in ArchivesSpace, using a combination of Python, MySQL, and Timetwister, a Ruby gem developed at the New York Public Library (NYPL).","Detelich,Alicia","Code4Lib","https://journal.code4lib.org/articles/14443","metadata normalization;ArchivesSpace;Yale;Python;Ruby;MySQL;NYPL"
"dda9e9fdea554315920be219e7585974",2013,"Augmenting the Cataloger’s Bag of Tricks : Using MarcEdit, Python,and PyMARC for Batch-Processing MARC Records Generated From the Archivists&#8217;Toolkit","Catalogers have traditionally created and edited MARC records on aone-by-one basis. Recently, it has become more common for catalogers to delve into scriptingand programming tools in order to automate the processing of large numbers of records simultaneously. This article provides a case study showing how MARCXML archival recordsgenerated by the Archivists' Toolkit (AT) can be modified in batches using the MarcEdit software, Python scripting and the PyMARC module in Python. It analyzes selected problems withthe MARC records exported by the AT and shows how MarcEdit and Python are used to resolve themso that the records are formatted correctly for loading into the library's local catalog.Similar methods could be used by catalogers dealing with any large set of MARC data, such asebook records from vendors.","Frank,Heidi","Code4Lib","http://journal.code4lib.org/articles/8336","cataloguer;MARC;MARCXML;MarcEdit;PyMARC"
"ddfb65f69e5f4eecbd99cdaafcef1b1b",2011,"Book Review: HTML5: Up and Running","Mark Pilgrim's HTML5: Up and Running was one of the first books published on the subject. If you’re looking for a really good, well-written, entertaining, concise overview of what’s going on right this very minute with HTML5 technologies and techniques, this is a good book to have.","Cyzyk,Mark","Code4Lib","http://journal.code4lib.org/articles/4146","book review"
"df352600b07d437db73c842901ff08be",2015,"Special Issue on Diversity in Library Technology Guest Editorial Committee","The guest editorial committee for Code4Lib Journal’s Special Issue on Diversity in Library Technology (issue 28) was developed in order to include new voices and perspectives on the journal’s practices and how they support inclusivity. The committee is comprised of eight guest editors and two regular editorial committee members. More information on the development of […]",,"Code4Lib","http://journal.code4lib.org/articles/10424","editorial"
"dfe29edf732e4c459b11226ad8027ccb",2018,"Centralized Accessioning Support for Born Digital Archives","Archives often receive obsolete digital storage media alongside paper acquisitions: CDs and DVDs mixed in with folders of correspondence, Zip disks, and floppy disks set aside by the donor with the intention to review the content later. Archives must not only have the expertise to work with digital media, but also the hardware and software to capture the content without the risk of altering the files merely by viewing them. This article will describe how Yale University Libraries and Museums addressed accessioning of born-digital archival content on physical media through a centralized digital accessioning support service. Centralizing the hardware and expertise required for working with physical media made it possible to accession media more quickly and return the files to the originating archives for arrangement and description.","Sara Prael,Alice","Code4Lib","http://journal.code4lib.org/articles/13494","archives;Yale;physical media;obsolete media"
"e0dccb1b74bf48c6b03847d4afcd3327",2013,"VIAFbot and the Integration of Library Data on Wikipedia","This article presents a case study of a project, led by Wikipedians in Residence at OCLC and the British Library, to integrate authority data from the Virtual International Authority File (VIAF) with biographical Wikipedia articles. This linking of data represents an opportunity for libraries to present their traditionally siloed data, such as catalog and authority records, in more openly accessible web platforms. The project successfully added authority data to hundreds of thousands of articles on the English Wikipedia, and is poised to do so on the hundreds of other Wikipedias in other languages. Furthermore, the advent of Wikidata has created opportunities for further analysis and comparison of data from libraries and Wikipedia alike. This project, for example, has already led to insights into gender imbalance both on Wikipedia and in library authority work. We explore the possibility of similar efforts to link other library data, such as classification schemes, in Wikipedia.","Klein,Maximilian;Kyrios,Alex","Code4Lib","http://journal.code4lib.org/articles/8964","VIAFbot;Wikipedia;siloed data;classification schemes"
"e1177185b44c45c0b6d83353f036c51a",2014,"Using Zapier with Trello for Electronic Resources Troubleshooting Workflow","Troubleshooting access problems is an important part of the electronic resources management workflow. This article discusses an opportunity to streamline and track troubleshooting using two web-based services: Trello and Zapier.","Finch,Meghan","Code4Lib","http://journal.code4lib.org/articles/10034","Zapier;Trello;workflow;troubleshooting"
"e13a648bcdc049be951d51c6638a4102",2015,"Editorial Introduction: It's All About Data, Except When It's Not.","Data capture and use is not new to libraries.We know data isn't everything, but it is ubiquitous in our work, enabling myriads of new ideas and projects.Articles in this issue reflect the expansion of data creation, capture, use, and analysis in library systems and services.","Bean,Carol","Code4Lib","http://journal.code4lib.org/articles/11072","editorial"
"e28f53d826d24bef84923b0fd535c953",2018,"Ship It: Logistical tracking of ILL physical loans","The OBILLSK Shipment Tracking system is the first consolidated and comprehensive shipment information system for interlibrary loan. The system is unique because not only does it offer an interface for consolidating the items being shipped out of an ILL office, it also provides real time statistical data of global geographic shipping patterns, tracking of packages across all major couriers, and customized date range reporting for ILL shipment activity. This system takes advantage of several web-based technologies that makes it easy to use for students, staff and library administrators. The web-based software utilizes a .NET platform and SQL Server database. Client-side frameworks include Bootstrap and jQuery for responsive design, Shield UI for data visualizations, and jVectorMap for geographical representation of shipments. The system is now available for all libraries. It is actively in use at 15 academic libraries nationwide and has over 190,000 items scanned since October of 2016. It is through the development of innovative technologies that libraries can continue to serve as incubators for practical solutions that can help the discipline and practice of librarianship.","Litsey,Ryan;Luker,Scott","Code4Lib","http://journal.code4lib.org/articles/13262","OBILLSK;shipment tracking;ILL;logistics"
"e296d6fcf80d4d7e909b133eedadc7f5",2013,"Better Search Through Query Expansion Using Controlled Vocabularies andApache Solr","This article describes how the University of Pennsylvania Museum of Archaeology and Anthropology (Penn Museum) modified its Solr-based discovery interface toimprove recall and enable end users to benefit from the power of their in-house controlledvocabularies. These modifications automatically expand the query generated by any search termthat matches their controlled vocabulary to include all related alternate and narrower terms. For example, if a user enters Ohio, that search will retrieve the record for an arrow head found in Cincinnati (a narrower term of Ohio) even if that record does not include the term Ohio.","Williams,Scott","Code4Lib","http://journal.code4lib.org/articles/7787","query expansion;Penn Museum;Solr;controlled vocabulary"
"e2afdf0bcb724183b9bd65f28dfda38c",2020,"From Text to Map: Combing Named Entity Recognition and Geographic Information Systems","This tutorial shows readers how to leverage the power of named entity recognition (NER) and geographic information systems (GIS) to extract place names from text, geocode them, and create a public-facing map. This process is highly useful across disciplines. For example, it can be used to generate maps from historical primary sources, works of literature set in the real world, and corpora of academic scholarship. In order to lead the reader through this process, the authors work with a 500 article sample of the COVID-19 Open Research Dataset Challenge (CORD-19) dataset. As of the date of writing, CORD-19 includes 45,000 full-text articles with metadata. Using this sample, the authors demonstrate how to extract locations from the full-text with the spaCy library in Python, highlight methods to clean up the extracted data with the Pandas library, and finally teach the reader how to create an interactive map of the places using ArcGIS Online. The processes and code are described in a manner that is reusable for any corpus of text","Harper,Charlie;Benjamin Gorham,R.","Code4Lib","https://journal.code4lib.org/articles/15405","NER;named entity recognition;GIS;COVID-19;spaCy;Python;Pandas;ArcGIS Online"
"e31abe02d79c41f6abdad7735831be9b",2017,"DIY DOI: Leveraging the DOI Infrastructure to Simplify Digital Preservation and Repository Management","This article describes methods for how staff with modest technical expertise can leverage the DOI (Digital Object Identifier) infrastructure in combination with third party storage and preservation solutions to build safer, more useful, and easier to manage repositories at much lower cost than is normally possible with standalone systems. It also demonstrates how understanding the underlying mechanisms and questioning the assumptions of technology metaphors such as filesystems can lead to seeing and using tools in new and more powerful ways.","Bannerjee,Kyle;Forero,David","Code4Lib","http://journal.code4lib.org/articles/12870","DIY;DOI;digital preservation;repository management"
"e3803ecf2e8347deb6622700a64d1803",2021,"Considered Content: a Design System for Equity, Accessibility, and Sustainability","The University of Minnesota Libraries developed and applied a principles-based design system to their Health Sciences Library website. With the design system at its center, the revised site was able to achieve accessible, ethical, inclusive, sustainable, responsible, and universal design. The final site was built with elegantly accessible semantic HTML-focused code on Drupal 8 with highly curated and considered content, meeting and exceeding WCAG 2.1 AA guidance and addressing cognitive and learning considerations through the use of plain language, templated pages for consistent page-level organization, and no hidden content. As a result, the site better supports all users regardless of their abilities, attention level, mental status, reading level, and reliability of their internet connection, all of which are especially critical now as an elevated number of people experience crises, anxieties, and depression.","Aspinall,Erinn;Drayer,Amy;Ormsby,Gabe;Neveau,Jen","Code4Lib","https://journal.code4lib.org/articles/15639","Minnesota;Health;Drupal;WCAG;AA;"
"e440e6aefd584e1f80b12df5cbe87ae6",2021,"Archive This Moment D.C.: A Case Study of Participatory Collecting During COVID-19","When the COVID-19 pandemic brought life in Washington, D.C. to a standstill in March 2020, staff at DC Public Library began looking for ways to document how this historic event was affecting everyday life. Recognizing the value of first-person accounts for historical research, staff launched Archive This Moment D.C. to preserve the story of daily life in the District during the stay-at-home order. Materials were collected from public Instagram and Twitter posts submitted through the hashtag #archivethismomentdc. In addition to social media, creators also submitted materials using an Airtable webform set up for the project and through email. Over 2,000 digital files were collected. This article will discuss the planning, professional collaboration, promotion, selection, access, and lessons learned from the project; as well as the technical setup, collection strategies, and metadata requirements. In particular, this article will include a discussion of the evolving collection scope of the project and the need for clear ethical guidelines surrounding privacy when collecting materials in real-time.","Burns,Julie;Farley,Laura;C. Hagan,Siobhan;Kelly,Paul;Warwick,Lisa","Code4Lib","https://journal.code4lib.org/articles/15534","COVID-19;Washington;archivethismomentdc"
"e470586e8b9a4ed2a1a2d44d1b456b46",2010,"Automatic Generation of Printed Catalogs: An Initial Attempt","Printed catalogs are useful in a variety of contexts. In special collections, they are often used as reference tools and to commemorate exhibits. They are useful in settings, such as in developing countries, where reliable access to the Internet—or even electricity—is not available. In addition, many private collectors like to have printed catalogs of their collections. All the information needed for creating printed catalogs is readily available in the MARC bibliographic records used by most libraries, but there are no turnkey solutions available for the conversion from MARC to printed catalog. This article describes the development of a system, available on github, that uses XSLT, Perl, and LaTeX to produce press-ready PDFs from MARCXML files. The article particularly focuses on the two XSLT stylesheets which comprise the core of the system, and do the ""heavy lifting"" of sorting and indexing the entries in the catalog. The author also highlights points where the data stored in MARC bibliographic records requires particular ""massaging,"" and suggests improvements for future attempts at automated printed catalog generation.","Camins-Esakov,Jared","Code4Lib","http://journal.code4lib.org/articles/3154","printed catalogues;MARC;XSLT;LaTeX;automatic printing"
"e4b3bc02238d4047a752048c758af9d8",2010,"Building a Location-aware Mobile Search Application with Z39.50 and HTML5","This paper presents MyTPL, a proof-of-concept web application intended to demonstrate that, with a little imagination, any library with a Z39.50 catalogue interface and a web server with some common open-source tools can readily provide their own location-aware mobile search application. The complete source code for MyTPL is provided under the GNU GPLv3 license, and is freely available.","Suhonos,MJ","Code4Lib","http://journal.code4lib.org/articles/2947","MyTPL;Z39.50;catalog interface"
"e5afe96dcfcf475dadb7d0ba1aa85782",2010,"How To Build a Computer Availability Map","Most libraries house one or more computer labs. Wouldn't it be nice to be able to let your patrons view how many and what type of computers are available at any given time? Well, now you can. Follow along in this tutorial that takes you through the stages of implementing a real-time computer availability map that works for a mobile and full website. The complete code package is provided under the GPL v3 license, and is available at: http://github.com/griggsk/availability-map.","Griggs,Kim","Code4Lib","http://journal.code4lib.org/articles/4067","computer labs"
"e68f13cafabb43d88f76301b9261108b",2012,"Case Study: Using Perl and CGI Scripts to Automate a Quality Control Workflow for Scanned Congressional Documents","The Law Library Digitization Project of the Rutgers University School of Law in Camden, New Jersey, developed a series of scripts in Perl and CGI that take advantage of the open-source module PerlMagick to automatically review the image quality of scanned government documents. By implementing these procedures, Rutgers was able to save staff working hours for document quality control by an estimated 25% percent from the previous manual-only workflow. These scripts can be adapted by novice Perl and CGI programmers to review and manipulate large numbers of text and image files using commands available in PerlMagick and ImageMagick.","Belfiore,Doreva","Code4Lib","http://journal.code4lib.org/articles/6731","case study;Perl;CGI;quality control;Rutgers;PerlMagick;ImageMagick"
"e6f5a1c9048447d695b1a8ab2150a229",2016,"Emflix – Gone Baby Gone","Enthusiasm is no replacement for experience. This article describes a tool developed at the Emerson College Library by an eager but overzealous cataloger. Attempting to enhance media-discovery in a familiar and intuitive way, he created a browseable and searchable Netflix-style interface. Though it may have been an interesting idea, many of the crucial steps that are involved in this kind of high-concept work were neglected. This article will explore and explain why the tool ultimately has not been maintained or updated, and what should have been done differently to ensure its legacy and continued use.","Ganin,Netanel","Code4Lib","http://journal.code4lib.org/articles/11762","interface;Emerson;failure"
"e8ce879f5fad490a8d810c9b4f755a82",2013,"Building a Library App Portfolio with Redis and Django","The Tutt Library at Colorado College is developing a portfolio of library applications for use by patrons and library staff. Developed under an iterative and incremental agile model, these single-use HTML5 applications target multiple devices while using Bootstrap and Django to deliver fast and responsive interfaces to underlying FRBR datastores running on Redis, an advanced NoSQL database server. Two types are delineated: applications for access and discovery, which are available to everyone; and productivity applications, which are primarily for library staff to administer and manage the FRBR-RDA records. The access portfolio includes Book Search, Article Search, Call Number, and Library Hours applications. The productivity side includes an Orders App and a MARC Batch application for ingesting MARC records as FRBR entities using RDA Core attributes. When a critical threshold is reached, the Tutt Library intends to replace its legacy ILS with this library application portfolio.","Nelson,Jeremy","Code4Lib","http://journal.code4lib.org/articles/7349","Tutt;FRBR;RDA;MARC;ILS;FRBR datastore;Django;HTML5"
"e9014437201e4dfc84b1e026f0bcce27",2014,"Solving Advanced Encoding Problems with FFMPEG","Previous articles in the Code4Lib Journal touch on the capabilities of FFMPEG in great detail, and given these excellent introductions, the purpose of this article is to tackle some of the common problems users might face, dissecting more complicated commands and suggesting their possible uses.","Romphf,Josh","Code4Lib","http://journal.code4lib.org/articles/9856","FFMPEG"
"e9af07e073e74480842a81a166f7a8c5",2017,"OpeNumisma: A Software Platform Managing Numismatic Collections with A Particular Focus On Reflectance Transformation Imaging","This paper describes OpeNumisma; a reusable web-based platform focused on digital numismatic collections. The platform provides an innovative merge of digital imaging and data management systems that offer great new opportunities for research and the dissemination of numismatic knowledge online. A unique feature of the platform is the application of Reflectance Transformation Imaging (RTI), a computational photographic method that offers tremendous image analysis and possibilities for numismatic research. This computational photography technique allows the user to observe on browser minor details, unseen with the naked eye just by holding the computer mouse rather than the actual object. The first successful implementation of OpeNumisma has been the creation of a digital library for the medieval coins from the collection of the Bank of Cyprus Cultural Foundation.","Avgousti,Avgoustinos;Nikolaidou,Andriana;Georgiou,Ropertos","Code4Lib","http://journal.code4lib.org/articles/12627","OpeNumisma;numismatic collections;Reflectance Transformation Imaging;Cyprus"
"ea74a71c11a145ecbb3bbc4c4e20d955",2018,"Wikidata: a platform for your library's linked open data","Seized with the desire to improve the visibility of Canadian music in the world, a ragtag band of librarians led by Stacy Allison-Cassin set out to host Wikipedia edit-a-thons in the style of Art+Feminism, but with a focus on addressing Canadian music instead. Along the way, they recognized that Wikidata offered a low-barrier, high-result method of making that data not only visible but reusable as linked open data, and consequently incorporated Wikidata into their edit-a-thons. This is their story.","Allison-Cassin,Stacy;Scott,Dan","Code4Lib","http://journal.code4lib.org/articles/13424","Wikidata;linked open data;Canada;edit-a-thons"
"eb3b06a335c9498f9de23a2964916c46",2022,"Predictable Book Shifting","There are many methods to carry out a library book shift but those methods allow for varying degrees of predictability. The Bookshift.py script, when used in conjunction with accurate measurements of a library's collection and shelving, provides library staff with predictability, flexibility, and the ability to shift in parallel. For every shelf, the script outputs a phrase such as the following, ""The last book from this shelf goes 12.3 in/cm into shelf 776."" While complicated shifts can still create surprises, using Bookshift.py or similar methods typically make those surprises easy to correct.","Lambert,Joshua","Code4Lib","https://journal.code4lib.org/articles/16577","book shifting;shelving"
"eba6e6e099634674b83aca73e6630f33",2018,"Approaching the largest ‘API’: extracting information from the Internet with Python","This article explores the need for libraries to algorithmically access and manipulate the world’s largest API: the Internet. The billions of pages on the ‘Internet API’ (HTTP, HTML, CSS, XPath, DOM, etc.) are easily accessible and manipulable.Libraries can assist in creating meaning through the datafication of information on the world wide web.Because most information is created for human consumption, some programming is required for automated extraction. Python is an easy-to-learn programming language with extensive packages and community support for web page automation.Four packages (Urllib, Selenium, BeautifulSoup, Scrapy) in Python can automate almost any web page for all sized projects. An example warrant data project is explained to illustrate how well Python packages can manipulate web pages to create meaning through assembling custom datasets.","E. Germann,Jonathan","Code4Lib","http://journal.code4lib.org/articles/13197","API;Python;custom datasets"
"ec15a2f3e83b48029c21e02d288903df",2012,"Creating a Seamless Cross-Platform Online Experience for Mobile Users","In creating a mobile-optimized website for Drexel University Libraries, we have strived to preserve the seamless transition between platforms that our desktop users experience. We employ separate technology and coding solutions to make Drupal, WordPress, and HTML sections mobile optimized, while continuously improving the mobile user experience in terms of design, usability, and site performance. This paper details how, through extensive research, design, and development, we found the best solution for creating a steady mobile experience for our users.","Lynch,Katherine","Code4Lib","http://journal.code4lib.org/articles/6223","Drexel;mobile experience"
"ec17bbe504c94619a31ee669b0c5d752",2017,"OPRM:Challenges to Including Open Peer Review in Open Access Repositories","The peer review system is the norm for many publications. It involves an editor and several experts in the field providing comments for a submitted article. The reviewer remains anonymous to the author, with only the editor knowing the reviewer´s identity. This model is now being challenged and open peer review (OPR) models are viewed as the new frontier of the review process. OPR is a term that encompasses diverse variations in the traditional review process. Examples of this are modifications in the way in which authors and reviewers are aware of each other’s identity (open identities), the visibility of the reviews carried out (open reviews) or the opening up of the review to the academic community (open participation). We present the project for the implementation of an Open Peer Review Module in two major Spanish repositories, DIGITAL.CSIC and e-IEO, together with some promising initial results and challenges in the take-up process. The OPR module, designed for integration with DSpace repositories, enables any scholar to provide a qualitative and quantitative evaluation of any research object hosted in these repositories.","Perakakis,Pandelis;Ponsati,Agnes;Bernal,Isabel;Sierra,Carles;Osman,Nardine;Mosquera-de-Arancibia,Concha;Lorenzo,Emilio","Code4Lib","http://journal.code4lib.org/articles/12171","peer review;open peer review;open access;repositories"
"ec20d77d0ac34f07a699171c190a63c0",2014,"Unix Commands and Batch Processing for the Reluctant Librarian or Archivist","The Unix environment offers librarians and archivists high-quality tools for quickly transforming born-digital and digitized assets, such as resizing videos, creating access copies of digitized photos, and making fair-use reproductions of audio recordings. These tools, such as ffmpeg, lame, sox, and ImageMagick, can apply one or more manipulations to digital assets without the need to manually process individual items, which can be error prone, time consuming, and tedious. This article will provide information on getting started in using the Unix environment to take advantage of these tools for batch processing.","Cocciolo,Anthony","Code4Lib","http://journal.code4lib.org/articles/9158","Unix commands;batch processing;ImageMagick"
"edfc1179769a4178bc0c7a22bb15b149",2017,"Between the Sheets: a Library-wide Inventory with Google","When it comes to taking an inventory of physical items, libraries often rely on their traditional integrated library system’s (ILS) à la carte add ons; outside vendors; or other possibly outdated, complex, and often expensive methods. For libraries with shrinking budgets and other limited resources, high costs can put these methods out of reach. At the University of Dayton Libraries, we set out to develop an inexpensive and reasonably easy-to-use method for conducting a library-wide physical item inventory. In this article, we explain a custom built Google Sheets-based library inventory system, along with some code for the implementation of a RESTful API (written in PHP) that interacts with our ILS. We will also explain our use of Google Apps scripts in our Google Sheet, which are crucial to our systems. Although this method used a specific ILS (Innovative Interfaces' Sierra product) and custom-built RESTful APIs, it may be possible to use similar approaches with other ILS software. Additional notes include areas for improvement and recommendations for interoperability with other ILS systems.","Boman,Craig;Voelker,Ray","Code4Lib","http://journal.code4lib.org/articles/12783","API;ILS;Dayton;RESTful API;API;PHP"
"ee0d028d469644d3a5ff3c2870a9ab40",2020,"Testing remote access to e-resource with CodeceptJS","At the Badische Landesbibliothek Karlsruhe (BLB) we offer a variety of e-resources with different access requirements. On the one hand, there is free access to open access material, no matter where you are. On the other hand, there are e-resources that you can only access when you are in the rooms of the BLB. We also offer e-resources that you can access from anywhere, but you must have a library account for authentication to gain access. To test the functionality of these access methods, we have created a project to automatically test the entire process from searching our catalogue, selecting a hit, logging in to the provider's site and checking the results. For this we use the End 2 End Testing Framework CodeceptJS.","Weber,Ralf","Code4Lib","https://journal.code4lib.org/articles/15297","e-resources;CodeceptJS;E2E testing"
"ee65978a86b840cdb17a93b08bc0aa1d",2022,"Automating reference consultation requests with JavaScript and a Google Form","At the CUNY Graduate Center Library, reference consultation requests were previously sent to a central email address, then manually directed by our head of reference to the appropriate subject expert. This process was cumbersome and because the inbox was not checked every day, responses were delayed and messages were occasionally missed. In order to streamline this process, I created a form and wrote a script that uses the answers in the form to automatically forward any consultation requests to the correct subject specialist. This was done using JavaScript, Google Sheets, and the Google Apps Script backend. When a patron requesting a consultation fills out the form, they include their field of research. This field is associated in my script with a particular subject specialist librarian, who then receives an email with the pertinent information. Rather than requiring either that patrons themselves search for the right subject specialist, or that library faculty spend time distributing messages to the right liaison, this enables a smoother, more direct interaction. In this article, I will describe the steps I took to write this script, using only freely available online software.","Zweibel,Stephen","Code4Lib","https://journal.code4lib.org/articles/16414","JavaScript;CUNY;Google Sheets;reference service"
"eea00cf2dd97424eb253c100c4af7a55",2014,"Automated processing of massive audio/video content using FFmpeg","Audio and video content forms an integral, important and expanding part of the digital collections in libraries and archives world-wide.While these memory institutions are familiar and well-versed in the management of more conventional materials such as books, periodicals, ephemera and images, the handling of audio (e.g., oral history recordings) and video content (e.g., audio-visual recordings, broadcast content) requires additional toolkits.In particular, a robust and comprehensive tool that provides a programmable interface is indispensable when dealing with tens of thousands of hours of audio and video content. FFmpeg is comprehensive and well-established open source software that is capable of the full-range of audio/video processing tasks (such as encode, decode, transcode, mux, demux, stream and filter). It is also capable of handling a wide-range of audio and video formats, a unique challenge in memory institutions.It comes with a command line interface, as well as a set of developer libraries that can be incorporated into applications.","Siang Hock,Kia;Lingxia,Li","Code4Lib","http://journal.code4lib.org/articles/9128","Ffmpeg;audio;video;automated processing"
"ef2be743d16f4585b7f68189c4bde3d2",2010,"Electronic Resources Security: A look at Unauthorized Users","Much of the literature written on electronic resources security focuses on systematic downloading.  However, when the unauthorized use from two cases of stolen identities at the University of Saskatchewan was studied in more depth, a different pattern emerged.  By analyzing proxy server data, we found that the unauthorized use was coming from all over the world, was focused on science, technology and medical resources, and included both small-scale and excessive downloading.  This article outlines some steps that libraries can take to detect and prevent small-scale unauthorized use and implications as libraries move towards Shibboleth authentication.","Tones White,Heather","Code4Lib","http://journal.code4lib.org/articles/4117","Saskatchewan;security;Shibboleth"
"ef851bd50a684a4e9a21492436c4a161",2012,"Editorial Introduction","Coordinating Editor Tim Lepczyk salutes change in this issue, welcoming new editors to the Journal and announcing his departure.","Lepczyk,Tim","Code4Lib","http://journal.code4lib.org/articles/7068","editorial"
"efd9df8cae22460ab66b0607bca97cb5",2016,"Data for Decision Making: Tracking Your Library’s Needs With TrackRef","Library services must adapt to changing patron needs. These adaptations should be data-driven. This paper reports on the use of TrackRef, an open source and free web program for managing reference statistics.","Carlozzi,Michael","Code4Lib","http://journal.code4lib.org/articles/11740","patron needs;TrackRef;reference statistics"
"f03e86ee6ca54827a209798ccb3ba7e4",2010,"OpenRoom: Making Room Reservation Easy for Students and Faculty","Scheduling and booking space is a problem facing many academic and public libraries. Systems staff at the Ball State University Libraries addressed this problem by developing a user friendly room management system, OpenRoom. The new room management application was developed using an open source model with easy installation and management in mind and is now publicly available.","W. Hafner,Arthur;L. Seaton,Robert;D. Faust,Bradley","Code4Lib","http://journal.code4lib.org/articles/2941","OpenRoom;booking space;Ball State;open source"
"f0f2f2295bc1494f8cd7846289fd4b96",2016,"Extracting, Augmenting, and Updating Metadata in Fedora 3 and 4 Using a Local OpenRefine Reconciliation Service","When developing local collections, librarians and archivists often create detailed metadata which then gets stored in collection-specific silos. At times, the metadata could be used to augment other collections but the software does not provide native support for object relationship update and augmentation. This article describes a project updating author metadata in one collection using a local reconciliation service generated from another collection's authority records. Because the Goddard Library is on the cusp of a migration from Fedora 3 to Fedora 4, this article addresses the challenges in updating Fedora 3 and ways Fedora 4's architecture will allow for easier updates.","Tillman,Ruth","Code4Lib","http://journal.code4lib.org/articles/11179","metadata;Fedora;OpenRefine;local reconciliation service"
"f109ed53b62d463da5141ce90bd3b78b",2015,"Communication Between Devices in the Viola Document Delivery System","Viola is a newly developed document delivery system that handles incoming and outgoing requests for printed books, articles, sharing electronic resources, and other document delivery services on the local level in a library organisation. An important part of Viola is the stack fetching Android application that enables librarians to collect books in the open and closed stacks in an efficient manner using a smartphone and a Bluetooth connected portable printer. The aim of this article is to show how information is transferred between systems and devices in Viola. The article presents code examples from Viola that use current .NET technologies. The examples span from the creation of high-level REST-based JSON APIs to byte array communication with a Bluetooth connected printer and the reading of RFID tags.Please note that code examples in this article are for illustration purposes only. Null checking and other exception handling has been removed for clarity. Code that is separated in Viola for testability and other reasons has been brought together to make it more readable.","Tolstoy,Theodor","Code4Lib","http://journal.code4lib.org/articles/10293","Viola;REST;JSON API;APIRFID;document delivery system"
"f236dbf4daac440dbb799dccbd0b80bd",2017,"Supporting Oral Histories in Islandora","Since 2014, the University of Toronto Scarborough Library’s Digital Scholarship Unit (DSU) has been working on an Islandora-based solution for creating and stewarding oral histories (the Oral Histories solution pack). Although regular updates regarding the status of this work have been presented at Open Repositories conferences, this is the first article to describe the goals and features associated with this codebase, as well as the roadmap for development. An Islandora-based approach is appropriate for addressing the challenges of Oral History, an interdisciplinary methodology with complex notions of authorship and audience that both brings a corresponding complexity of use cases and roots Oral Histories projects in the ever-emergent technical and preservation challenges associated with multimedia and born digital assets. By leveraging Islandora, those embarking on Oral Histories projects benefit from existing community-supported code. By writing and maintaining the Oral Histories solution pack, the library seeks to build on common ground for those supporting Oral Histories projects and encourage a sustainable solution and feature set.","Emmanuel Barnes,Marcus;Ledchumykanthan,Natkeeran;Pham,Kim;Stapelfeldt,Kirsta","Code4Lib","http://journal.code4lib.org/articles/12176","oral histories;Islandora; Toronto"
"f2e97451c8be41ebaa6a2c3475b3c3bf",2013,"A Comparison of Article Search APIs via Blinded Experiment and Developer Review","This study looks at perceived user preference between products that can provide a scholarly article search service via an application programming interface (API). The study set up a blinded review and asked users at Johns Hopkins to select the service that provided the most useful results. Few statistically significant preferences were detected, and some interpretation is provided of what the results might tell us. The specific products evaluated for this study are: Serials Solutions Summon, Ex Libris Primo, EBSCO EDS, EBSCOHost ‘traditional’ API, and Elsevier Scopus. Re-usable open source tools for implementing article search were created to support the study and future development, and a developer review of the APIs is included based on the developer's experience in this implementation.","Rochkind,Jonathan","Code4Lib","http://journal.code4lib.org/articles/7738","API;study;article search;search;blinded review"
"f330e1713867422b974aa8d5db225ad9",2022,"Preservation and Visualization of theRural Route Nomad Photo and Video Collection","This article documents the steps taken in the preservation of a personal photo and video project, “Rural Route Nomad,” consisting of 14,058 born-digital objects from over a dozen different digital cameras used on world travels throughout all seven continents from the end of 2008 through 2009. Work was done independently, “DIY” if you will, with professional standards implemented in a manageable way sans the more extensive resources of a larger institution.Efforts were undertaken in three main stages: preservation, dataset generation, and visualization.","Webber,Alan","Code4Lib","https://journal.code4lib.org/articles/16626","preservation;images;dataset generation;visualization"
"f382a0d55e4f4449996cfb83ecf6a863",2015,"­The Geospatial Metadata Manager’s Toolbox: Three Techniques for Maintaining Records","Managing geospatial metadata records requires a range of techniques.At the University of Idaho Library, we have tens of thousands of records which need to be maintained as well as the addition of new records which need to be normalized and added to the collections.We show a graphical user interface (GUI) tool that was developed to make simple modifications, a simple XSLT that operates on complex metadata, and a Python script with enables parallel processing to make maintenance tasks more efficient.Throughout, we compare these techniques and discuss when they may be useful.","Godfrey,Bruce;Kenyon,Jeremy","Code4Lib","http://journal.code4lib.org/articles/10601","geospatial metadata;Idaho;GUI;XSLT;Python;parallel processing;techniques"
"f39a3ab606a44e778812c1f3e641023c",2014,"EPUB as publication format in Open Access journals: Tools and workflow","In this article, we present a case study of how the main publishing format of an Open Access journal was changed from PDF to EPUB by designing a new workflow using JATS as the basic XML source format. We state the reasons and discuss advantages for doing this, how we did it, and the costs of changing an established Microsoft Word workflow. As an example, we use one typical sociology article with tables, illustrations and references. We then follow the article from JATS markup through different transformations resulting in XHTML, EPUB and MOBI versions. In the end, we put everything together in an automated XProc pipeline. The process has been developed on free and open source tools, and we describe and evaluate these tools in the article. The workflow is suitable for non-professional publishers, and all code is attached and free for reuse by others.","Eikebrokk,Trude;Arne Dahl,Tor;Kessel,Siri","Code4Lib","http://journal.code4lib.org/articles/9462","EPUB;PDF;JATS;OJS"
"f3f762c1030e45809f0d07aa06cc9a5b",2008,"WordPress as a Content Management System for a Library Web Site: How to Create a Dynamically Generated Subject Guide","This article explains a method of generating dynamic subject guides through the WordPress content management system. This method includes the use of the Exec-PHP WordPress plugin and additional PHP code to create a new category-based loop within the preexisting WordPress loop. Example code and screenshots are provided.","Dodson,Joshua","Code4Lib","http://journal.code4lib.org/articles/76","WordPress;web site"
"f519d4f6db2c424c82dcf2bd50a964bd",2014,"Recipes for Enhancing Digital Collections with Linked Data","Standards-based metadata in digital library collections are commonly less than standard. Limitations brought on by routine cataloging errors, sporadic use of authority and controlled vocabularies, and systems that cannot effectively handle text encoding lead to pervasive quality issues. This paper describes the use of Linked Data for enhancement and quality control of existing digital collections metadata. We provide practical recipes for transforming uncontrolled text values into semantically rich data, performing automated cleanup on hand-entered fields, and discovering new information from links between legacy metadata and external datasets.","Johnson,Thomas;Estlund,Karen","Code4Lib","http://journal.code4lib.org/articles/9214","linked data;quality control;metadata;automated cleanup"
"f58f58ad7418426a8adc380818913897",2017,"New Metadata Recipes for Old Cookbooks: Creating and Analyzing a Digital Collection Using the HathiTrust Research Center Portal","The Early American Cookbooks digital project is a case study in analyzing collections as data using HathiTrust and the HathiTrust Research Center (HTRC) Portal. The purposes of the project are to create a freely available, searchable collection of full-text early American cookbooks within the HathiTrust Digital Library, to offer an overview of the scope and contents of the collection, and to analyze trends and patterns in the metadata and the full text of the collection. The digital project has two basic components: a collection of 1450 full-text cookbooks published in the United States between 1800 and 1920 and a website to present a guide to the collection and the results of the analysis. This article will focus on the workflow for analyzing the metadata and the full-text of the collection. The workflow will cover: 1) creating a searchable public collection of full-text titles within the HathiTrust Digital Library and uploading it to the HTRC Portal, 2) analyzing and visualizing legacy MARC data for the collection using MarcEdit, OpenRefine and Tableau, and 3) using the text analysis tools in the HTRC Portal to look for trends and patterns in the full text of the collection.","Stevens,Gioia","Code4Lib","http://journal.code4lib.org/articles/12548","cookbooks;medatata;MARC;MarcEdit;OpenRefine;Tableau;HTRC Portal"
"f5ad4f2f5102498d83d88cefb6aae8ef",2011,"Using Authority Data in VuFind","The use of keyword-oriented next-generation catalogs in libraries has diminished the perceived value of the structured authority data that played a more crucial role in earlier OPACs. However, authority data can still be combined with modern discovery in useful ways. This article examines several ways in which the open source VuFind environment provides information to its users, showing how these mechanisms can be combined with authority data to enhance discovery. Topics covered include autosuggestion, context-sensitive recommendations, use of APIs, and means of harvesting and locally indexing authority data.","Katz,Demian;LeVan,Ralph;Ziso,Ya’aqov","Code4Lib","http://journal.code4lib.org/articles/5354","API;VuFind;OPAC;indexing;authority data"
"f6941e21c5e44f9b9ddbe9b75f644c21",2009,"Automatic Preparation of ETD Material from the Internet Archive for the DSpace Repository Platform","A big challenge associated with getting an institutional repository off the ground is getting content into it. This article will look at how to use digitization services at the Internet Archive alongside software utilities that the author developed to automate the harvesting of scanned dissertations and associated Dublin Core XML files to create an ETD Portal using the DSpace platform. The end result is a metadata-rich, full-text collection of theses that can be constructed for little out of pocket cost.","Ribaric,Tim","Code4Lib","http://journal.code4lib.org/articles/2152","ETD;Dspace;Dublin Core"
"f7feca42ee3d4991bb354223e47b9d4c",2021,"Leveraging a Custom Python Script to Scrape Subject Headings for Journals","In our current library fiscal climate with yearly inflationary cost increases of 2-6+% for many journals and journal package subscriptions, it is imperative that libraries strive to make our budgets go further to expand our suite of resources. As a result, most academic libraries annually undertake some form of electronic journal review, employing factors such as cost per use to inform budgetary decisions. In this paper we detail some tech savvy processes we created to leverage a Python script to automate journal subject heading generation within the OCLC’s WorldCat catalog, the MOBIUS (A Missouri Library Consortium) Catalog, and the VuFind Library Catalog, a now retired catalog for the CARLI (Consortium for Academic and Research Libraries in Illinois). We also describe the rationale for the inception of this project, the methodology we utilized, the current limitations, and details of our future work in automating our annual analysis of journal subject headings by use of an OCLC API.","R. McDavid,Shelly;McDavid,Eric;E. Das,Neil","Code4Lib","https://journal.code4lib.org/articles/16080","Python;subject headings;OCLC;WorldCat;MOBIUS;Missouri;CARLI;API"
"f8176b9ed0db48fb89498c7d74576e89",2017,"Autoload: a pipeline for expanding the holdings of an Institutional Repository enabled by ResourceSync","Providing local access to locally produced content is a primary goal of the Institutional Repository (IR). Guidelines, requirements, and workflows are among the ways in which institutions attempt to ensure this content is deposited and preserved, but some content is always missed. At Los Alamos National Laboratory, the library implemented a service called LANL Research Online (LARO), to provide public access to a collection of publicly shareable LANL researcher publications authored between 2006 and 2016. LARO exposed the fact that we have full text for only about 10% of eligible publications for this time period, despite a review and release requirement that ought to have resulted in a much higher deposition rate. This discovery motivated a new effort to discover and add more full text content to LARO. Autoload attempts to locate and harvest items that were not deposited locally, but for which archivable copies exist. Here we describe the Autoload pipeline prototype and how it aggregates and utilizes Web services including Crossref, SHERPA/RoMEO, and oaDOI as it attempts to retrieve archivable copies of resources. Autoload employs a bootstrapping mechanism based on the ResourceSync standard, a NISO standard for data replication and synchronization. We implemented support for ResourceSync atop the LARO Solr index, which exposes metadata contained in the local IR. This allowed us to utilize ResourceSync without modifying our IR. We close with a brief discussion of other uses we envision for our ResourceSync-Solr implementation, and describe how a new effort called Signposting can replace cumbersome screen scraping with a robust autodiscovery path to content which leverages the Web protocol.","Powell,James;Klein,Martin;Van de Sompel,Herbert","Code4Lib","http://journal.code4lib.org/articles/12427","pipeline;institutional repository;Los Alamos;LANL;LARO;Autoload;pipeline;Solr;ResourceSync"
"f8a8f5ce405b4661a45751d6dd1a2012",2021,"Closing the Gap between FAIR Data Repositories and Hierarchical Data Formats","Many in the scientific community, particularly in publicly funded research, are pushing to adhere to more accessible data standards to maximize the findability, accessibility, interoperability, and reusability (FAIR) of scientific data, especially with the growing prevalence of machine learning augmented research. Online FAIR data repositories, such as the Open Science Framework (OSF), help facilitate the adoption of these standards by providing frameworks for storage, access, search, APIs, and other features that create organized hubs of scientific data. However, the wider acceptance of such repositories is hindered by the lack of support of hierarchical data formats, such as Technical Data Management Streaming (TDMS) and Hierarchical Data Format 5 (HDF5), that many researchers rely on to organize their datasets. Various tools and strategies should be used to allow hierarchical data formats, FAIR data repositories, and scientific organizations to work more seamlessly together. A pilot project at Los Alamos National Laboratory (LANL) addresses the disconnect between them by integrating the OSF FAIR data repository with hierarchical data renderers, extending support for additional file types in their framework. The multifaceted interactive renderer displays a tree of metadata alongside a table and plot of the data channels in the file. This allows users to quickly and efficiently load large and complex data files directly in the OSF webapp. Users who are browsing files can quickly and intuitively see the files in the way they or their colleagues structured the hierarchical form and immediately grasp their contents. This solution helps bridge the gap between hierarchical data storage techniques and FAIR data repositories, making both of them more viable options for scientific institutions like LANL which have been put off by the lack of integration between them.","B. Bailey,Connor;F. Balakirev,Fedor;L. Balakireva,Lyudmila","Code4Lib","https://journal.code4lib.org/articles/16223","API;FAIR;data repositories;Open Science Framework;LANL;OSF;hierarchical data storage"
"f8a9849f5ea64bc3a1cc34cd1a4a272b",2019,"A Systematic Approach to Collecting Student Work","Digital technology has profoundly changed design education over the past couple of decades. The digital design process generates design solutions from many different angles and points of views, captured and expressed in many file formats and file types. In this environment of ubiquitous digital files, what are effective ways for a design school to capture a snapshot of the work created within their school, and to create a long-term collection of student files for purposes of research and promotion, and for preserving the history of the school?  This paper describes the recent efforts of the Harvard Graduate School of Design in creating a scalable and long-term data management solution for digital student work files.The first part describes the context and history of student work at the Harvard Graduate School of Design. The second section of the paper focuses on the functionality of the tool we created, and lastly, the paper looks at the library’s current efforts for the long-term archiving of the collected student files in Harvard’s digital repository.","Mueller,Janina","Code4Lib","https://journal.code4lib.org/articles/14277","Harvard;archiving"
"f8da1e550c9140b98edb4efab68923c3",2010,"Creating Filtered, Translated Newsfeeds","Google Translate's API creates the possibility to leverage machine translation to both filter global newsfeeds for content regarding a specific topic, and to aggregate filtered feed items as a newsfeed. Filtered items can be translated so that the resulting newsfeed can provide basic information about topic-specific news articles from around the globe in the desired language of the consumer. This article explores a possible solution for inputting alternate words and phrases in the user’s native language, aggregating and filtering newsfeeds progammatically, managing filter terms, and using Google Translate’s API.","Marks Collins,Linn;L. B. Martinez,Mark;E. Powell,James","Code4Lib","http://journal.code4lib.org/articles/3232","API;Google Translate;newsfeeds"
"f97c14b9028543cc821928bffa0aac6b",2014,"Within Limits: mass-digitization from scratch","The provincial library of West-Vlaanderen (Belgium) is digitizing a large part of its iconographic collection. Due to various (technical and financial) reasons no specialist software was used. FastScan is a set of VBS-scripts that was developed by the author using off-the-shelf software that was either included in MS Windows (XP & 7) or already installed (imageMagick, Irfanview, littlecms, exiv2). This scripting package has increased the digitization efforts immensely. The article will show what software was used, the problems that occurred and how they were scripted together.","De Praetere,Pieter","Code4Lib","http://journal.code4lib.org/articles/9780","Belgium;iconographic collection;DastScan;VBS;mass digitization"
"f98b0e4dfd3446ccb2da81caf874e2e3",2018,"Editorial: Beyond Posters: On Hospitality in Libtech","In this editorial, I will be using the word hospitality to mean the intentional welcome of others into a space which one currently occupies, possibly as a member of a dominant group. I do not wish to encourage the idea that one should cultivate or maintain a role of benevolent host in a way that forces others to remain forever guest or outsider, although there will always be newcomers. Hospitality may be a first step to ceding one's position as host in a space. It may be expanding that space to become a place with many potential hosts, each respected for their varied contributions and skillsets. It may also be supporting those in a different space or a different role, such as those who use the technologies we build and support (both colleagues and patrons), and respecting them in that space.","Kitchin Tillman,Ruth","Code4Lib","http://journal.code4lib.org/articles/13432","editorial"
"fbd174b2ea714450a9ea97fce058c880",2014,"A Metadata Schema for Geospatial Resource Discovery Use Cases","We introduce a metadata schema that focuses on GIS discovery use cases for patrons in a research library setting. Text search, faceted refinement, and spatial search and relevancy are among GeoBlacklight's primary use cases for federated geospatial holdings. The schema supports a variety of GIS data types and enables contextual, collection-oriented discovery applications as well as traditional portal applications. One key limitation of GIS resource discovery is the general lack of normative metadata practices, which has led to a proliferation of metadata schemas and duplicate records. The ISO 19115/19139 and FGDC standards specify metadata formats, but are intricate, lengthy, and not focused on discovery. Moreover, they require sophisticated authoring environments and cataloging expertise. Geographic metadata standards target preservation and quality measure use cases, but they do not provide for simple inter-institutional sharing of metadata for discovery use cases. To this end, our schema reuses elements from Dublin Core and GeoRSS to leverage their normative semantics, community best practices, open-source software implementations, and extensive examples already deployed in discovery contexts such as web search and mapping. Finally, we discuss a Solr implementation of the schema using a ""geo"" extension to MODS.","Hardy,Darren;Durante,Kim","Code4Lib","http://journal.code4lib.org/articles/9710","metadata schema;GIS;GeoBlacklight;FGDC;Dublin Core;GeoRSS;MODS"
"fbe97f8da6044f9d9df5abc3e4802a8d",2008,"Geocoding LCSH in the Biodiversity Heritage Library","Reusing metadata generated through years of cataloging practice is a natural and pragmatic way of leveraging an institution's investment in describing its resources. Using Library of Congress Subject Headings (LCSH), the Biodiversity Heritage Library generates new interfaces for browsing and navigating books in a digital library. LCSH are grouped into tag clouds and plotted on interactive maps using methods available within the Google Maps Application Programming Interface (API). Code examples are included, and issues related to these interfaces and the underlying LCSH data are examined.","Crozier,Marc;Paige,Jay;Kalfatovic,Martin;Freeland,Chris","Code4Lib","http://journal.code4lib.org/articles/52","geocoding;LCSH;biodiversity;API"
"fcd36e55c87845c6bdd5415b5c4b1d03",2019,"Visualizing Fedora-managed TEI and MEI documents within Islandora","The Early Modern Songscapes (EMS) project represents a development partnership between the University of Toronto Scarborough’s Digital Scholarship Unit (DSU), the University of Maryland, and the University of South Carolina. Developers, librarians and faculty from both institutions have collaborated on an intermedia online platform designed to support the scholarly investigation of early modern English song. The first iteration of the platform, launched at the Early modern Songscapes Conference, held February 8-9, 2019 at the University of Toronto’s Centre for Reformation and Renaissance Studies, serves Fedora-held Text Encoding Initiative (TEI) and Music Encoding Initiative (MEI) documents through a JavaScript viewer capable of being embedded within the Islandora digital asset management framework. The viewer presents versions of a song’s musical notation and textual underlay followed by the entire song text.This article reviews the status of this technology, and the process of developing an XML framework for TEI and MEI editions that would serve the requirements of all stakeholder technologies. Beyond the applicability of this technology in other digital scholarship contexts, the approach may serve others seeking methods for integrating technologies into Islandora or working across institutional development environments.","Viglianti, Marcus Emmanuel Barnes, Natkeeran Ledchumykanthan, Kirsta Stapelfeldt,Raffaele","Code4Lib","https://journal.code4lib.org/articles/14532","Fedora;DSU;TEI;MEI;JavaScript;XML;Islandora;visualization"
"fd39abef629c42fc826874d076274f4e",2017,"What’s New? Deploying a Library New Titles Page with Minimal Programming","With a new titles web page, a library has a place to show faculty, students, and staff the items they are purchasing for their community. However, many times heavy programing knowledge and/or a LAMP stack (Linux, Apache, MySQL, PHP) or APIs separate a library’s data from making a new titles web page a reality. Without IT staff, a new titles page can become nearly impossible or not worth the effort. Here we will demonstrate how a small liberal arts college took its acquisition data and combined it with a Google Sheet, HTML, and a little JavaScript to create a new titles web page that was dynamic and engaging to its users.","Meyerhofer,John","Code4Lib","http://journal.code4lib.org/articles/12199","user engagement;JavaScript;Google Sheet"
"fd4531ea40a14567875bf6b754522616",2016,"Bringing our Internet Archive collection back home: A case study from the University of Mary Washington","The Internet Archive is a great boon to smaller libraries that may not have the resources to host their own digital materials.However, individual items uploaded to the Internet Archive are hard to treat as a collection.Full text searching can only be done within an item.It can be difficult to direct patrons to local resources.Since 2010, the University of Mary Washington has uploaded over two thousand digitized university publications, including the student newspaper and the yearbook, to the Internet Archive.Taken together, these represent almost 100 years of UMW history.Using Apache Lucy, we built a search interface, Eagle Explorer, that treats our Internet Archive collection as a cohesive whole.Patrons can use Eagle Explorer to full-text search within the collection and to filter by date and publication.This article will describe how we created Eagle Explorer, the challenges we encountered, and its reception from the campus community.","Perdue,Katherine","Code4Lib","http://journal.code4lib.org/articles/11131","Internet Archive;case study;UMW;Apache Lucy;Eagle Explorer"
"fdf62114314245c28fed8e2faa66452e",2013,"Open Source Library Software Development in a Small Rural Library System","Using the Crawford County Federated Library System’s development of an open source web kiosk management system, as an example, this article will illustrate how an open source library project is defined, specified, written, tested and rolled out. The article will also discuss how the project was released as an Open Source project and future development of the project. The web kiosk project is called Libki and was written to authenticate users and allow access to the Internet kiosks based on time limits. Libki is a completely Open Source project and is now used by multiple libraries across the US. The client side of Libki is cross platform and supports multiple operating systems including Microsoft Windows and Linux. The administrative side of the program allows access to user logs, controls time and access and allows the librarian to log a patron off the system in real time. Libki was completely developed and written by staff members of the Crawford County Federated Library System.","Hall,Kyle;Murdock Ames,Cindy;Brice,John","Code4Lib","http://journal.code4lib.org/articles/7939","kiosk;Libki"
"fe059ab7a95646a88f36f186b9973f07",2007,"Beyond OPAC 2.0: Library Catalog as Versatile Discovery Platform","North Carolina State University has developed an Application Programming Interface (API) “platform”, called CatalogWS, to provide web service access to catalog search and availability services. This project was motivated by the realization that the discovery of library collections should not be limited to a single catalog application, and such a platform could support the efficient creation of novel interfaces based on consistent services. Some technical discussion of the CatalogWS architecture is provided, including a technical description of web service protocols implemented. Several applications providing discovery in novel contexts have already been developed based on CatalogWS, and are described in some depth. CatalogWS has helped create a culture of experimentation and enabled a larger group of staff to work with library catalog data and services in new and interesting ways.","Sierra,Tito;Ryan,Joseph;West,Markus","Code4Lib","http://journal.code4lib.org/articles/10","API;OPAC;CatalogWS;project;architecture"
"feec8fb977aa41649abb852b8c2a3537",2010,"Editorial Introduction – A Cataloger's Perspective on the Code4Lib Journal","On the Code4Lib Journal, technology, and the universe of library cataloging and metadata.","McGrath,Kelley","Code4Lib","http://journal.code4lib.org/articles/3950","editorial"
"ff39c6c281584362b2d4e6cb57064660",2021,"On Two Proposed Metrics of Electronic Resource Use","There are many ways to look at electronic resource use, individually or aggregated. I propose two new metrics to help give a better understanding of comparative use across an online collection. Users per mille is a relative annual measure of how many users a platform had for every thousand potential users: this tells us how many people used a given platform. Interest factor is the average number of uses of a platform by people who used it more than once: this tells us how much people used a given platform. These two metrics are enough to give us good insight into collection use. Dividing each into quartiles allows a quadrant comparison of lows and highs on each metric, giving a quick view of platforms many people use a lot (the big expensive ones), many people use very little (a curious subset), a few people use a lot (very specific to a narrow subject) and a few people use very little (deserves attention). This helps understand collection use and informs collection management.","Denton,William","Code4Lib","https://journal.code4lib.org/articles/16087","metrics;collection use;collection management;users"
